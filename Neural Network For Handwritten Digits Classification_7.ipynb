{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "72855e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.youtube.com/watch?v=iqQgED9vV7k&list=PLeo1K3hjS3uu7CxAacxVndI4bE_o3BDtO&index=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "62a42a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f43f0f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "981ee08b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d86066e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "55aa79bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x27d3e090b08>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "457bd82a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9263c0bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1, 9], dtype=uint8)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8835c2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_flattened = X_train.reshape(len(X_train), 28*28)\n",
    "X_test_flattened = X_test.reshape(len(X_test), 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "27ea010f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_flattened.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d95372b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Dense in module tensorflow.python.keras.layers.core:\n",
      "\n",
      "class Dense(tensorflow.python.keras.engine.base_layer.Layer)\n",
      " |  Dense(units, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)\n",
      " |  \n",
      " |  Just your regular densely-connected NN layer.\n",
      " |  \n",
      " |  `Dense` implements the operation:\n",
      " |  `output = activation(dot(input, kernel) + bias)`\n",
      " |  where `activation` is the element-wise activation function\n",
      " |  passed as the `activation` argument, `kernel` is a weights matrix\n",
      " |  created by the layer, and `bias` is a bias vector created by the layer\n",
      " |  (only applicable if `use_bias` is `True`).\n",
      " |  \n",
      " |  Note: If the input to the layer has a rank greater than 2, then\n",
      " |  it is flattened prior to the initial dot product with `kernel`.\n",
      " |  \n",
      " |  Example:\n",
      " |  \n",
      " |  ```python\n",
      " |  # as first layer in a sequential model:\n",
      " |  model = Sequential()\n",
      " |  model.add(Dense(32, input_shape=(16,)))\n",
      " |  # now the model will take as input arrays of shape (*, 16)\n",
      " |  # and output arrays of shape (*, 32)\n",
      " |  \n",
      " |  # after the first layer, you don't need to specify\n",
      " |  # the size of the input anymore:\n",
      " |  model.add(Dense(32))\n",
      " |  ```\n",
      " |  \n",
      " |  Arguments:\n",
      " |    units: Positive integer, dimensionality of the output space.\n",
      " |    activation: Activation function to use.\n",
      " |      If you don't specify anything, no activation is applied\n",
      " |      (ie. \"linear\" activation: `a(x) = x`).\n",
      " |    use_bias: Boolean, whether the layer uses a bias vector.\n",
      " |    kernel_initializer: Initializer for the `kernel` weights matrix.\n",
      " |    bias_initializer: Initializer for the bias vector.\n",
      " |    kernel_regularizer: Regularizer function applied to\n",
      " |      the `kernel` weights matrix.\n",
      " |    bias_regularizer: Regularizer function applied to the bias vector.\n",
      " |    activity_regularizer: Regularizer function applied to\n",
      " |      the output of the layer (its \"activation\")..\n",
      " |    kernel_constraint: Constraint function applied to\n",
      " |      the `kernel` weights matrix.\n",
      " |    bias_constraint: Constraint function applied to the bias vector.\n",
      " |  \n",
      " |  Input shape:\n",
      " |    N-D tensor with shape: `(batch_size, ..., input_dim)`.\n",
      " |    The most common situation would be\n",
      " |    a 2D input with shape `(batch_size, input_dim)`.\n",
      " |  \n",
      " |  Output shape:\n",
      " |    N-D tensor with shape: `(batch_size, ..., units)`.\n",
      " |    For instance, for a 2D input with shape `(batch_size, input_dim)`,\n",
      " |    the output would have shape `(batch_size, units)`.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Dense\n",
      " |      tensorflow.python.keras.engine.base_layer.Layer\n",
      " |      tensorflow.python.module.module.Module\n",
      " |      tensorflow.python.training.tracking.tracking.AutoTrackable\n",
      " |      tensorflow.python.training.tracking.base.Trackable\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, units, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)\n",
      " |  \n",
      " |  build(self, input_shape)\n",
      " |      Creates the variables of the layer (optional, for subclass implementers).\n",
      " |      \n",
      " |      This is a method that implementers of subclasses of `Layer` or `Model`\n",
      " |      can override if they need a state-creation step in-between\n",
      " |      layer instantiation and layer call.\n",
      " |      \n",
      " |      This is typically used to create the weights of `Layer` subclasses.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        input_shape: Instance of `TensorShape`, or list of instances of\n",
      " |          `TensorShape` if the layer expects a list of inputs\n",
      " |          (one instance per input).\n",
      " |  \n",
      " |  call(self, inputs)\n",
      " |      This is where the layer's logic lives.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          inputs: Input tensor, or list/tuple of input tensors.\n",
      " |          **kwargs: Additional keyword arguments.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor or list/tuple of tensors.\n",
      " |  \n",
      " |  compute_output_shape(self, input_shape)\n",
      " |      Computes the output shape of the layer.\n",
      " |      \n",
      " |      If the layer has not been built, this method will call `build` on the\n",
      " |      layer. This assumes that the layer will later be used with inputs that\n",
      " |      match the input shape provided here.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          input_shape: Shape tuple (tuple of integers)\n",
      " |              or list of shape tuples (one per output tensor of the layer).\n",
      " |              Shape tuples can include None for free dimensions,\n",
      " |              instead of an integer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An input shape tuple.\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the config of the layer.\n",
      " |      \n",
      " |      A layer config is a Python dictionary (serializable)\n",
      " |      containing the configuration of a layer.\n",
      " |      The same layer can be reinstantiated later\n",
      " |      (without its trained weights) from this configuration.\n",
      " |      \n",
      " |      The config of a layer does not include connectivity\n",
      " |      information, nor the layer class name. These are handled\n",
      " |      by `Network` (one layer of abstraction above).\n",
      " |      \n",
      " |      Returns:\n",
      " |          Python dictionary.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  __call__(self, inputs, *args, **kwargs)\n",
      " |      Wraps `call`, applying pre- and post-processing steps.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: input tensor(s).\n",
      " |        *args: additional positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: additional keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |      \n",
      " |      Note:\n",
      " |        - The following optional keyword arguments are reserved for specific uses:\n",
      " |          * `training`: Boolean scalar tensor of Python boolean indicating\n",
      " |            whether the `call` is meant for training or inference.\n",
      " |          * `mask`: Boolean input mask.\n",
      " |        - If the layer's `call` method takes a `mask` argument (as some Keras\n",
      " |          layers do), its default value will be set to the mask generated\n",
      " |          for `inputs` by the previous layer (if `input` did come from\n",
      " |          a layer that generated a corresponding mask, i.e. if it came from\n",
      " |          a Keras layer with masking support.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: if the layer's `call` method returns None (an invalid value).\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Support self.foo = trackable syntax.\n",
      " |  \n",
      " |  add_loss(self, losses, inputs=None)\n",
      " |      Add loss tensor(s), potentially dependent on layer inputs.\n",
      " |      \n",
      " |      Some losses (for instance, activity regularization losses) may be dependent\n",
      " |      on the inputs passed when calling a layer. Hence, when reusing the same\n",
      " |      layer on different inputs `a` and `b`, some entries in `layer.losses` may\n",
      " |      be dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      This method can be used inside a subclassed layer or model's `call`\n",
      " |      function, in which case `losses` should be a Tensor or list of Tensors.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      class MyLayer(tf.keras.layers.Layer):\n",
      " |        def call(inputs, self):\n",
      " |          self.add_loss(tf.abs(tf.reduce_mean(inputs)), inputs=True)\n",
      " |          return inputs\n",
      " |      ```\n",
      " |      \n",
      " |      This method can also be called directly on a Functional Model during\n",
      " |      construction. In this case, any loss Tensors passed to this Model must\n",
      " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
      " |      losses become part of the model's topology and are tracked in `get_config`.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Actvity regularization.\n",
      " |      model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
      " |      ```\n",
      " |      \n",
      " |      If this is not the case for your loss (if, for example, your loss references\n",
      " |      a `Variable` of one of the model's layers), you can wrap your loss in a\n",
      " |      zero-argument lambda. These losses are not tracked as part of the model's\n",
      " |      topology since they can't be serialized.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Weight regularization.\n",
      " |      model.add_loss(lambda: tf.reduce_mean(x.kernel))\n",
      " |      ```\n",
      " |      \n",
      " |      The `get_losses_for` method allows to retrieve the losses relevant to a\n",
      " |      specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        losses: Loss tensor, or list/tuple of tensors. Rather than tensors, losses\n",
      " |          may also be zero-argument callables which create a loss tensor.\n",
      " |        inputs: Ignored when executing eagerly. If anything other than None is\n",
      " |          passed, it signals the losses are conditional on some of the layer's\n",
      " |          inputs, and thus they should only be run where these inputs are\n",
      " |          available. This is the case for activity regularization losses, for\n",
      " |          instance. If `None` is passed, the losses are assumed\n",
      " |          to be unconditional, and will apply across all dataflows of the layer\n",
      " |          (e.g. weight regularization losses).\n",
      " |  \n",
      " |  add_metric(self, value, aggregation=None, name=None)\n",
      " |      Adds metric tensor to the layer.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: Metric tensor.\n",
      " |        aggregation: Sample-wise metric reduction function. If `aggregation=None`,\n",
      " |          it indicates that the metric tensor provided has been aggregated\n",
      " |          already. eg, `bin_acc = BinaryAccuracy(name='acc')` followed by\n",
      " |          `model.add_metric(bin_acc(y_true, y_pred))`. If aggregation='mean', the\n",
      " |          given metric tensor will be sample-wise reduced using `mean` function.\n",
      " |          eg, `model.add_metric(tf.reduce_sum(outputs), name='output_mean',\n",
      " |          aggregation='mean')`.\n",
      " |        name: String metric name.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If `aggregation` is anything other than None or `mean`.\n",
      " |  \n",
      " |  add_update(self, updates, inputs=None)\n",
      " |      Add update op(s), potentially dependent on layer inputs. (deprecated arguments)\n",
      " |      \n",
      " |      Warning: SOME ARGUMENTS ARE DEPRECATED: `(inputs)`. They will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      `inputs` is now automatically inferred\n",
      " |      \n",
      " |      Weight updates (for instance, the updates of the moving mean and variance\n",
      " |      in a BatchNormalization layer) may be dependent on the inputs passed\n",
      " |      when calling a layer. Hence, when reusing the same layer on\n",
      " |      different inputs `a` and `b`, some entries in `layer.updates` may be\n",
      " |      dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      The `get_updates_for` method allows to retrieve the updates relevant to a\n",
      " |      specific set of inputs.\n",
      " |      \n",
      " |      This call is ignored when eager execution is enabled (in that case, variable\n",
      " |      updates are run on the fly and thus do not need to be tracked for later\n",
      " |      execution).\n",
      " |      \n",
      " |      Arguments:\n",
      " |        updates: Update op, or list/tuple of update ops, or zero-arg callable\n",
      " |          that returns an update op. A zero-arg callable should be passed in\n",
      " |          order to disable running the updates by setting `trainable=False`\n",
      " |          on this Layer, when executing in Eager mode.\n",
      " |        inputs: Deprecated, will be automatically inferred.\n",
      " |  \n",
      " |  add_variable(self, *args, **kwargs)\n",
      " |      Deprecated, do NOT use! Alias for `add_weight`. (deprecated)\n",
      " |      \n",
      " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      Please use `layer.add_weight` method instead.\n",
      " |  \n",
      " |  add_weight(self, name=None, shape=None, dtype=None, initializer=None, regularizer=None, trainable=None, constraint=None, partitioner=None, use_resource=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregation.NONE: 0>, **kwargs)\n",
      " |      Adds a new variable to the layer.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        name: Variable name.\n",
      " |        shape: Variable shape. Defaults to scalar if unspecified.\n",
      " |        dtype: The type of the variable. Defaults to `self.dtype` or `float32`.\n",
      " |        initializer: Initializer instance (callable).\n",
      " |        regularizer: Regularizer instance (callable).\n",
      " |        trainable: Boolean, whether the variable should be part of the layer's\n",
      " |          \"trainable_variables\" (e.g. variables, biases)\n",
      " |          or \"non_trainable_variables\" (e.g. BatchNorm mean and variance).\n",
      " |          Note that `trainable` cannot be `True` if `synchronization`\n",
      " |          is set to `ON_READ`.\n",
      " |        constraint: Constraint instance (callable).\n",
      " |        partitioner: Partitioner to be passed to the `Trackable` API.\n",
      " |        use_resource: Whether to use `ResourceVariable`.\n",
      " |        synchronization: Indicates when a distributed a variable will be\n",
      " |          aggregated. Accepted values are constants defined in the class\n",
      " |          `tf.VariableSynchronization`. By default the synchronization is set to\n",
      " |          `AUTO` and the current `DistributionStrategy` chooses\n",
      " |          when to synchronize. If `synchronization` is set to `ON_READ`,\n",
      " |          `trainable` must not be set to `True`.\n",
      " |        aggregation: Indicates how a distributed variable will be aggregated.\n",
      " |          Accepted values are constants defined in the class\n",
      " |          `tf.VariableAggregation`.\n",
      " |        **kwargs: Additional keyword arguments. Accepted values are `getter` and\n",
      " |          `collections`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The created variable. Usually either a `Variable` or `ResourceVariable`\n",
      " |        instance. If `partitioner` is not `None`, a `PartitionedVariable`\n",
      " |        instance is returned.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called with partitioned variable regularization and\n",
      " |          eager execution is enabled.\n",
      " |        ValueError: When giving unsupported dtype and no initializer or when\n",
      " |          trainable has been set to True with synchronization set as `ON_READ`.\n",
      " |  \n",
      " |  apply(self, inputs, *args, **kwargs)\n",
      " |      Deprecated, do NOT use! (deprecated)\n",
      " |      \n",
      " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      Please use `layer.__call__` method instead.\n",
      " |      \n",
      " |      This is an alias of `self.__call__`.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor(s).\n",
      " |        *args: additional positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: additional keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |  \n",
      " |  compute_mask(self, inputs, mask=None)\n",
      " |      Computes an output mask tensor.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          inputs: Tensor or list of tensors.\n",
      " |          mask: Tensor or list of tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |          None or a tensor (or list of tensors,\n",
      " |              one per output tensor of the layer).\n",
      " |  \n",
      " |  compute_output_signature(self, input_signature)\n",
      " |      Compute the output tensor signature of the layer based on the inputs.\n",
      " |      \n",
      " |      Unlike a TensorShape object, a TensorSpec object contains both shape\n",
      " |      and dtype information for a tensor. This method allows layers to provide\n",
      " |      output dtype information if it is different from the input dtype.\n",
      " |      For any layer that doesn't implement this function,\n",
      " |      the framework will fall back to use `compute_output_shape`, and will\n",
      " |      assume that the output dtype matches the input dtype.\n",
      " |      \n",
      " |      Args:\n",
      " |        input_signature: Single TensorSpec or nested structure of TensorSpec\n",
      " |          objects, describing a candidate input for the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Single TensorSpec or nested structure of TensorSpec objects, describing\n",
      " |          how the layer would transform the provided input.\n",
      " |      \n",
      " |      Raises:\n",
      " |        TypeError: If input_signature contains a non-TensorSpec object.\n",
      " |  \n",
      " |  count_params(self)\n",
      " |      Count the total number of scalars composing the weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An integer count.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: if the layer isn't yet built\n",
      " |            (in which case its weights aren't yet defined).\n",
      " |  \n",
      " |  get_input_at(self, node_index)\n",
      " |      Retrieves the input tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_input_mask_at(self, node_index)\n",
      " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_shape_at(self, node_index)\n",
      " |      Retrieves the input shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_losses_for(self, inputs)\n",
      " |      Retrieves losses relevant to a specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor or list/tuple of input tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |        List of loss tensors of the layer that depend on `inputs`.\n",
      " |  \n",
      " |  get_output_at(self, node_index)\n",
      " |      Retrieves the output tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_output_mask_at(self, node_index)\n",
      " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_shape_at(self, node_index)\n",
      " |      Retrieves the output shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_updates_for(self, inputs)\n",
      " |      Retrieves updates relevant to a specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor or list/tuple of input tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |        List of update ops of the layer that depend on `inputs`.\n",
      " |  \n",
      " |  get_weights(self)\n",
      " |      Returns the current weights of the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Weights values as a list of numpy arrays.\n",
      " |  \n",
      " |  set_weights(self, weights)\n",
      " |      Sets the weights of the layer, from Numpy arrays.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          weights: a list of Numpy arrays. The number\n",
      " |              of arrays and their shape must match\n",
      " |              number of the dimensions of the weights\n",
      " |              of the layer (i.e. it should match the\n",
      " |              output of `get_weights`).\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: If the provided weights list does not match the\n",
      " |              layer's specifications.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  from_config(config) from builtins.type\n",
      " |      Creates a layer from its config.\n",
      " |      \n",
      " |      This method is the reverse of `get_config`,\n",
      " |      capable of instantiating the same layer from the config\n",
      " |      dictionary. It does not handle layer connectivity\n",
      " |      (handled by Network), nor weights (handled by `set_weights`).\n",
      " |      \n",
      " |      Arguments:\n",
      " |          config: A Python dictionary, typically the\n",
      " |              output of get_config.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A layer instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  activity_regularizer\n",
      " |      Optional regularizer function for the output of this layer.\n",
      " |  \n",
      " |  dtype\n",
      " |  \n",
      " |  dynamic\n",
      " |  \n",
      " |  inbound_nodes\n",
      " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      " |  \n",
      " |  input\n",
      " |      Retrieves the input tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input tensor or list of input tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |        AttributeError: If no inbound nodes are found.\n",
      " |  \n",
      " |  input_mask\n",
      " |      Retrieves the input mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input mask tensor (potentially None) or list of input\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_shape\n",
      " |      Retrieves the input shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer, or if all inputs\n",
      " |      have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per input tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined input_shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  input_spec\n",
      " |  \n",
      " |  losses\n",
      " |      Losses which are associated with this `Layer`.\n",
      " |      \n",
      " |      Variable regularization tensors are created when this property is accessed,\n",
      " |      so it is eager safe: accessing `losses` under a `tf.GradientTape` will\n",
      " |      propagate gradients back to the corresponding variables.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of tensors.\n",
      " |  \n",
      " |  metrics\n",
      " |  \n",
      " |  name\n",
      " |      Returns the name of this module as passed or determined in the ctor.\n",
      " |      \n",
      " |      NOTE: This is not the same as the `self.name_scope.name` which includes\n",
      " |      parent module names.\n",
      " |  \n",
      " |  non_trainable_variables\n",
      " |  \n",
      " |  non_trainable_weights\n",
      " |  \n",
      " |  outbound_nodes\n",
      " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      " |  \n",
      " |  output\n",
      " |      Retrieves the output tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one output,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor or list of output tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        AttributeError: if the layer is connected to more than one incoming\n",
      " |          layers.\n",
      " |        RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  output_mask\n",
      " |      Retrieves the output mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output mask tensor (potentially None) or list of output\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_shape\n",
      " |      Retrieves the output shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has one output,\n",
      " |      or if all outputs have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per output tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined output shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  trainable\n",
      " |  \n",
      " |  trainable_variables\n",
      " |      Sequence of variables owned by this module and it's submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  trainable_weights\n",
      " |  \n",
      " |  updates\n",
      " |  \n",
      " |  variables\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Alias of `self.weights`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  weights\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  with_name_scope(method) from builtins.type\n",
      " |      Decorator to automatically enter the module name scope.\n",
      " |      \n",
      " |      ```\n",
      " |      class MyModule(tf.Module):\n",
      " |        @tf.Module.with_name_scope\n",
      " |        def __call__(self, x):\n",
      " |          if not hasattr(self, 'w'):\n",
      " |            self.w = tf.Variable(tf.random.normal([x.shape[1], 64]))\n",
      " |          return tf.matmul(x, self.w)\n",
      " |      ```\n",
      " |      \n",
      " |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
      " |      names included the module name:\n",
      " |      \n",
      " |      ```\n",
      " |      mod = MyModule()\n",
      " |      mod(tf.ones([8, 32]))\n",
      " |      # ==> <tf.Tensor: ...>\n",
      " |      mod.w\n",
      " |      # ==> <tf.Variable ...'my_module/w:0'>\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        method: The method to wrap.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The original method wrapped such that it enters the module's name scope.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  name_scope\n",
      " |      Returns a `tf.name_scope` instance for this class.\n",
      " |  \n",
      " |  submodules\n",
      " |      Sequence of all sub-modules.\n",
      " |      \n",
      " |      Submodules are modules which are properties of this module, or found as\n",
      " |      properties of modules which are properties of this module (and so on).\n",
      " |      \n",
      " |      ```\n",
      " |      a = tf.Module()\n",
      " |      b = tf.Module()\n",
      " |      c = tf.Module()\n",
      " |      a.b = b\n",
      " |      b.c = c\n",
      " |      assert list(a.submodules) == [b, c]\n",
      " |      assert list(b.submodules) == [c]\n",
      " |      assert list(c.submodules) == []\n",
      " |      ```\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of all submodules.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.training.tracking.base.Trackable:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(keras.layers.Dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5bee9714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 11s 179us/sample - loss: 2.1435 - acc: 0.4683\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 12s 193us/sample - loss: 1.3851 - acc: 0.5322\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x27d3e134b88>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(10, input_shape=(784,), activation='sigmoid') # 10 is number of output neurons\n",
    "])\n",
    "\n",
    "model.compile(optimizer = 'adam', \n",
    "             loss = 'sparse_categorical_crossentropy',\n",
    "             metrics = ['accuracy'])\n",
    "\n",
    "model.fit(X_train_flattened, y_train, epochs = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6d708f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I do some scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a4ff0ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "aea6ffc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0cc6d417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "49bdd54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_flattened = X_train.reshape(len(X_train),28*28)\n",
    "X_test_flattened = X_test.reshape(len(X_test), 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "41baf946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Dense in module tensorflow.python.keras.layers.core:\n",
      "\n",
      "class Dense(tensorflow.python.keras.engine.base_layer.Layer)\n",
      " |  Dense(units, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)\n",
      " |  \n",
      " |  Just your regular densely-connected NN layer.\n",
      " |  \n",
      " |  `Dense` implements the operation:\n",
      " |  `output = activation(dot(input, kernel) + bias)`\n",
      " |  where `activation` is the element-wise activation function\n",
      " |  passed as the `activation` argument, `kernel` is a weights matrix\n",
      " |  created by the layer, and `bias` is a bias vector created by the layer\n",
      " |  (only applicable if `use_bias` is `True`).\n",
      " |  \n",
      " |  Note: If the input to the layer has a rank greater than 2, then\n",
      " |  it is flattened prior to the initial dot product with `kernel`.\n",
      " |  \n",
      " |  Example:\n",
      " |  \n",
      " |  ```python\n",
      " |  # as first layer in a sequential model:\n",
      " |  model = Sequential()\n",
      " |  model.add(Dense(32, input_shape=(16,)))\n",
      " |  # now the model will take as input arrays of shape (*, 16)\n",
      " |  # and output arrays of shape (*, 32)\n",
      " |  \n",
      " |  # after the first layer, you don't need to specify\n",
      " |  # the size of the input anymore:\n",
      " |  model.add(Dense(32))\n",
      " |  ```\n",
      " |  \n",
      " |  Arguments:\n",
      " |    units: Positive integer, dimensionality of the output space.\n",
      " |    activation: Activation function to use.\n",
      " |      If you don't specify anything, no activation is applied\n",
      " |      (ie. \"linear\" activation: `a(x) = x`).\n",
      " |    use_bias: Boolean, whether the layer uses a bias vector.\n",
      " |    kernel_initializer: Initializer for the `kernel` weights matrix.\n",
      " |    bias_initializer: Initializer for the bias vector.\n",
      " |    kernel_regularizer: Regularizer function applied to\n",
      " |      the `kernel` weights matrix.\n",
      " |    bias_regularizer: Regularizer function applied to the bias vector.\n",
      " |    activity_regularizer: Regularizer function applied to\n",
      " |      the output of the layer (its \"activation\")..\n",
      " |    kernel_constraint: Constraint function applied to\n",
      " |      the `kernel` weights matrix.\n",
      " |    bias_constraint: Constraint function applied to the bias vector.\n",
      " |  \n",
      " |  Input shape:\n",
      " |    N-D tensor with shape: `(batch_size, ..., input_dim)`.\n",
      " |    The most common situation would be\n",
      " |    a 2D input with shape `(batch_size, input_dim)`.\n",
      " |  \n",
      " |  Output shape:\n",
      " |    N-D tensor with shape: `(batch_size, ..., units)`.\n",
      " |    For instance, for a 2D input with shape `(batch_size, input_dim)`,\n",
      " |    the output would have shape `(batch_size, units)`.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Dense\n",
      " |      tensorflow.python.keras.engine.base_layer.Layer\n",
      " |      tensorflow.python.module.module.Module\n",
      " |      tensorflow.python.training.tracking.tracking.AutoTrackable\n",
      " |      tensorflow.python.training.tracking.base.Trackable\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, units, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)\n",
      " |  \n",
      " |  build(self, input_shape)\n",
      " |      Creates the variables of the layer (optional, for subclass implementers).\n",
      " |      \n",
      " |      This is a method that implementers of subclasses of `Layer` or `Model`\n",
      " |      can override if they need a state-creation step in-between\n",
      " |      layer instantiation and layer call.\n",
      " |      \n",
      " |      This is typically used to create the weights of `Layer` subclasses.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        input_shape: Instance of `TensorShape`, or list of instances of\n",
      " |          `TensorShape` if the layer expects a list of inputs\n",
      " |          (one instance per input).\n",
      " |  \n",
      " |  call(self, inputs)\n",
      " |      This is where the layer's logic lives.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          inputs: Input tensor, or list/tuple of input tensors.\n",
      " |          **kwargs: Additional keyword arguments.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor or list/tuple of tensors.\n",
      " |  \n",
      " |  compute_output_shape(self, input_shape)\n",
      " |      Computes the output shape of the layer.\n",
      " |      \n",
      " |      If the layer has not been built, this method will call `build` on the\n",
      " |      layer. This assumes that the layer will later be used with inputs that\n",
      " |      match the input shape provided here.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          input_shape: Shape tuple (tuple of integers)\n",
      " |              or list of shape tuples (one per output tensor of the layer).\n",
      " |              Shape tuples can include None for free dimensions,\n",
      " |              instead of an integer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An input shape tuple.\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the config of the layer.\n",
      " |      \n",
      " |      A layer config is a Python dictionary (serializable)\n",
      " |      containing the configuration of a layer.\n",
      " |      The same layer can be reinstantiated later\n",
      " |      (without its trained weights) from this configuration.\n",
      " |      \n",
      " |      The config of a layer does not include connectivity\n",
      " |      information, nor the layer class name. These are handled\n",
      " |      by `Network` (one layer of abstraction above).\n",
      " |      \n",
      " |      Returns:\n",
      " |          Python dictionary.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  __call__(self, inputs, *args, **kwargs)\n",
      " |      Wraps `call`, applying pre- and post-processing steps.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: input tensor(s).\n",
      " |        *args: additional positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: additional keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |      \n",
      " |      Note:\n",
      " |        - The following optional keyword arguments are reserved for specific uses:\n",
      " |          * `training`: Boolean scalar tensor of Python boolean indicating\n",
      " |            whether the `call` is meant for training or inference.\n",
      " |          * `mask`: Boolean input mask.\n",
      " |        - If the layer's `call` method takes a `mask` argument (as some Keras\n",
      " |          layers do), its default value will be set to the mask generated\n",
      " |          for `inputs` by the previous layer (if `input` did come from\n",
      " |          a layer that generated a corresponding mask, i.e. if it came from\n",
      " |          a Keras layer with masking support.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: if the layer's `call` method returns None (an invalid value).\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Support self.foo = trackable syntax.\n",
      " |  \n",
      " |  add_loss(self, losses, inputs=None)\n",
      " |      Add loss tensor(s), potentially dependent on layer inputs.\n",
      " |      \n",
      " |      Some losses (for instance, activity regularization losses) may be dependent\n",
      " |      on the inputs passed when calling a layer. Hence, when reusing the same\n",
      " |      layer on different inputs `a` and `b`, some entries in `layer.losses` may\n",
      " |      be dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      This method can be used inside a subclassed layer or model's `call`\n",
      " |      function, in which case `losses` should be a Tensor or list of Tensors.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      class MyLayer(tf.keras.layers.Layer):\n",
      " |        def call(inputs, self):\n",
      " |          self.add_loss(tf.abs(tf.reduce_mean(inputs)), inputs=True)\n",
      " |          return inputs\n",
      " |      ```\n",
      " |      \n",
      " |      This method can also be called directly on a Functional Model during\n",
      " |      construction. In this case, any loss Tensors passed to this Model must\n",
      " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
      " |      losses become part of the model's topology and are tracked in `get_config`.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Actvity regularization.\n",
      " |      model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
      " |      ```\n",
      " |      \n",
      " |      If this is not the case for your loss (if, for example, your loss references\n",
      " |      a `Variable` of one of the model's layers), you can wrap your loss in a\n",
      " |      zero-argument lambda. These losses are not tracked as part of the model's\n",
      " |      topology since they can't be serialized.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Weight regularization.\n",
      " |      model.add_loss(lambda: tf.reduce_mean(x.kernel))\n",
      " |      ```\n",
      " |      \n",
      " |      The `get_losses_for` method allows to retrieve the losses relevant to a\n",
      " |      specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        losses: Loss tensor, or list/tuple of tensors. Rather than tensors, losses\n",
      " |          may also be zero-argument callables which create a loss tensor.\n",
      " |        inputs: Ignored when executing eagerly. If anything other than None is\n",
      " |          passed, it signals the losses are conditional on some of the layer's\n",
      " |          inputs, and thus they should only be run where these inputs are\n",
      " |          available. This is the case for activity regularization losses, for\n",
      " |          instance. If `None` is passed, the losses are assumed\n",
      " |          to be unconditional, and will apply across all dataflows of the layer\n",
      " |          (e.g. weight regularization losses).\n",
      " |  \n",
      " |  add_metric(self, value, aggregation=None, name=None)\n",
      " |      Adds metric tensor to the layer.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: Metric tensor.\n",
      " |        aggregation: Sample-wise metric reduction function. If `aggregation=None`,\n",
      " |          it indicates that the metric tensor provided has been aggregated\n",
      " |          already. eg, `bin_acc = BinaryAccuracy(name='acc')` followed by\n",
      " |          `model.add_metric(bin_acc(y_true, y_pred))`. If aggregation='mean', the\n",
      " |          given metric tensor will be sample-wise reduced using `mean` function.\n",
      " |          eg, `model.add_metric(tf.reduce_sum(outputs), name='output_mean',\n",
      " |          aggregation='mean')`.\n",
      " |        name: String metric name.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If `aggregation` is anything other than None or `mean`.\n",
      " |  \n",
      " |  add_update(self, updates, inputs=None)\n",
      " |      Add update op(s), potentially dependent on layer inputs. (deprecated arguments)\n",
      " |      \n",
      " |      Warning: SOME ARGUMENTS ARE DEPRECATED: `(inputs)`. They will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      `inputs` is now automatically inferred\n",
      " |      \n",
      " |      Weight updates (for instance, the updates of the moving mean and variance\n",
      " |      in a BatchNormalization layer) may be dependent on the inputs passed\n",
      " |      when calling a layer. Hence, when reusing the same layer on\n",
      " |      different inputs `a` and `b`, some entries in `layer.updates` may be\n",
      " |      dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      The `get_updates_for` method allows to retrieve the updates relevant to a\n",
      " |      specific set of inputs.\n",
      " |      \n",
      " |      This call is ignored when eager execution is enabled (in that case, variable\n",
      " |      updates are run on the fly and thus do not need to be tracked for later\n",
      " |      execution).\n",
      " |      \n",
      " |      Arguments:\n",
      " |        updates: Update op, or list/tuple of update ops, or zero-arg callable\n",
      " |          that returns an update op. A zero-arg callable should be passed in\n",
      " |          order to disable running the updates by setting `trainable=False`\n",
      " |          on this Layer, when executing in Eager mode.\n",
      " |        inputs: Deprecated, will be automatically inferred.\n",
      " |  \n",
      " |  add_variable(self, *args, **kwargs)\n",
      " |      Deprecated, do NOT use! Alias for `add_weight`. (deprecated)\n",
      " |      \n",
      " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      Please use `layer.add_weight` method instead.\n",
      " |  \n",
      " |  add_weight(self, name=None, shape=None, dtype=None, initializer=None, regularizer=None, trainable=None, constraint=None, partitioner=None, use_resource=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregation.NONE: 0>, **kwargs)\n",
      " |      Adds a new variable to the layer.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        name: Variable name.\n",
      " |        shape: Variable shape. Defaults to scalar if unspecified.\n",
      " |        dtype: The type of the variable. Defaults to `self.dtype` or `float32`.\n",
      " |        initializer: Initializer instance (callable).\n",
      " |        regularizer: Regularizer instance (callable).\n",
      " |        trainable: Boolean, whether the variable should be part of the layer's\n",
      " |          \"trainable_variables\" (e.g. variables, biases)\n",
      " |          or \"non_trainable_variables\" (e.g. BatchNorm mean and variance).\n",
      " |          Note that `trainable` cannot be `True` if `synchronization`\n",
      " |          is set to `ON_READ`.\n",
      " |        constraint: Constraint instance (callable).\n",
      " |        partitioner: Partitioner to be passed to the `Trackable` API.\n",
      " |        use_resource: Whether to use `ResourceVariable`.\n",
      " |        synchronization: Indicates when a distributed a variable will be\n",
      " |          aggregated. Accepted values are constants defined in the class\n",
      " |          `tf.VariableSynchronization`. By default the synchronization is set to\n",
      " |          `AUTO` and the current `DistributionStrategy` chooses\n",
      " |          when to synchronize. If `synchronization` is set to `ON_READ`,\n",
      " |          `trainable` must not be set to `True`.\n",
      " |        aggregation: Indicates how a distributed variable will be aggregated.\n",
      " |          Accepted values are constants defined in the class\n",
      " |          `tf.VariableAggregation`.\n",
      " |        **kwargs: Additional keyword arguments. Accepted values are `getter` and\n",
      " |          `collections`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The created variable. Usually either a `Variable` or `ResourceVariable`\n",
      " |        instance. If `partitioner` is not `None`, a `PartitionedVariable`\n",
      " |        instance is returned.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called with partitioned variable regularization and\n",
      " |          eager execution is enabled.\n",
      " |        ValueError: When giving unsupported dtype and no initializer or when\n",
      " |          trainable has been set to True with synchronization set as `ON_READ`.\n",
      " |  \n",
      " |  apply(self, inputs, *args, **kwargs)\n",
      " |      Deprecated, do NOT use! (deprecated)\n",
      " |      \n",
      " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      Please use `layer.__call__` method instead.\n",
      " |      \n",
      " |      This is an alias of `self.__call__`.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor(s).\n",
      " |        *args: additional positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: additional keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |  \n",
      " |  compute_mask(self, inputs, mask=None)\n",
      " |      Computes an output mask tensor.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          inputs: Tensor or list of tensors.\n",
      " |          mask: Tensor or list of tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |          None or a tensor (or list of tensors,\n",
      " |              one per output tensor of the layer).\n",
      " |  \n",
      " |  compute_output_signature(self, input_signature)\n",
      " |      Compute the output tensor signature of the layer based on the inputs.\n",
      " |      \n",
      " |      Unlike a TensorShape object, a TensorSpec object contains both shape\n",
      " |      and dtype information for a tensor. This method allows layers to provide\n",
      " |      output dtype information if it is different from the input dtype.\n",
      " |      For any layer that doesn't implement this function,\n",
      " |      the framework will fall back to use `compute_output_shape`, and will\n",
      " |      assume that the output dtype matches the input dtype.\n",
      " |      \n",
      " |      Args:\n",
      " |        input_signature: Single TensorSpec or nested structure of TensorSpec\n",
      " |          objects, describing a candidate input for the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Single TensorSpec or nested structure of TensorSpec objects, describing\n",
      " |          how the layer would transform the provided input.\n",
      " |      \n",
      " |      Raises:\n",
      " |        TypeError: If input_signature contains a non-TensorSpec object.\n",
      " |  \n",
      " |  count_params(self)\n",
      " |      Count the total number of scalars composing the weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An integer count.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: if the layer isn't yet built\n",
      " |            (in which case its weights aren't yet defined).\n",
      " |  \n",
      " |  get_input_at(self, node_index)\n",
      " |      Retrieves the input tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_input_mask_at(self, node_index)\n",
      " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_shape_at(self, node_index)\n",
      " |      Retrieves the input shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_losses_for(self, inputs)\n",
      " |      Retrieves losses relevant to a specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor or list/tuple of input tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |        List of loss tensors of the layer that depend on `inputs`.\n",
      " |  \n",
      " |  get_output_at(self, node_index)\n",
      " |      Retrieves the output tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_output_mask_at(self, node_index)\n",
      " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_shape_at(self, node_index)\n",
      " |      Retrieves the output shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_updates_for(self, inputs)\n",
      " |      Retrieves updates relevant to a specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor or list/tuple of input tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |        List of update ops of the layer that depend on `inputs`.\n",
      " |  \n",
      " |  get_weights(self)\n",
      " |      Returns the current weights of the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Weights values as a list of numpy arrays.\n",
      " |  \n",
      " |  set_weights(self, weights)\n",
      " |      Sets the weights of the layer, from Numpy arrays.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          weights: a list of Numpy arrays. The number\n",
      " |              of arrays and their shape must match\n",
      " |              number of the dimensions of the weights\n",
      " |              of the layer (i.e. it should match the\n",
      " |              output of `get_weights`).\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: If the provided weights list does not match the\n",
      " |              layer's specifications.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  from_config(config) from builtins.type\n",
      " |      Creates a layer from its config.\n",
      " |      \n",
      " |      This method is the reverse of `get_config`,\n",
      " |      capable of instantiating the same layer from the config\n",
      " |      dictionary. It does not handle layer connectivity\n",
      " |      (handled by Network), nor weights (handled by `set_weights`).\n",
      " |      \n",
      " |      Arguments:\n",
      " |          config: A Python dictionary, typically the\n",
      " |              output of get_config.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A layer instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  activity_regularizer\n",
      " |      Optional regularizer function for the output of this layer.\n",
      " |  \n",
      " |  dtype\n",
      " |  \n",
      " |  dynamic\n",
      " |  \n",
      " |  inbound_nodes\n",
      " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      " |  \n",
      " |  input\n",
      " |      Retrieves the input tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input tensor or list of input tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |        AttributeError: If no inbound nodes are found.\n",
      " |  \n",
      " |  input_mask\n",
      " |      Retrieves the input mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input mask tensor (potentially None) or list of input\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_shape\n",
      " |      Retrieves the input shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer, or if all inputs\n",
      " |      have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per input tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined input_shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  input_spec\n",
      " |  \n",
      " |  losses\n",
      " |      Losses which are associated with this `Layer`.\n",
      " |      \n",
      " |      Variable regularization tensors are created when this property is accessed,\n",
      " |      so it is eager safe: accessing `losses` under a `tf.GradientTape` will\n",
      " |      propagate gradients back to the corresponding variables.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of tensors.\n",
      " |  \n",
      " |  metrics\n",
      " |  \n",
      " |  name\n",
      " |      Returns the name of this module as passed or determined in the ctor.\n",
      " |      \n",
      " |      NOTE: This is not the same as the `self.name_scope.name` which includes\n",
      " |      parent module names.\n",
      " |  \n",
      " |  non_trainable_variables\n",
      " |  \n",
      " |  non_trainable_weights\n",
      " |  \n",
      " |  outbound_nodes\n",
      " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      " |  \n",
      " |  output\n",
      " |      Retrieves the output tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one output,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor or list of output tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        AttributeError: if the layer is connected to more than one incoming\n",
      " |          layers.\n",
      " |        RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  output_mask\n",
      " |      Retrieves the output mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output mask tensor (potentially None) or list of output\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_shape\n",
      " |      Retrieves the output shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has one output,\n",
      " |      or if all outputs have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per output tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined output shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  trainable\n",
      " |  \n",
      " |  trainable_variables\n",
      " |      Sequence of variables owned by this module and it's submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  trainable_weights\n",
      " |  \n",
      " |  updates\n",
      " |  \n",
      " |  variables\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Alias of `self.weights`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  weights\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  with_name_scope(method) from builtins.type\n",
      " |      Decorator to automatically enter the module name scope.\n",
      " |      \n",
      " |      ```\n",
      " |      class MyModule(tf.Module):\n",
      " |        @tf.Module.with_name_scope\n",
      " |        def __call__(self, x):\n",
      " |          if not hasattr(self, 'w'):\n",
      " |            self.w = tf.Variable(tf.random.normal([x.shape[1], 64]))\n",
      " |          return tf.matmul(x, self.w)\n",
      " |      ```\n",
      " |      \n",
      " |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
      " |      names included the module name:\n",
      " |      \n",
      " |      ```\n",
      " |      mod = MyModule()\n",
      " |      mod(tf.ones([8, 32]))\n",
      " |      # ==> <tf.Tensor: ...>\n",
      " |      mod.w\n",
      " |      # ==> <tf.Variable ...'my_module/w:0'>\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        method: The method to wrap.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The original method wrapped such that it enters the module's name scope.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  name_scope\n",
      " |      Returns a `tf.name_scope` instance for this class.\n",
      " |  \n",
      " |  submodules\n",
      " |      Sequence of all sub-modules.\n",
      " |      \n",
      " |      Submodules are modules which are properties of this module, or found as\n",
      " |      properties of modules which are properties of this module (and so on).\n",
      " |      \n",
      " |      ```\n",
      " |      a = tf.Module()\n",
      " |      b = tf.Module()\n",
      " |      c = tf.Module()\n",
      " |      a.b = b\n",
      " |      b.c = c\n",
      " |      assert list(a.submodules) == [b, c]\n",
      " |      assert list(b.submodules) == [c]\n",
      " |      assert list(c.submodules) == []\n",
      " |      ```\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of all submodules.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.training.tracking.base.Trackable:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(keras.layers.Dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a28af4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 11s 177us/sample - loss: 0.4903 - acc: 0.8773 - loss: 0.4925 - acc: 0.87\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 11s 182us/sample - loss: 0.3061 - acc: 0.9159 - loss: 0.3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x27d3f1cd148>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = keras.Sequential([\n",
    "    keras.layers.Dense(10, activation = 'sigmoid'), # I didn't have to put input_shape as an argument. It works without it\n",
    "])\n",
    "\n",
    "model2.compile(optimizer = 'adam', \n",
    "               loss = 'sparse_categorical_crossentropy', \n",
    "               metrics = ['accuracy'])\n",
    "\n",
    "model2.fit(X_train_flattened, y_train, epochs = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "19e9c332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we can see, scaling gives better accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f728c9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 124us/sample - loss: 0.2838 - acc: 0.9213\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.28378038030862807, 0.9213]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(X_test_flattened, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9d420526",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_2 = model2.predict(X_test_flattened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "591b8773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.1870265e-04, 0.0000000e+00, 2.0775199e-04, 4.9988925e-03,\n",
       "       6.2584877e-06, 1.3968349e-04, 1.7881393e-07, 7.5092858e-01,\n",
       "       2.1228194e-04, 2.0318627e-03], dtype=float32)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "aa64a9fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x27d3ac56b48>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "43126d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_test_2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0843804b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ok, it works properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0ad33b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "88b86e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted_labels = [np.argmax(i) for i in y_test_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "741e0e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 9,\n",
       " 6,\n",
       " 9,\n",
       " 0,\n",
       " 6,\n",
       " 9,\n",
       " 0,\n",
       " 1,\n",
       " 5,\n",
       " 9,\n",
       " 7,\n",
       " 3,\n",
       " 4,\n",
       " 9,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 0,\n",
       " 7,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 7,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 9,\n",
       " 5,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 2,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 2,\n",
       " 9,\n",
       " 1,\n",
       " 7,\n",
       " 3,\n",
       " 2,\n",
       " 9,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 2,\n",
       " 7,\n",
       " 8,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 9,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 7,\n",
       " 6,\n",
       " 9,\n",
       " 6,\n",
       " 0,\n",
       " 5,\n",
       " 4,\n",
       " 9,\n",
       " 9,\n",
       " 2,\n",
       " 1,\n",
       " 9,\n",
       " 4,\n",
       " 8,\n",
       " 7,\n",
       " 3,\n",
       " 9,\n",
       " 7,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 9,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 7,\n",
       " 6,\n",
       " 4,\n",
       " 9,\n",
       " 0,\n",
       " 5,\n",
       " 8,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 7,\n",
       " 8,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 7,\n",
       " 3,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 8,\n",
       " 2,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 6,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 7,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 8,\n",
       " 5,\n",
       " 0,\n",
       " 8,\n",
       " 9,\n",
       " 2,\n",
       " 5,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 8,\n",
       " 1,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 9,\n",
       " 5,\n",
       " 2,\n",
       " 9,\n",
       " 4,\n",
       " 7,\n",
       " 9,\n",
       " 3,\n",
       " 9,\n",
       " 0,\n",
       " 3,\n",
       " 6,\n",
       " 5,\n",
       " 5,\n",
       " 7,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 1,\n",
       " 7,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 9,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 2,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 9,\n",
       " 5,\n",
       " 7,\n",
       " 7,\n",
       " 2,\n",
       " 8,\n",
       " 2,\n",
       " 0,\n",
       " 8,\n",
       " 5,\n",
       " 7,\n",
       " 7,\n",
       " 9,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 8,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 4,\n",
       " 1,\n",
       " 8,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 9,\n",
       " 7,\n",
       " 5,\n",
       " 9,\n",
       " 2,\n",
       " 6,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 9,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 9,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 1,\n",
       " 9,\n",
       " 6,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 7,\n",
       " 7,\n",
       " 9,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 9,\n",
       " 7,\n",
       " 8,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 8,\n",
       " 1,\n",
       " 0,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 0,\n",
       " 6,\n",
       " 1,\n",
       " 8,\n",
       " 5,\n",
       " 1,\n",
       " 7,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 7,\n",
       " 2,\n",
       " 5,\n",
       " 0,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 3,\n",
       " 7,\n",
       " 2,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 7,\n",
       " 3,\n",
       " 7,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 1,\n",
       " 9,\n",
       " 2,\n",
       " 8,\n",
       " 6,\n",
       " 1,\n",
       " 9,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 7,\n",
       " 7,\n",
       " 5,\n",
       " 7,\n",
       " 9,\n",
       " 7,\n",
       " 1,\n",
       " 9,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 9,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 9,\n",
       " 1,\n",
       " 4,\n",
       " 8,\n",
       " 1,\n",
       " 8,\n",
       " 4,\n",
       " 5,\n",
       " 9,\n",
       " 7,\n",
       " 8,\n",
       " 3,\n",
       " 7,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 8,\n",
       " 0,\n",
       " 6,\n",
       " 4,\n",
       " 8,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 9,\n",
       " 1,\n",
       " 2,\n",
       " 6,\n",
       " 8,\n",
       " 0,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 2,\n",
       " 9,\n",
       " 5,\n",
       " 8,\n",
       " 9,\n",
       " 6,\n",
       " 1,\n",
       " 8,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 8,\n",
       " 3,\n",
       " 1,\n",
       " 9,\n",
       " 7,\n",
       " 5,\n",
       " 4,\n",
       " 0,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 0,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 4,\n",
       " 0,\n",
       " 6,\n",
       " 3,\n",
       " 9,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 6,\n",
       " 5,\n",
       " 7,\n",
       " 8,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 2,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 8,\n",
       " 9,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 8,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 8,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 8,\n",
       " 3,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 0,\n",
       " 8,\n",
       " 7,\n",
       " 4,\n",
       " 4,\n",
       " 7,\n",
       " 9,\n",
       " 6,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 9,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 8,\n",
       " 3,\n",
       " 3,\n",
       " 9,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 1,\n",
       " 7,\n",
       " 0,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 9,\n",
       " 6,\n",
       " 3,\n",
       " 8,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 6,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 5,\n",
       " 9,\n",
       " 8,\n",
       " 6,\n",
       " 0,\n",
       " 2,\n",
       " 6,\n",
       " 0,\n",
       " 2,\n",
       " 8,\n",
       " 3,\n",
       " 1,\n",
       " 9,\n",
       " 7,\n",
       " 5,\n",
       " 8,\n",
       " 0,\n",
       " 8,\n",
       " 4,\n",
       " 6,\n",
       " 2,\n",
       " 6,\n",
       " 7,\n",
       " 4,\n",
       " 9,\n",
       " 6,\n",
       " 9,\n",
       " 8,\n",
       " 2,\n",
       " 2,\n",
       " 9,\n",
       " 2,\n",
       " 7,\n",
       " 3,\n",
       " 5,\n",
       " 9,\n",
       " 1,\n",
       " 8,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 8,\n",
       " 0,\n",
       " 3,\n",
       " 7,\n",
       " 9,\n",
       " 4,\n",
       " 0,\n",
       " 9,\n",
       " 1,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 5,\n",
       " 1,\n",
       " 7,\n",
       " 3,\n",
       " 9,\n",
       " 7,\n",
       " 6,\n",
       " 9,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 8,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 9,\n",
       " 2,\n",
       " 4,\n",
       " 7,\n",
       " 8,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 7,\n",
       " 7,\n",
       " 0,\n",
       " 7,\n",
       " 9,\n",
       " 9,\n",
       " 4,\n",
       " 8,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 0,\n",
       " 8,\n",
       " 2,\n",
       " 1,\n",
       " 6,\n",
       " 8,\n",
       " 4,\n",
       " 8,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 6,\n",
       " 1,\n",
       " 7,\n",
       " 3,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 2,\n",
       " 6,\n",
       " 9,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 6,\n",
       " 8,\n",
       " 5,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 6,\n",
       " 2,\n",
       " 1,\n",
       " 7,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 4,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 4,\n",
       " 7,\n",
       " 1,\n",
       " 9,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 8,\n",
       " 9,\n",
       " 4,\n",
       " 1,\n",
       " 9,\n",
       " 3,\n",
       " 8,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 8,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 7,\n",
       " 3,\n",
       " 5,\n",
       " 9,\n",
       " 6,\n",
       " 3,\n",
       " 2,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 0,\n",
       " 7,\n",
       " 2,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 7,\n",
       " 9,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 7,\n",
       " 7,\n",
       " 4,\n",
       " 7,\n",
       " 0,\n",
       " 7,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 7,\n",
       " 7,\n",
       " 0,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 9,\n",
       " 2,\n",
       " 8,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 6,\n",
       " 0,\n",
       " 8,\n",
       " 2,\n",
       " 9,\n",
       " 2,\n",
       " 8,\n",
       " 2,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 9,\n",
       " 9,\n",
       " 3,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 9,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 2,\n",
       " 8,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 0,\n",
       " 2,\n",
       " 9,\n",
       " 1,\n",
       " 4,\n",
       " 7,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 4,\n",
       " 7,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 7,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 9,\n",
       " 1,\n",
       " 7,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 8,\n",
       " 6,\n",
       " 5,\n",
       " 0,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 2,\n",
       " 7,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 6,\n",
       " 4,\n",
       " 9,\n",
       " 5,\n",
       " 6,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 9,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 0,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 1,\n",
       " 2,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 9,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 8,\n",
       " 9,\n",
       " ...]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "de132085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_module_wrapper',\n",
       " '_sys',\n",
       " 'abs',\n",
       " 'accumulate_n',\n",
       " 'acos',\n",
       " 'acosh',\n",
       " 'add',\n",
       " 'add_n',\n",
       " 'angle',\n",
       " 'argmax',\n",
       " 'argmin',\n",
       " 'asin',\n",
       " 'asinh',\n",
       " 'atan',\n",
       " 'atan2',\n",
       " 'atanh',\n",
       " 'bessel_i0',\n",
       " 'bessel_i0e',\n",
       " 'bessel_i1',\n",
       " 'bessel_i1e',\n",
       " 'betainc',\n",
       " 'bincount',\n",
       " 'ceil',\n",
       " 'confusion_matrix',\n",
       " 'conj',\n",
       " 'cos',\n",
       " 'cosh',\n",
       " 'count_nonzero',\n",
       " 'cumprod',\n",
       " 'cumsum',\n",
       " 'cumulative_logsumexp',\n",
       " 'digamma',\n",
       " 'divide',\n",
       " 'divide_no_nan',\n",
       " 'equal',\n",
       " 'erf',\n",
       " 'erfc',\n",
       " 'exp',\n",
       " 'expm1',\n",
       " 'floor',\n",
       " 'floordiv',\n",
       " 'floormod',\n",
       " 'greater',\n",
       " 'greater_equal',\n",
       " 'igamma',\n",
       " 'igammac',\n",
       " 'imag',\n",
       " 'in_top_k',\n",
       " 'invert_permutation',\n",
       " 'is_finite',\n",
       " 'is_inf',\n",
       " 'is_nan',\n",
       " 'is_non_decreasing',\n",
       " 'is_strictly_increasing',\n",
       " 'l2_normalize',\n",
       " 'lbeta',\n",
       " 'less',\n",
       " 'less_equal',\n",
       " 'lgamma',\n",
       " 'log',\n",
       " 'log1p',\n",
       " 'log_sigmoid',\n",
       " 'log_softmax',\n",
       " 'logical_and',\n",
       " 'logical_not',\n",
       " 'logical_or',\n",
       " 'logical_xor',\n",
       " 'maximum',\n",
       " 'minimum',\n",
       " 'mod',\n",
       " 'multiply',\n",
       " 'multiply_no_nan',\n",
       " 'negative',\n",
       " 'nextafter',\n",
       " 'not_equal',\n",
       " 'polygamma',\n",
       " 'polyval',\n",
       " 'pow',\n",
       " 'real',\n",
       " 'reciprocal',\n",
       " 'reciprocal_no_nan',\n",
       " 'reduce_all',\n",
       " 'reduce_any',\n",
       " 'reduce_euclidean_norm',\n",
       " 'reduce_logsumexp',\n",
       " 'reduce_max',\n",
       " 'reduce_mean',\n",
       " 'reduce_min',\n",
       " 'reduce_prod',\n",
       " 'reduce_std',\n",
       " 'reduce_sum',\n",
       " 'reduce_variance',\n",
       " 'rint',\n",
       " 'round',\n",
       " 'rsqrt',\n",
       " 'scalar_mul',\n",
       " 'segment_max',\n",
       " 'segment_mean',\n",
       " 'segment_min',\n",
       " 'segment_prod',\n",
       " 'segment_sum',\n",
       " 'sigmoid',\n",
       " 'sign',\n",
       " 'sin',\n",
       " 'sinh',\n",
       " 'softmax',\n",
       " 'softplus',\n",
       " 'softsign',\n",
       " 'sqrt',\n",
       " 'square',\n",
       " 'squared_difference',\n",
       " 'subtract',\n",
       " 'tan',\n",
       " 'tanh',\n",
       " 'top_k',\n",
       " 'truediv',\n",
       " 'unsorted_segment_max',\n",
       " 'unsorted_segment_mean',\n",
       " 'unsorted_segment_min',\n",
       " 'unsorted_segment_prod',\n",
       " 'unsorted_segment_sqrt_n',\n",
       " 'unsorted_segment_sum',\n",
       " 'xdivy',\n",
       " 'xlogy',\n",
       " 'zero_fraction',\n",
       " 'zeta']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(tf.math)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b6ece0ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function confusion_matrix_v1 in module tensorflow.python.ops.confusion_matrix:\n",
      "\n",
      "confusion_matrix_v1(labels, predictions, num_classes=None, dtype=tf.int32, name=None, weights=None)\n",
      "    Computes the confusion matrix from predictions and labels.\n",
      "    \n",
      "    The matrix columns represent the prediction labels and the rows represent the\n",
      "    real labels. The confusion matrix is always a 2-D array of shape `[n, n]`,\n",
      "    where `n` is the number of valid labels for a given classification task. Both\n",
      "    prediction and labels must be 1-D arrays of the same shape in order for this\n",
      "    function to work.\n",
      "    \n",
      "    If `num_classes` is `None`, then `num_classes` will be set to one plus the\n",
      "    maximum value in either predictions or labels. Class labels are expected to\n",
      "    start at 0. For example, if `num_classes` is 3, then the possible labels\n",
      "    would be `[0, 1, 2]`.\n",
      "    \n",
      "    If `weights` is not `None`, then each prediction contributes its\n",
      "    corresponding weight to the total value of the confusion matrix cell.\n",
      "    \n",
      "    For example:\n",
      "    \n",
      "    ```python\n",
      "      tf.math.confusion_matrix([1, 2, 4], [2, 2, 4]) ==>\n",
      "          [[0 0 0 0 0]\n",
      "           [0 0 1 0 0]\n",
      "           [0 0 1 0 0]\n",
      "           [0 0 0 0 0]\n",
      "           [0 0 0 0 1]]\n",
      "    ```\n",
      "    \n",
      "    Note that the possible labels are assumed to be `[0, 1, 2, 3, 4]`,\n",
      "    resulting in a 5x5 confusion matrix.\n",
      "    \n",
      "    Args:\n",
      "      labels: 1-D `Tensor` of real labels for the classification task.\n",
      "      predictions: 1-D `Tensor` of predictions for a given classification.\n",
      "      num_classes: The possible number of labels the classification task can have.\n",
      "        If this value is not provided, it will be calculated using both\n",
      "        predictions and labels array.\n",
      "      dtype: Data type of the confusion matrix.\n",
      "      name: Scope name.\n",
      "      weights: An optional `Tensor` whose shape matches `predictions`.\n",
      "    \n",
      "    Returns:\n",
      "      A `Tensor` of type `dtype` with shape `[n, n]` representing the confusion\n",
      "      matrix, where `n` is the number of possible labels in the classification\n",
      "      task.\n",
      "    \n",
      "    Raises:\n",
      "      ValueError: If both predictions and labels are not 1-D vectors and have\n",
      "        mismatched shapes, or if `weights` is not `None` and its shape doesn't\n",
      "        match `predictions`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.math.confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d782ad78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b085e6a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 9,\n",
       " 6,\n",
       " 9,\n",
       " 0,\n",
       " 6,\n",
       " 9,\n",
       " 0,\n",
       " 1,\n",
       " 5,\n",
       " 9,\n",
       " 7,\n",
       " 3,\n",
       " 4,\n",
       " 9,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 0,\n",
       " 7,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 7,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 9,\n",
       " 5,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 2,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 2,\n",
       " 9,\n",
       " 1,\n",
       " 7,\n",
       " 3,\n",
       " 2,\n",
       " 9,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 2,\n",
       " 7,\n",
       " 8,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 9,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 7,\n",
       " 6,\n",
       " 9,\n",
       " 6,\n",
       " 0,\n",
       " 5,\n",
       " 4,\n",
       " 9,\n",
       " 9,\n",
       " 2,\n",
       " 1,\n",
       " 9,\n",
       " 4,\n",
       " 8,\n",
       " 7,\n",
       " 3,\n",
       " 9,\n",
       " 7,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 9,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 7,\n",
       " 6,\n",
       " 4,\n",
       " 9,\n",
       " 0,\n",
       " 5,\n",
       " 8,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 7,\n",
       " 8,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 7,\n",
       " 3,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 8,\n",
       " 2,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 6,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 7,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 8,\n",
       " 5,\n",
       " 0,\n",
       " 8,\n",
       " 9,\n",
       " 2,\n",
       " 5,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 8,\n",
       " 1,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 9,\n",
       " 5,\n",
       " 2,\n",
       " 9,\n",
       " 4,\n",
       " 7,\n",
       " 9,\n",
       " 3,\n",
       " 9,\n",
       " 0,\n",
       " 3,\n",
       " 6,\n",
       " 5,\n",
       " 5,\n",
       " 7,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 1,\n",
       " 7,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 9,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 2,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 9,\n",
       " 5,\n",
       " 7,\n",
       " 7,\n",
       " 2,\n",
       " 8,\n",
       " 2,\n",
       " 0,\n",
       " 8,\n",
       " 5,\n",
       " 7,\n",
       " 7,\n",
       " 9,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 8,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 9,\n",
       " 9,\n",
       " 4,\n",
       " 1,\n",
       " 8,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 9,\n",
       " 7,\n",
       " 5,\n",
       " 9,\n",
       " 2,\n",
       " 6,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 9,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 9,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 1,\n",
       " 9,\n",
       " 6,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 7,\n",
       " 7,\n",
       " 9,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 9,\n",
       " 7,\n",
       " 8,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 8,\n",
       " 1,\n",
       " 0,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 0,\n",
       " 6,\n",
       " 1,\n",
       " 8,\n",
       " 5,\n",
       " 1,\n",
       " 7,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 7,\n",
       " 2,\n",
       " 5,\n",
       " 0,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 3,\n",
       " 7,\n",
       " 2,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 7,\n",
       " 3,\n",
       " 7,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 1,\n",
       " 9,\n",
       " 2,\n",
       " 8,\n",
       " 6,\n",
       " 1,\n",
       " 9,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 8,\n",
       " 3,\n",
       " 8,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 7,\n",
       " 7,\n",
       " 5,\n",
       " 7,\n",
       " 9,\n",
       " 7,\n",
       " 1,\n",
       " 9,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 9,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 9,\n",
       " 1,\n",
       " 4,\n",
       " 8,\n",
       " 1,\n",
       " 8,\n",
       " 4,\n",
       " 5,\n",
       " 9,\n",
       " 7,\n",
       " 8,\n",
       " 3,\n",
       " 7,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 8,\n",
       " 0,\n",
       " 6,\n",
       " 4,\n",
       " 8,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 9,\n",
       " 1,\n",
       " 2,\n",
       " 6,\n",
       " 8,\n",
       " 0,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 2,\n",
       " 9,\n",
       " 5,\n",
       " 8,\n",
       " 9,\n",
       " 6,\n",
       " 1,\n",
       " 8,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 8,\n",
       " 3,\n",
       " 1,\n",
       " 9,\n",
       " 7,\n",
       " 5,\n",
       " 4,\n",
       " 0,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 0,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 4,\n",
       " 0,\n",
       " 6,\n",
       " 3,\n",
       " 9,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 6,\n",
       " 5,\n",
       " 7,\n",
       " 8,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 2,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 8,\n",
       " 9,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 8,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 8,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 8,\n",
       " 3,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 0,\n",
       " 8,\n",
       " 7,\n",
       " 4,\n",
       " 4,\n",
       " 7,\n",
       " 9,\n",
       " 6,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 9,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 8,\n",
       " 3,\n",
       " 3,\n",
       " 9,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 1,\n",
       " 7,\n",
       " 0,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 9,\n",
       " 6,\n",
       " 3,\n",
       " 8,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 6,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 5,\n",
       " 9,\n",
       " 8,\n",
       " 6,\n",
       " 0,\n",
       " 2,\n",
       " 6,\n",
       " 0,\n",
       " 2,\n",
       " 8,\n",
       " 3,\n",
       " 1,\n",
       " 9,\n",
       " 7,\n",
       " 5,\n",
       " 8,\n",
       " 0,\n",
       " 8,\n",
       " 4,\n",
       " 6,\n",
       " 2,\n",
       " 6,\n",
       " 7,\n",
       " 4,\n",
       " 9,\n",
       " 6,\n",
       " 9,\n",
       " 8,\n",
       " 2,\n",
       " 2,\n",
       " 9,\n",
       " 2,\n",
       " 7,\n",
       " 3,\n",
       " 5,\n",
       " 9,\n",
       " 1,\n",
       " 8,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 8,\n",
       " 0,\n",
       " 3,\n",
       " 7,\n",
       " 9,\n",
       " 4,\n",
       " 0,\n",
       " 9,\n",
       " 1,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 5,\n",
       " 1,\n",
       " 7,\n",
       " 3,\n",
       " 9,\n",
       " 7,\n",
       " 6,\n",
       " 9,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 8,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 9,\n",
       " 2,\n",
       " 4,\n",
       " 7,\n",
       " 8,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 7,\n",
       " 7,\n",
       " 0,\n",
       " 7,\n",
       " 9,\n",
       " 9,\n",
       " 4,\n",
       " 8,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 0,\n",
       " 8,\n",
       " 2,\n",
       " 1,\n",
       " 6,\n",
       " 8,\n",
       " 4,\n",
       " 8,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 6,\n",
       " 1,\n",
       " 7,\n",
       " 3,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 2,\n",
       " 6,\n",
       " 9,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 6,\n",
       " 8,\n",
       " 5,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 6,\n",
       " 2,\n",
       " 1,\n",
       " 7,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 4,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 4,\n",
       " 7,\n",
       " 1,\n",
       " 9,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 8,\n",
       " 9,\n",
       " 4,\n",
       " 1,\n",
       " 9,\n",
       " 3,\n",
       " 8,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 8,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 7,\n",
       " 3,\n",
       " 5,\n",
       " 9,\n",
       " 6,\n",
       " 3,\n",
       " 2,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 0,\n",
       " 7,\n",
       " 2,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 7,\n",
       " 9,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 7,\n",
       " 7,\n",
       " 4,\n",
       " 7,\n",
       " 0,\n",
       " 7,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 7,\n",
       " 7,\n",
       " 0,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 9,\n",
       " 2,\n",
       " 8,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 6,\n",
       " 0,\n",
       " 8,\n",
       " 2,\n",
       " 9,\n",
       " 2,\n",
       " 8,\n",
       " 2,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 9,\n",
       " 9,\n",
       " 3,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 9,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 2,\n",
       " 8,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 0,\n",
       " 2,\n",
       " 9,\n",
       " 1,\n",
       " 4,\n",
       " 7,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 4,\n",
       " 7,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 7,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 9,\n",
       " 1,\n",
       " 7,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 8,\n",
       " 6,\n",
       " 5,\n",
       " 0,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 2,\n",
       " 7,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 6,\n",
       " 4,\n",
       " 9,\n",
       " 5,\n",
       " 6,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 9,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 0,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 1,\n",
       " 2,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 9,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 8,\n",
       " 9,\n",
       " ...]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "74fcbebe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cm = tf.math.confusion_matrix(labels = y_test, predictions = y_predicted_labels)\n",
    "# Uruchomienie sesji obliczeniowej\n",
    "with tf.Session() as sess:\n",
    "    # Wykonanie obliczeń dla tensora symbolicznego\n",
    "    cm_array = sess.run(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "5ab22c70",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(95.72222222222221, 0.5, 'Truth')"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.heatmap(cm_array, annot = True, fmt='d' )\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Truth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "188f40fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will check if code from git works:\n",
    "# I've checked and there's also same warning as was above. So everything is ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "1021e09a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 15s 255us/sample - loss: 0.2916 - acc: 0.9182\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 10s 175us/sample - loss: 0.1385 - acc: 0.9591\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x27d38cae808>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = keras.Sequential([\n",
    "    keras.layers.Dense(100, activation = 'relu'), # I didn't have to put input_shape as an argument. It works without it\n",
    "    keras.layers.Dense(10, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "model3.compile(optimizer = 'adam', \n",
    "               loss = 'sparse_categorical_crossentropy', \n",
    "               metrics = ['accuracy'])\n",
    "\n",
    "model3.fit(X_train_flattened, y_train, epochs = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "5ea4c56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As I can see. I've received better results with hidden layer than before without it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "33f0680d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 184us/sample - loss: 0.1173 - acc: 0.9655\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.11730524017829448, 0.9655]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.evaluate(X_test_flattened, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "1a5cb917",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(95.72222222222221, 0.5, 'Truth')"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_test_3 = model3.predict(X_test_flattened)\n",
    "y_predicted_labels_2 = [np.argmax(i) for i in y_test_3]\n",
    "\n",
    "cm2 = tf.math.confusion_matrix(labels = y_test, predictions = y_predicted_labels_2)\n",
    "# Uruchomienie sesji obliczeniowej\n",
    "with tf.Session() as sess:\n",
    "    # Wykonanie obliczeń dla tensora symbolicznego\n",
    "    cm2_array = sess.run(cm2)\n",
    "    \n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(10,7))\n",
    "sns.heatmap(cm2_array, annot = True, fmt='d' )\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Truth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d83e7f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For flatten function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ed0caf6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Flatten in module tensorflow.python.keras.layers.core:\n",
      "\n",
      "class Flatten(tensorflow.python.keras.engine.base_layer.Layer)\n",
      " |  Flatten(data_format=None, **kwargs)\n",
      " |  \n",
      " |  Flattens the input. Does not affect the batch size.\n",
      " |  \n",
      " |  If inputs are shaped `(batch,)` without a channel dimension, then flattening\n",
      " |  adds an extra channel dimension and output shapes are `(batch, 1)`.\n",
      " |  \n",
      " |  Arguments:\n",
      " |    data_format: A string,\n",
      " |      one of `channels_last` (default) or `channels_first`.\n",
      " |      The ordering of the dimensions in the inputs.\n",
      " |      `channels_last` corresponds to inputs with shape\n",
      " |      `(batch, ..., channels)` while `channels_first` corresponds to\n",
      " |      inputs with shape `(batch, channels, ...)`.\n",
      " |      It defaults to the `image_data_format` value found in your\n",
      " |      Keras config file at `~/.keras/keras.json`.\n",
      " |      If you never set it, then it will be \"channels_last\".\n",
      " |  \n",
      " |  Example:\n",
      " |  \n",
      " |  ```python\n",
      " |  model = Sequential()\n",
      " |  model.add(Convolution2D(64, 3, 3,\n",
      " |                          border_mode='same',\n",
      " |                          input_shape=(3, 32, 32)))\n",
      " |  # now: model.output_shape == (None, 64, 32, 32)\n",
      " |  \n",
      " |  model.add(Flatten())\n",
      " |  # now: model.output_shape == (None, 65536)\n",
      " |  ```\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Flatten\n",
      " |      tensorflow.python.keras.engine.base_layer.Layer\n",
      " |      tensorflow.python.module.module.Module\n",
      " |      tensorflow.python.training.tracking.tracking.AutoTrackable\n",
      " |      tensorflow.python.training.tracking.base.Trackable\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, data_format=None, **kwargs)\n",
      " |  \n",
      " |  call(self, inputs)\n",
      " |      This is where the layer's logic lives.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          inputs: Input tensor, or list/tuple of input tensors.\n",
      " |          **kwargs: Additional keyword arguments.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor or list/tuple of tensors.\n",
      " |  \n",
      " |  compute_output_shape(self, input_shape)\n",
      " |      Computes the output shape of the layer.\n",
      " |      \n",
      " |      If the layer has not been built, this method will call `build` on the\n",
      " |      layer. This assumes that the layer will later be used with inputs that\n",
      " |      match the input shape provided here.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          input_shape: Shape tuple (tuple of integers)\n",
      " |              or list of shape tuples (one per output tensor of the layer).\n",
      " |              Shape tuples can include None for free dimensions,\n",
      " |              instead of an integer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An input shape tuple.\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the config of the layer.\n",
      " |      \n",
      " |      A layer config is a Python dictionary (serializable)\n",
      " |      containing the configuration of a layer.\n",
      " |      The same layer can be reinstantiated later\n",
      " |      (without its trained weights) from this configuration.\n",
      " |      \n",
      " |      The config of a layer does not include connectivity\n",
      " |      information, nor the layer class name. These are handled\n",
      " |      by `Network` (one layer of abstraction above).\n",
      " |      \n",
      " |      Returns:\n",
      " |          Python dictionary.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  __call__(self, inputs, *args, **kwargs)\n",
      " |      Wraps `call`, applying pre- and post-processing steps.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: input tensor(s).\n",
      " |        *args: additional positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: additional keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |      \n",
      " |      Note:\n",
      " |        - The following optional keyword arguments are reserved for specific uses:\n",
      " |          * `training`: Boolean scalar tensor of Python boolean indicating\n",
      " |            whether the `call` is meant for training or inference.\n",
      " |          * `mask`: Boolean input mask.\n",
      " |        - If the layer's `call` method takes a `mask` argument (as some Keras\n",
      " |          layers do), its default value will be set to the mask generated\n",
      " |          for `inputs` by the previous layer (if `input` did come from\n",
      " |          a layer that generated a corresponding mask, i.e. if it came from\n",
      " |          a Keras layer with masking support.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: if the layer's `call` method returns None (an invalid value).\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Support self.foo = trackable syntax.\n",
      " |  \n",
      " |  add_loss(self, losses, inputs=None)\n",
      " |      Add loss tensor(s), potentially dependent on layer inputs.\n",
      " |      \n",
      " |      Some losses (for instance, activity regularization losses) may be dependent\n",
      " |      on the inputs passed when calling a layer. Hence, when reusing the same\n",
      " |      layer on different inputs `a` and `b`, some entries in `layer.losses` may\n",
      " |      be dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      This method can be used inside a subclassed layer or model's `call`\n",
      " |      function, in which case `losses` should be a Tensor or list of Tensors.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      class MyLayer(tf.keras.layers.Layer):\n",
      " |        def call(inputs, self):\n",
      " |          self.add_loss(tf.abs(tf.reduce_mean(inputs)), inputs=True)\n",
      " |          return inputs\n",
      " |      ```\n",
      " |      \n",
      " |      This method can also be called directly on a Functional Model during\n",
      " |      construction. In this case, any loss Tensors passed to this Model must\n",
      " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
      " |      losses become part of the model's topology and are tracked in `get_config`.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Actvity regularization.\n",
      " |      model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
      " |      ```\n",
      " |      \n",
      " |      If this is not the case for your loss (if, for example, your loss references\n",
      " |      a `Variable` of one of the model's layers), you can wrap your loss in a\n",
      " |      zero-argument lambda. These losses are not tracked as part of the model's\n",
      " |      topology since they can't be serialized.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Weight regularization.\n",
      " |      model.add_loss(lambda: tf.reduce_mean(x.kernel))\n",
      " |      ```\n",
      " |      \n",
      " |      The `get_losses_for` method allows to retrieve the losses relevant to a\n",
      " |      specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        losses: Loss tensor, or list/tuple of tensors. Rather than tensors, losses\n",
      " |          may also be zero-argument callables which create a loss tensor.\n",
      " |        inputs: Ignored when executing eagerly. If anything other than None is\n",
      " |          passed, it signals the losses are conditional on some of the layer's\n",
      " |          inputs, and thus they should only be run where these inputs are\n",
      " |          available. This is the case for activity regularization losses, for\n",
      " |          instance. If `None` is passed, the losses are assumed\n",
      " |          to be unconditional, and will apply across all dataflows of the layer\n",
      " |          (e.g. weight regularization losses).\n",
      " |  \n",
      " |  add_metric(self, value, aggregation=None, name=None)\n",
      " |      Adds metric tensor to the layer.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: Metric tensor.\n",
      " |        aggregation: Sample-wise metric reduction function. If `aggregation=None`,\n",
      " |          it indicates that the metric tensor provided has been aggregated\n",
      " |          already. eg, `bin_acc = BinaryAccuracy(name='acc')` followed by\n",
      " |          `model.add_metric(bin_acc(y_true, y_pred))`. If aggregation='mean', the\n",
      " |          given metric tensor will be sample-wise reduced using `mean` function.\n",
      " |          eg, `model.add_metric(tf.reduce_sum(outputs), name='output_mean',\n",
      " |          aggregation='mean')`.\n",
      " |        name: String metric name.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If `aggregation` is anything other than None or `mean`.\n",
      " |  \n",
      " |  add_update(self, updates, inputs=None)\n",
      " |      Add update op(s), potentially dependent on layer inputs. (deprecated arguments)\n",
      " |      \n",
      " |      Warning: SOME ARGUMENTS ARE DEPRECATED: `(inputs)`. They will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      `inputs` is now automatically inferred\n",
      " |      \n",
      " |      Weight updates (for instance, the updates of the moving mean and variance\n",
      " |      in a BatchNormalization layer) may be dependent on the inputs passed\n",
      " |      when calling a layer. Hence, when reusing the same layer on\n",
      " |      different inputs `a` and `b`, some entries in `layer.updates` may be\n",
      " |      dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      The `get_updates_for` method allows to retrieve the updates relevant to a\n",
      " |      specific set of inputs.\n",
      " |      \n",
      " |      This call is ignored when eager execution is enabled (in that case, variable\n",
      " |      updates are run on the fly and thus do not need to be tracked for later\n",
      " |      execution).\n",
      " |      \n",
      " |      Arguments:\n",
      " |        updates: Update op, or list/tuple of update ops, or zero-arg callable\n",
      " |          that returns an update op. A zero-arg callable should be passed in\n",
      " |          order to disable running the updates by setting `trainable=False`\n",
      " |          on this Layer, when executing in Eager mode.\n",
      " |        inputs: Deprecated, will be automatically inferred.\n",
      " |  \n",
      " |  add_variable(self, *args, **kwargs)\n",
      " |      Deprecated, do NOT use! Alias for `add_weight`. (deprecated)\n",
      " |      \n",
      " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      Please use `layer.add_weight` method instead.\n",
      " |  \n",
      " |  add_weight(self, name=None, shape=None, dtype=None, initializer=None, regularizer=None, trainable=None, constraint=None, partitioner=None, use_resource=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregation.NONE: 0>, **kwargs)\n",
      " |      Adds a new variable to the layer.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        name: Variable name.\n",
      " |        shape: Variable shape. Defaults to scalar if unspecified.\n",
      " |        dtype: The type of the variable. Defaults to `self.dtype` or `float32`.\n",
      " |        initializer: Initializer instance (callable).\n",
      " |        regularizer: Regularizer instance (callable).\n",
      " |        trainable: Boolean, whether the variable should be part of the layer's\n",
      " |          \"trainable_variables\" (e.g. variables, biases)\n",
      " |          or \"non_trainable_variables\" (e.g. BatchNorm mean and variance).\n",
      " |          Note that `trainable` cannot be `True` if `synchronization`\n",
      " |          is set to `ON_READ`.\n",
      " |        constraint: Constraint instance (callable).\n",
      " |        partitioner: Partitioner to be passed to the `Trackable` API.\n",
      " |        use_resource: Whether to use `ResourceVariable`.\n",
      " |        synchronization: Indicates when a distributed a variable will be\n",
      " |          aggregated. Accepted values are constants defined in the class\n",
      " |          `tf.VariableSynchronization`. By default the synchronization is set to\n",
      " |          `AUTO` and the current `DistributionStrategy` chooses\n",
      " |          when to synchronize. If `synchronization` is set to `ON_READ`,\n",
      " |          `trainable` must not be set to `True`.\n",
      " |        aggregation: Indicates how a distributed variable will be aggregated.\n",
      " |          Accepted values are constants defined in the class\n",
      " |          `tf.VariableAggregation`.\n",
      " |        **kwargs: Additional keyword arguments. Accepted values are `getter` and\n",
      " |          `collections`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The created variable. Usually either a `Variable` or `ResourceVariable`\n",
      " |        instance. If `partitioner` is not `None`, a `PartitionedVariable`\n",
      " |        instance is returned.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called with partitioned variable regularization and\n",
      " |          eager execution is enabled.\n",
      " |        ValueError: When giving unsupported dtype and no initializer or when\n",
      " |          trainable has been set to True with synchronization set as `ON_READ`.\n",
      " |  \n",
      " |  apply(self, inputs, *args, **kwargs)\n",
      " |      Deprecated, do NOT use! (deprecated)\n",
      " |      \n",
      " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      Please use `layer.__call__` method instead.\n",
      " |      \n",
      " |      This is an alias of `self.__call__`.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor(s).\n",
      " |        *args: additional positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: additional keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |  \n",
      " |  build(self, input_shape)\n",
      " |      Creates the variables of the layer (optional, for subclass implementers).\n",
      " |      \n",
      " |      This is a method that implementers of subclasses of `Layer` or `Model`\n",
      " |      can override if they need a state-creation step in-between\n",
      " |      layer instantiation and layer call.\n",
      " |      \n",
      " |      This is typically used to create the weights of `Layer` subclasses.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        input_shape: Instance of `TensorShape`, or list of instances of\n",
      " |          `TensorShape` if the layer expects a list of inputs\n",
      " |          (one instance per input).\n",
      " |  \n",
      " |  compute_mask(self, inputs, mask=None)\n",
      " |      Computes an output mask tensor.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          inputs: Tensor or list of tensors.\n",
      " |          mask: Tensor or list of tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |          None or a tensor (or list of tensors,\n",
      " |              one per output tensor of the layer).\n",
      " |  \n",
      " |  compute_output_signature(self, input_signature)\n",
      " |      Compute the output tensor signature of the layer based on the inputs.\n",
      " |      \n",
      " |      Unlike a TensorShape object, a TensorSpec object contains both shape\n",
      " |      and dtype information for a tensor. This method allows layers to provide\n",
      " |      output dtype information if it is different from the input dtype.\n",
      " |      For any layer that doesn't implement this function,\n",
      " |      the framework will fall back to use `compute_output_shape`, and will\n",
      " |      assume that the output dtype matches the input dtype.\n",
      " |      \n",
      " |      Args:\n",
      " |        input_signature: Single TensorSpec or nested structure of TensorSpec\n",
      " |          objects, describing a candidate input for the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Single TensorSpec or nested structure of TensorSpec objects, describing\n",
      " |          how the layer would transform the provided input.\n",
      " |      \n",
      " |      Raises:\n",
      " |        TypeError: If input_signature contains a non-TensorSpec object.\n",
      " |  \n",
      " |  count_params(self)\n",
      " |      Count the total number of scalars composing the weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An integer count.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: if the layer isn't yet built\n",
      " |            (in which case its weights aren't yet defined).\n",
      " |  \n",
      " |  get_input_at(self, node_index)\n",
      " |      Retrieves the input tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_input_mask_at(self, node_index)\n",
      " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_shape_at(self, node_index)\n",
      " |      Retrieves the input shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_losses_for(self, inputs)\n",
      " |      Retrieves losses relevant to a specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor or list/tuple of input tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |        List of loss tensors of the layer that depend on `inputs`.\n",
      " |  \n",
      " |  get_output_at(self, node_index)\n",
      " |      Retrieves the output tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_output_mask_at(self, node_index)\n",
      " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_shape_at(self, node_index)\n",
      " |      Retrieves the output shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_updates_for(self, inputs)\n",
      " |      Retrieves updates relevant to a specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor or list/tuple of input tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |        List of update ops of the layer that depend on `inputs`.\n",
      " |  \n",
      " |  get_weights(self)\n",
      " |      Returns the current weights of the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Weights values as a list of numpy arrays.\n",
      " |  \n",
      " |  set_weights(self, weights)\n",
      " |      Sets the weights of the layer, from Numpy arrays.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          weights: a list of Numpy arrays. The number\n",
      " |              of arrays and their shape must match\n",
      " |              number of the dimensions of the weights\n",
      " |              of the layer (i.e. it should match the\n",
      " |              output of `get_weights`).\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: If the provided weights list does not match the\n",
      " |              layer's specifications.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  from_config(config) from builtins.type\n",
      " |      Creates a layer from its config.\n",
      " |      \n",
      " |      This method is the reverse of `get_config`,\n",
      " |      capable of instantiating the same layer from the config\n",
      " |      dictionary. It does not handle layer connectivity\n",
      " |      (handled by Network), nor weights (handled by `set_weights`).\n",
      " |      \n",
      " |      Arguments:\n",
      " |          config: A Python dictionary, typically the\n",
      " |              output of get_config.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A layer instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  activity_regularizer\n",
      " |      Optional regularizer function for the output of this layer.\n",
      " |  \n",
      " |  dtype\n",
      " |  \n",
      " |  dynamic\n",
      " |  \n",
      " |  inbound_nodes\n",
      " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      " |  \n",
      " |  input\n",
      " |      Retrieves the input tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input tensor or list of input tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |        AttributeError: If no inbound nodes are found.\n",
      " |  \n",
      " |  input_mask\n",
      " |      Retrieves the input mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input mask tensor (potentially None) or list of input\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_shape\n",
      " |      Retrieves the input shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer, or if all inputs\n",
      " |      have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per input tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined input_shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  input_spec\n",
      " |  \n",
      " |  losses\n",
      " |      Losses which are associated with this `Layer`.\n",
      " |      \n",
      " |      Variable regularization tensors are created when this property is accessed,\n",
      " |      so it is eager safe: accessing `losses` under a `tf.GradientTape` will\n",
      " |      propagate gradients back to the corresponding variables.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of tensors.\n",
      " |  \n",
      " |  metrics\n",
      " |  \n",
      " |  name\n",
      " |      Returns the name of this module as passed or determined in the ctor.\n",
      " |      \n",
      " |      NOTE: This is not the same as the `self.name_scope.name` which includes\n",
      " |      parent module names.\n",
      " |  \n",
      " |  non_trainable_variables\n",
      " |  \n",
      " |  non_trainable_weights\n",
      " |  \n",
      " |  outbound_nodes\n",
      " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      " |  \n",
      " |  output\n",
      " |      Retrieves the output tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one output,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor or list of output tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        AttributeError: if the layer is connected to more than one incoming\n",
      " |          layers.\n",
      " |        RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  output_mask\n",
      " |      Retrieves the output mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output mask tensor (potentially None) or list of output\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_shape\n",
      " |      Retrieves the output shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has one output,\n",
      " |      or if all outputs have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per output tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined output shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  trainable\n",
      " |  \n",
      " |  trainable_variables\n",
      " |      Sequence of variables owned by this module and it's submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  trainable_weights\n",
      " |  \n",
      " |  updates\n",
      " |  \n",
      " |  variables\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Alias of `self.weights`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  weights\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  with_name_scope(method) from builtins.type\n",
      " |      Decorator to automatically enter the module name scope.\n",
      " |      \n",
      " |      ```\n",
      " |      class MyModule(tf.Module):\n",
      " |        @tf.Module.with_name_scope\n",
      " |        def __call__(self, x):\n",
      " |          if not hasattr(self, 'w'):\n",
      " |            self.w = tf.Variable(tf.random.normal([x.shape[1], 64]))\n",
      " |          return tf.matmul(x, self.w)\n",
      " |      ```\n",
      " |      \n",
      " |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
      " |      names included the module name:\n",
      " |      \n",
      " |      ```\n",
      " |      mod = MyModule()\n",
      " |      mod(tf.ones([8, 32]))\n",
      " |      # ==> <tf.Tensor: ...>\n",
      " |      mod.w\n",
      " |      # ==> <tf.Variable ...'my_module/w:0'>\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        method: The method to wrap.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The original method wrapped such that it enters the module's name scope.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  name_scope\n",
      " |      Returns a `tf.name_scope` instance for this class.\n",
      " |  \n",
      " |  submodules\n",
      " |      Sequence of all sub-modules.\n",
      " |      \n",
      " |      Submodules are modules which are properties of this module, or found as\n",
      " |      properties of modules which are properties of this module (and so on).\n",
      " |      \n",
      " |      ```\n",
      " |      a = tf.Module()\n",
      " |      b = tf.Module()\n",
      " |      c = tf.Module()\n",
      " |      a.b = b\n",
      " |      b.c = c\n",
      " |      assert list(a.submodules) == [b, c]\n",
      " |      assert list(b.submodules) == [c]\n",
      " |      assert list(c.submodules) == []\n",
      " |      ```\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of all submodules.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.training.tracking.base.Trackable:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(keras.layers.Flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "73b5e28a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 7s 125us/sample - loss: 0.2957 - acc: 0.9174\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 8s 136us/sample - loss: 0.1361 - acc: 0.9600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x27d39083e48>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4 = keras.Sequential([\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(100, activation = 'relu'), # I didn't have to put input_shape as an argument. It works without it\n",
    "    keras.layers.Dense(10, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "model4.compile(optimizer = 'adam', \n",
    "               loss = 'sparse_categorical_crossentropy', \n",
    "               metrics = ['accuracy'])\n",
    "\n",
    "model4.fit(X_train, y_train, epochs = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4345d7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's convenient because I don't have to create a flatten array :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c8f198",
   "metadata": {},
   "source": [
    "# Checking different model.compile parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a13b34ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I search in google for \"keras loss functions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "a28a9358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 13s 209us/sample - loss: 1.0561 - acc: 0.0271\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 10s 169us/sample - loss: 1.0028 - acc: 0.0390\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x27d391e9788>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5 = keras.Sequential([\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(100, activation = 'relu'), # I didn't have to put input_shape as an argument. It works without it\n",
    "    keras.layers.Dense(10, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "model5.compile(optimizer = 'SGD', \n",
    "               loss = 'poisson', \n",
    "               metrics = ['accuracy'])\n",
    "\n",
    "model5.fit(X_train, y_train, epochs = 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
