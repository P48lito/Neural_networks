{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c75ac9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.youtube.com/watch?v=7HPwo4wnJeA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70caaf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "55db98fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_module_wrapper',\n",
       " '_sys',\n",
       " 'boston_housing',\n",
       " 'cifar10',\n",
       " 'cifar100',\n",
       " 'fashion_mnist',\n",
       " 'imdb',\n",
       " 'mnist',\n",
       " 'reuters']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06438811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([[[[ 59,  62,  63],\n",
       "           [ 43,  46,  45],\n",
       "           [ 50,  48,  43],\n",
       "           ...,\n",
       "           [158, 132, 108],\n",
       "           [152, 125, 102],\n",
       "           [148, 124, 103]],\n",
       "  \n",
       "          [[ 16,  20,  20],\n",
       "           [  0,   0,   0],\n",
       "           [ 18,   8,   0],\n",
       "           ...,\n",
       "           [123,  88,  55],\n",
       "           [119,  83,  50],\n",
       "           [122,  87,  57]],\n",
       "  \n",
       "          [[ 25,  24,  21],\n",
       "           [ 16,   7,   0],\n",
       "           [ 49,  27,   8],\n",
       "           ...,\n",
       "           [118,  84,  50],\n",
       "           [120,  84,  50],\n",
       "           [109,  73,  42]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[208, 170,  96],\n",
       "           [201, 153,  34],\n",
       "           [198, 161,  26],\n",
       "           ...,\n",
       "           [160, 133,  70],\n",
       "           [ 56,  31,   7],\n",
       "           [ 53,  34,  20]],\n",
       "  \n",
       "          [[180, 139,  96],\n",
       "           [173, 123,  42],\n",
       "           [186, 144,  30],\n",
       "           ...,\n",
       "           [184, 148,  94],\n",
       "           [ 97,  62,  34],\n",
       "           [ 83,  53,  34]],\n",
       "  \n",
       "          [[177, 144, 116],\n",
       "           [168, 129,  94],\n",
       "           [179, 142,  87],\n",
       "           ...,\n",
       "           [216, 184, 140],\n",
       "           [151, 118,  84],\n",
       "           [123,  92,  72]]],\n",
       "  \n",
       "  \n",
       "         [[[154, 177, 187],\n",
       "           [126, 137, 136],\n",
       "           [105, 104,  95],\n",
       "           ...,\n",
       "           [ 91,  95,  71],\n",
       "           [ 87,  90,  71],\n",
       "           [ 79,  81,  70]],\n",
       "  \n",
       "          [[140, 160, 169],\n",
       "           [145, 153, 154],\n",
       "           [125, 125, 118],\n",
       "           ...,\n",
       "           [ 96,  99,  78],\n",
       "           [ 77,  80,  62],\n",
       "           [ 71,  73,  61]],\n",
       "  \n",
       "          [[140, 155, 164],\n",
       "           [139, 146, 149],\n",
       "           [115, 115, 112],\n",
       "           ...,\n",
       "           [ 79,  82,  64],\n",
       "           [ 68,  70,  55],\n",
       "           [ 67,  69,  55]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[175, 167, 166],\n",
       "           [156, 154, 160],\n",
       "           [154, 160, 170],\n",
       "           ...,\n",
       "           [ 42,  34,  36],\n",
       "           [ 61,  53,  57],\n",
       "           [ 93,  83,  91]],\n",
       "  \n",
       "          [[165, 154, 128],\n",
       "           [156, 152, 130],\n",
       "           [159, 161, 142],\n",
       "           ...,\n",
       "           [103,  93,  96],\n",
       "           [123, 114, 120],\n",
       "           [131, 121, 131]],\n",
       "  \n",
       "          [[163, 148, 120],\n",
       "           [158, 148, 122],\n",
       "           [163, 156, 133],\n",
       "           ...,\n",
       "           [143, 133, 139],\n",
       "           [143, 134, 142],\n",
       "           [143, 133, 144]]],\n",
       "  \n",
       "  \n",
       "         [[[255, 255, 255],\n",
       "           [253, 253, 253],\n",
       "           [253, 253, 253],\n",
       "           ...,\n",
       "           [253, 253, 253],\n",
       "           [253, 253, 253],\n",
       "           [253, 253, 253]],\n",
       "  \n",
       "          [[255, 255, 255],\n",
       "           [255, 255, 255],\n",
       "           [255, 255, 255],\n",
       "           ...,\n",
       "           [255, 255, 255],\n",
       "           [255, 255, 255],\n",
       "           [255, 255, 255]],\n",
       "  \n",
       "          [[255, 255, 255],\n",
       "           [254, 254, 254],\n",
       "           [254, 254, 254],\n",
       "           ...,\n",
       "           [254, 254, 254],\n",
       "           [254, 254, 254],\n",
       "           [254, 254, 254]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[113, 120, 112],\n",
       "           [111, 118, 111],\n",
       "           [105, 112, 106],\n",
       "           ...,\n",
       "           [ 72,  81,  80],\n",
       "           [ 72,  80,  79],\n",
       "           [ 72,  80,  79]],\n",
       "  \n",
       "          [[111, 118, 110],\n",
       "           [104, 111, 104],\n",
       "           [ 99, 106,  98],\n",
       "           ...,\n",
       "           [ 68,  75,  73],\n",
       "           [ 70,  76,  75],\n",
       "           [ 78,  84,  82]],\n",
       "  \n",
       "          [[106, 113, 105],\n",
       "           [ 99, 106,  98],\n",
       "           [ 95, 102,  94],\n",
       "           ...,\n",
       "           [ 78,  85,  83],\n",
       "           [ 79,  85,  83],\n",
       "           [ 80,  86,  84]]],\n",
       "  \n",
       "  \n",
       "         ...,\n",
       "  \n",
       "  \n",
       "         [[[ 35, 178, 235],\n",
       "           [ 40, 176, 239],\n",
       "           [ 42, 176, 241],\n",
       "           ...,\n",
       "           [ 99, 177, 219],\n",
       "           [ 79, 147, 197],\n",
       "           [ 89, 148, 189]],\n",
       "  \n",
       "          [[ 57, 182, 234],\n",
       "           [ 44, 184, 250],\n",
       "           [ 50, 183, 240],\n",
       "           ...,\n",
       "           [156, 182, 200],\n",
       "           [141, 177, 206],\n",
       "           [116, 149, 175]],\n",
       "  \n",
       "          [[ 98, 197, 237],\n",
       "           [ 64, 189, 252],\n",
       "           [ 69, 192, 245],\n",
       "           ...,\n",
       "           [188, 195, 206],\n",
       "           [119, 135, 147],\n",
       "           [ 61,  79,  90]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[ 73,  79,  77],\n",
       "           [ 53,  63,  68],\n",
       "           [ 54,  68,  80],\n",
       "           ...,\n",
       "           [ 17,  40,  64],\n",
       "           [ 21,  36,  51],\n",
       "           [ 33,  48,  49]],\n",
       "  \n",
       "          [[ 61,  68,  75],\n",
       "           [ 55,  70,  86],\n",
       "           [ 57,  79, 103],\n",
       "           ...,\n",
       "           [ 24,  48,  72],\n",
       "           [ 17,  35,  53],\n",
       "           [  7,  23,  32]],\n",
       "  \n",
       "          [[ 44,  56,  73],\n",
       "           [ 46,  66,  88],\n",
       "           [ 49,  77, 105],\n",
       "           ...,\n",
       "           [ 27,  52,  77],\n",
       "           [ 21,  43,  66],\n",
       "           [ 12,  31,  50]]],\n",
       "  \n",
       "  \n",
       "         [[[189, 211, 240],\n",
       "           [186, 208, 236],\n",
       "           [185, 207, 235],\n",
       "           ...,\n",
       "           [175, 195, 224],\n",
       "           [172, 194, 222],\n",
       "           [169, 194, 220]],\n",
       "  \n",
       "          [[194, 210, 239],\n",
       "           [191, 207, 236],\n",
       "           [190, 206, 235],\n",
       "           ...,\n",
       "           [173, 192, 220],\n",
       "           [171, 191, 218],\n",
       "           [167, 190, 216]],\n",
       "  \n",
       "          [[208, 219, 244],\n",
       "           [205, 216, 240],\n",
       "           [204, 215, 239],\n",
       "           ...,\n",
       "           [175, 191, 217],\n",
       "           [172, 190, 216],\n",
       "           [169, 191, 215]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[207, 199, 181],\n",
       "           [203, 195, 175],\n",
       "           [203, 196, 173],\n",
       "           ...,\n",
       "           [135, 132, 127],\n",
       "           [162, 158, 150],\n",
       "           [168, 163, 151]],\n",
       "  \n",
       "          [[198, 190, 170],\n",
       "           [189, 181, 159],\n",
       "           [180, 172, 147],\n",
       "           ...,\n",
       "           [178, 171, 160],\n",
       "           [175, 169, 156],\n",
       "           [175, 169, 154]],\n",
       "  \n",
       "          [[198, 189, 173],\n",
       "           [189, 181, 162],\n",
       "           [178, 170, 149],\n",
       "           ...,\n",
       "           [195, 184, 169],\n",
       "           [196, 189, 171],\n",
       "           [195, 190, 171]]],\n",
       "  \n",
       "  \n",
       "         [[[229, 229, 239],\n",
       "           [236, 237, 247],\n",
       "           [234, 236, 247],\n",
       "           ...,\n",
       "           [217, 219, 233],\n",
       "           [221, 223, 234],\n",
       "           [222, 223, 233]],\n",
       "  \n",
       "          [[222, 221, 229],\n",
       "           [239, 239, 249],\n",
       "           [233, 234, 246],\n",
       "           ...,\n",
       "           [223, 223, 236],\n",
       "           [227, 228, 238],\n",
       "           [210, 211, 220]],\n",
       "  \n",
       "          [[213, 206, 211],\n",
       "           [234, 232, 239],\n",
       "           [231, 233, 244],\n",
       "           ...,\n",
       "           [220, 220, 232],\n",
       "           [220, 219, 232],\n",
       "           [202, 203, 215]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[150, 143, 135],\n",
       "           [140, 135, 127],\n",
       "           [132, 127, 120],\n",
       "           ...,\n",
       "           [224, 222, 218],\n",
       "           [230, 228, 225],\n",
       "           [241, 241, 238]],\n",
       "  \n",
       "          [[137, 132, 126],\n",
       "           [130, 127, 120],\n",
       "           [125, 121, 115],\n",
       "           ...,\n",
       "           [181, 180, 178],\n",
       "           [202, 201, 198],\n",
       "           [212, 211, 207]],\n",
       "  \n",
       "          [[122, 119, 114],\n",
       "           [118, 116, 110],\n",
       "           [120, 116, 111],\n",
       "           ...,\n",
       "           [179, 177, 173],\n",
       "           [164, 164, 162],\n",
       "           [163, 163, 161]]]], dtype=uint8),\n",
       "  array([[6],\n",
       "         [9],\n",
       "         [9],\n",
       "         ...,\n",
       "         [9],\n",
       "         [1],\n",
       "         [1]], dtype=uint8)),\n",
       " (array([[[[158, 112,  49],\n",
       "           [159, 111,  47],\n",
       "           [165, 116,  51],\n",
       "           ...,\n",
       "           [137,  95,  36],\n",
       "           [126,  91,  36],\n",
       "           [116,  85,  33]],\n",
       "  \n",
       "          [[152, 112,  51],\n",
       "           [151, 110,  40],\n",
       "           [159, 114,  45],\n",
       "           ...,\n",
       "           [136,  95,  31],\n",
       "           [125,  91,  32],\n",
       "           [119,  88,  34]],\n",
       "  \n",
       "          [[151, 110,  47],\n",
       "           [151, 109,  33],\n",
       "           [158, 111,  36],\n",
       "           ...,\n",
       "           [139,  98,  34],\n",
       "           [130,  95,  34],\n",
       "           [120,  89,  33]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[ 68, 124, 177],\n",
       "           [ 42, 100, 148],\n",
       "           [ 31,  88, 137],\n",
       "           ...,\n",
       "           [ 38,  97, 146],\n",
       "           [ 13,  64, 108],\n",
       "           [ 40,  85, 127]],\n",
       "  \n",
       "          [[ 61, 116, 168],\n",
       "           [ 49, 102, 148],\n",
       "           [ 35,  85, 132],\n",
       "           ...,\n",
       "           [ 26,  82, 130],\n",
       "           [ 29,  82, 126],\n",
       "           [ 20,  64, 107]],\n",
       "  \n",
       "          [[ 54, 107, 160],\n",
       "           [ 56, 105, 149],\n",
       "           [ 45,  89, 132],\n",
       "           ...,\n",
       "           [ 24,  77, 124],\n",
       "           [ 34,  84, 129],\n",
       "           [ 21,  67, 110]]],\n",
       "  \n",
       "  \n",
       "         [[[235, 235, 235],\n",
       "           [231, 231, 231],\n",
       "           [232, 232, 232],\n",
       "           ...,\n",
       "           [233, 233, 233],\n",
       "           [233, 233, 233],\n",
       "           [232, 232, 232]],\n",
       "  \n",
       "          [[238, 238, 238],\n",
       "           [235, 235, 235],\n",
       "           [235, 235, 235],\n",
       "           ...,\n",
       "           [236, 236, 236],\n",
       "           [236, 236, 236],\n",
       "           [235, 235, 235]],\n",
       "  \n",
       "          [[237, 237, 237],\n",
       "           [234, 234, 234],\n",
       "           [234, 234, 234],\n",
       "           ...,\n",
       "           [235, 235, 235],\n",
       "           [235, 235, 235],\n",
       "           [234, 234, 234]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[ 87,  99,  89],\n",
       "           [ 43,  51,  37],\n",
       "           [ 19,  23,  11],\n",
       "           ...,\n",
       "           [169, 184, 179],\n",
       "           [182, 197, 193],\n",
       "           [188, 202, 201]],\n",
       "  \n",
       "          [[ 82,  96,  82],\n",
       "           [ 46,  57,  36],\n",
       "           [ 36,  44,  22],\n",
       "           ...,\n",
       "           [174, 189, 183],\n",
       "           [185, 200, 196],\n",
       "           [187, 202, 200]],\n",
       "  \n",
       "          [[ 85, 101,  83],\n",
       "           [ 62,  75,  48],\n",
       "           [ 58,  67,  38],\n",
       "           ...,\n",
       "           [168, 183, 178],\n",
       "           [180, 195, 191],\n",
       "           [186, 200, 199]]],\n",
       "  \n",
       "  \n",
       "         [[[158, 190, 222],\n",
       "           [158, 187, 218],\n",
       "           [139, 166, 194],\n",
       "           ...,\n",
       "           [228, 231, 234],\n",
       "           [237, 239, 243],\n",
       "           [238, 241, 246]],\n",
       "  \n",
       "          [[170, 200, 229],\n",
       "           [172, 199, 226],\n",
       "           [151, 176, 201],\n",
       "           ...,\n",
       "           [232, 232, 236],\n",
       "           [246, 246, 250],\n",
       "           [246, 247, 251]],\n",
       "  \n",
       "          [[174, 201, 225],\n",
       "           [176, 200, 222],\n",
       "           [157, 179, 199],\n",
       "           ...,\n",
       "           [230, 229, 232],\n",
       "           [250, 249, 251],\n",
       "           [245, 244, 247]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[ 31,  40,  45],\n",
       "           [ 30,  39,  44],\n",
       "           [ 26,  35,  40],\n",
       "           ...,\n",
       "           [ 37,  40,  46],\n",
       "           [  9,  13,  14],\n",
       "           [  4,   7,   5]],\n",
       "  \n",
       "          [[ 23,  34,  39],\n",
       "           [ 27,  38,  43],\n",
       "           [ 25,  36,  41],\n",
       "           ...,\n",
       "           [ 19,  20,  24],\n",
       "           [  4,   6,   3],\n",
       "           [  5,   7,   3]],\n",
       "  \n",
       "          [[ 28,  41,  47],\n",
       "           [ 30,  43,  50],\n",
       "           [ 32,  45,  52],\n",
       "           ...,\n",
       "           [  5,   6,   8],\n",
       "           [  4,   5,   3],\n",
       "           [  7,   8,   7]]],\n",
       "  \n",
       "  \n",
       "         ...,\n",
       "  \n",
       "  \n",
       "         [[[ 20,  15,  12],\n",
       "           [ 19,  14,  11],\n",
       "           [ 15,  14,  11],\n",
       "           ...,\n",
       "           [ 10,   9,   7],\n",
       "           [ 12,  11,   9],\n",
       "           [ 13,  12,  10]],\n",
       "  \n",
       "          [[ 21,  16,  13],\n",
       "           [ 20,  16,  13],\n",
       "           [ 18,  17,  12],\n",
       "           ...,\n",
       "           [ 10,   9,   7],\n",
       "           [ 10,   9,   7],\n",
       "           [ 12,  11,   9]],\n",
       "  \n",
       "          [[ 21,  16,  13],\n",
       "           [ 21,  17,  12],\n",
       "           [ 20,  18,  11],\n",
       "           ...,\n",
       "           [ 12,  11,   9],\n",
       "           [ 12,  11,   9],\n",
       "           [ 13,  12,  10]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[ 33,  25,  13],\n",
       "           [ 34,  26,  15],\n",
       "           [ 34,  26,  15],\n",
       "           ...,\n",
       "           [ 28,  25,  52],\n",
       "           [ 29,  25,  58],\n",
       "           [ 23,  20,  42]],\n",
       "  \n",
       "          [[ 33,  25,  14],\n",
       "           [ 34,  26,  15],\n",
       "           [ 34,  26,  15],\n",
       "           ...,\n",
       "           [ 27,  24,  52],\n",
       "           [ 27,  24,  56],\n",
       "           [ 25,  22,  47]],\n",
       "  \n",
       "          [[ 31,  23,  12],\n",
       "           [ 32,  24,  13],\n",
       "           [ 33,  25,  14],\n",
       "           ...,\n",
       "           [ 24,  23,  50],\n",
       "           [ 26,  23,  53],\n",
       "           [ 25,  20,  47]]],\n",
       "  \n",
       "  \n",
       "         [[[ 25,  40,  12],\n",
       "           [ 15,  36,   3],\n",
       "           [ 23,  41,  18],\n",
       "           ...,\n",
       "           [ 61,  82,  78],\n",
       "           [ 92, 113, 112],\n",
       "           [ 75,  89,  92]],\n",
       "  \n",
       "          [[ 12,  25,   6],\n",
       "           [ 20,  37,   7],\n",
       "           [ 24,  36,  15],\n",
       "           ...,\n",
       "           [115, 134, 138],\n",
       "           [149, 168, 177],\n",
       "           [104, 117, 131]],\n",
       "  \n",
       "          [[ 12,  25,  11],\n",
       "           [ 15,  29,   6],\n",
       "           [ 34,  40,  24],\n",
       "           ...,\n",
       "           [154, 172, 182],\n",
       "           [157, 175, 192],\n",
       "           [116, 129, 151]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[100, 129,  81],\n",
       "           [103, 132,  84],\n",
       "           [104, 134,  86],\n",
       "           ...,\n",
       "           [ 97, 128,  84],\n",
       "           [ 98, 126,  84],\n",
       "           [ 91, 121,  79]],\n",
       "  \n",
       "          [[103, 132,  83],\n",
       "           [104, 131,  83],\n",
       "           [107, 135,  87],\n",
       "           ...,\n",
       "           [101, 132,  87],\n",
       "           [ 99, 127,  84],\n",
       "           [ 92, 121,  79]],\n",
       "  \n",
       "          [[ 95, 126,  78],\n",
       "           [ 95, 123,  76],\n",
       "           [101, 128,  81],\n",
       "           ...,\n",
       "           [ 93, 124,  80],\n",
       "           [ 95, 123,  81],\n",
       "           [ 92, 120,  80]]],\n",
       "  \n",
       "  \n",
       "         [[[ 73,  78,  75],\n",
       "           [ 98, 103, 113],\n",
       "           [ 99, 106, 114],\n",
       "           ...,\n",
       "           [135, 150, 152],\n",
       "           [135, 149, 154],\n",
       "           [203, 215, 223]],\n",
       "  \n",
       "          [[ 69,  73,  70],\n",
       "           [ 84,  89,  97],\n",
       "           [ 68,  75,  81],\n",
       "           ...,\n",
       "           [ 85,  95,  89],\n",
       "           [ 71,  82,  80],\n",
       "           [120, 133, 135]],\n",
       "  \n",
       "          [[ 69,  73,  70],\n",
       "           [ 90,  95, 100],\n",
       "           [ 62,  71,  74],\n",
       "           ...,\n",
       "           [ 74,  81,  70],\n",
       "           [ 53,  62,  54],\n",
       "           [ 62,  74,  69]],\n",
       "  \n",
       "          ...,\n",
       "  \n",
       "          [[123, 128,  96],\n",
       "           [132, 132, 102],\n",
       "           [129, 128, 100],\n",
       "           ...,\n",
       "           [108, 107,  88],\n",
       "           [ 62,  60,  55],\n",
       "           [ 27,  27,  28]],\n",
       "  \n",
       "          [[115, 121,  91],\n",
       "           [123, 124,  95],\n",
       "           [129, 126,  99],\n",
       "           ...,\n",
       "           [115, 116,  94],\n",
       "           [ 66,  65,  59],\n",
       "           [ 27,  27,  27]],\n",
       "  \n",
       "          [[116, 120,  90],\n",
       "           [121, 122,  94],\n",
       "           [129, 128, 101],\n",
       "           ...,\n",
       "           [116, 115,  94],\n",
       "           [ 68,  65,  58],\n",
       "           [ 27,  26,  26]]]], dtype=uint8),\n",
       "  array([[3],\n",
       "         [8],\n",
       "         [8],\n",
       "         ...,\n",
       "         [5],\n",
       "         [1],\n",
       "         [7]], dtype=uint8)))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3596fbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train,y_train), (X_test, y_test) = datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef7652a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Annotation',\n",
       " 'Arrow',\n",
       " 'Artist',\n",
       " 'AutoLocator',\n",
       " 'Axes',\n",
       " 'Button',\n",
       " 'Circle',\n",
       " 'Figure',\n",
       " 'FigureCanvasBase',\n",
       " 'FixedFormatter',\n",
       " 'FixedLocator',\n",
       " 'FormatStrFormatter',\n",
       " 'Formatter',\n",
       " 'FuncFormatter',\n",
       " 'GridSpec',\n",
       " 'IndexLocator',\n",
       " 'Line2D',\n",
       " 'LinearLocator',\n",
       " 'Locator',\n",
       " 'LogFormatter',\n",
       " 'LogFormatterExponent',\n",
       " 'LogFormatterMathtext',\n",
       " 'LogLocator',\n",
       " 'MaxNLocator',\n",
       " 'MouseButton',\n",
       " 'MultipleLocator',\n",
       " 'Normalize',\n",
       " 'NullFormatter',\n",
       " 'NullLocator',\n",
       " 'Number',\n",
       " 'PolarAxes',\n",
       " 'Polygon',\n",
       " 'Rectangle',\n",
       " 'ScalarFormatter',\n",
       " 'Slider',\n",
       " 'Subplot',\n",
       " 'SubplotSpec',\n",
       " 'Text',\n",
       " 'TickHelper',\n",
       " 'Widget',\n",
       " '_INSTALL_FIG_OBSERVER',\n",
       " '_IP_REGISTERED',\n",
       " '_IoffContext',\n",
       " '_IonContext',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__spec__',\n",
       " '_api',\n",
       " '_auto_draw_if_interactive',\n",
       " '_backend_mod',\n",
       " '_copy_docstring_and_deprecators',\n",
       " '_get_backend_mod',\n",
       " '_get_required_interactive_framework',\n",
       " '_interactive_bk',\n",
       " '_log',\n",
       " '_pylab_helpers',\n",
       " '_setup_pyplot_info_docstrings',\n",
       " '_warn_if_gui_out_of_main_thread',\n",
       " '_xkcd',\n",
       " 'acorr',\n",
       " 'angle_spectrum',\n",
       " 'annotate',\n",
       " 'arrow',\n",
       " 'autoscale',\n",
       " 'autumn',\n",
       " 'axes',\n",
       " 'axhline',\n",
       " 'axhspan',\n",
       " 'axis',\n",
       " 'axline',\n",
       " 'axvline',\n",
       " 'axvspan',\n",
       " 'bar',\n",
       " 'bar_label',\n",
       " 'barbs',\n",
       " 'barh',\n",
       " 'bone',\n",
       " 'box',\n",
       " 'boxplot',\n",
       " 'broken_barh',\n",
       " 'cbook',\n",
       " 'cla',\n",
       " 'clabel',\n",
       " 'clf',\n",
       " 'clim',\n",
       " 'close',\n",
       " 'cm',\n",
       " 'cohere',\n",
       " 'colorbar',\n",
       " 'colormaps',\n",
       " 'connect',\n",
       " 'contour',\n",
       " 'contourf',\n",
       " 'cool',\n",
       " 'copper',\n",
       " 'csd',\n",
       " 'cycler',\n",
       " 'delaxes',\n",
       " 'disconnect',\n",
       " 'docstring',\n",
       " 'draw',\n",
       " 'draw_all',\n",
       " 'draw_if_interactive',\n",
       " 'errorbar',\n",
       " 'eventplot',\n",
       " 'figaspect',\n",
       " 'figimage',\n",
       " 'figlegend',\n",
       " 'fignum_exists',\n",
       " 'figtext',\n",
       " 'figure',\n",
       " 'fill',\n",
       " 'fill_between',\n",
       " 'fill_betweenx',\n",
       " 'findobj',\n",
       " 'flag',\n",
       " 'functools',\n",
       " 'gca',\n",
       " 'gcf',\n",
       " 'gci',\n",
       " 'get',\n",
       " 'get_backend',\n",
       " 'get_cmap',\n",
       " 'get_current_fig_manager',\n",
       " 'get_figlabels',\n",
       " 'get_fignums',\n",
       " 'get_plot_commands',\n",
       " 'get_scale_names',\n",
       " 'getp',\n",
       " 'ginput',\n",
       " 'gray',\n",
       " 'grid',\n",
       " 'hexbin',\n",
       " 'hist',\n",
       " 'hist2d',\n",
       " 'hlines',\n",
       " 'hot',\n",
       " 'hsv',\n",
       " 'importlib',\n",
       " 'imread',\n",
       " 'imsave',\n",
       " 'imshow',\n",
       " 'inferno',\n",
       " 'inspect',\n",
       " 'install_repl_displayhook',\n",
       " 'interactive',\n",
       " 'ioff',\n",
       " 'ion',\n",
       " 'isinteractive',\n",
       " 'jet',\n",
       " 'legend',\n",
       " 'locator_params',\n",
       " 'logging',\n",
       " 'loglog',\n",
       " 'magma',\n",
       " 'magnitude_spectrum',\n",
       " 'margins',\n",
       " 'matplotlib',\n",
       " 'matshow',\n",
       " 'minorticks_off',\n",
       " 'minorticks_on',\n",
       " 'mlab',\n",
       " 'new_figure_manager',\n",
       " 'nipy_spectral',\n",
       " 'np',\n",
       " 'pause',\n",
       " 'pcolor',\n",
       " 'pcolormesh',\n",
       " 'phase_spectrum',\n",
       " 'pie',\n",
       " 'pink',\n",
       " 'plasma',\n",
       " 'plot',\n",
       " 'plot_date',\n",
       " 'plotting',\n",
       " 'polar',\n",
       " 'prism',\n",
       " 'psd',\n",
       " 'quiver',\n",
       " 'quiverkey',\n",
       " 'rc',\n",
       " 'rcParams',\n",
       " 'rcParamsDefault',\n",
       " 'rcParamsOrig',\n",
       " 'rc_context',\n",
       " 'rcdefaults',\n",
       " 'rcsetup',\n",
       " 're',\n",
       " 'register_cmap',\n",
       " 'rgrids',\n",
       " 'savefig',\n",
       " 'sca',\n",
       " 'scatter',\n",
       " 'sci',\n",
       " 'semilogx',\n",
       " 'semilogy',\n",
       " 'set_cmap',\n",
       " 'set_loglevel',\n",
       " 'setp',\n",
       " 'show',\n",
       " 'specgram',\n",
       " 'spring',\n",
       " 'spy',\n",
       " 'stackplot',\n",
       " 'stairs',\n",
       " 'stem',\n",
       " 'step',\n",
       " 'streamplot',\n",
       " 'style',\n",
       " 'subplot',\n",
       " 'subplot2grid',\n",
       " 'subplot_mosaic',\n",
       " 'subplot_tool',\n",
       " 'subplots',\n",
       " 'subplots_adjust',\n",
       " 'summer',\n",
       " 'suptitle',\n",
       " 'switch_backend',\n",
       " 'sys',\n",
       " 'table',\n",
       " 'text',\n",
       " 'thetagrids',\n",
       " 'threading',\n",
       " 'tick_params',\n",
       " 'ticklabel_format',\n",
       " 'tight_layout',\n",
       " 'time',\n",
       " 'title',\n",
       " 'tricontour',\n",
       " 'tricontourf',\n",
       " 'tripcolor',\n",
       " 'triplot',\n",
       " 'twinx',\n",
       " 'twiny',\n",
       " 'uninstall_repl_displayhook',\n",
       " 'violinplot',\n",
       " 'viridis',\n",
       " 'vlines',\n",
       " 'waitforbuttonpress',\n",
       " 'winter',\n",
       " 'xcorr',\n",
       " 'xkcd',\n",
       " 'xlabel',\n",
       " 'xlim',\n",
       " 'xscale',\n",
       " 'xticks',\n",
       " 'ylabel',\n",
       " 'ylim',\n",
       " 'yscale',\n",
       " 'yticks']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4fd5d6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "97e804a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fdf85b6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6],\n",
       "       [9],\n",
       "       [9],\n",
       "       [4],\n",
       "       [1]], dtype=uint8)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "72b43b79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 9, 9, 4, 1], dtype=uint8)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y_train.reshape(-1,)\n",
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3e78a4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = y_train.reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0f94c7a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'truck'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0d7526f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['airplane',\n",
       " 'automobile',\n",
       " 'bird',\n",
       " 'cat',\n",
       " 'deer',\n",
       " 'dog',\n",
       " 'frog',\n",
       " 'horse',\n",
       " 'ship',\n",
       " 'truck']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "75500204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 32, 32, 3)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6074dc7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "398ef513",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_sample(X, y, index):\n",
    "    plt.figure(figsize = (15,2))\n",
    "    plt.imshow(X[index])\n",
    "    plt.xlabel(classes[y[index]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f8d9dd67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_sample(X_train, y_train, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4711c625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_sample(X_train, y_train, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "342a5576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To normalize to 1 from 0 range\n",
    "X_train = X_train /255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d26d2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/codebasics/deep-learning-keras-tf-tutorial/blob/master/16_cnn_cifar10_small_image_classification/cnn_cifar10_dataset.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f7a1fffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Moje_programy\\envs\\ZMWD1\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Train on 50000 samples\n",
      "Epoch 1/5\n",
      "50000/50000 [==============================] - 143s 3ms/sample - loss: 1.8095 - acc: 0.3574\n",
      "Epoch 2/5\n",
      "50000/50000 [==============================] - 100s 2ms/sample - loss: 1.6251 - acc: 0.4277\n",
      "Epoch 3/5\n",
      "50000/50000 [==============================] - 124s 2ms/sample - loss: 1.5423 - acc: 0.4581\n",
      "Epoch 4/5\n",
      "50000/50000 [==============================] - 106s 2ms/sample - loss: 1.4828 - acc: 0.4764\n",
      "Epoch 5/5\n",
      "50000/50000 [==============================] - 127s 3ms/sample - loss: 1.4337 - acc: 0.4962\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x27d51a79448>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann = models.Sequential([\n",
    "        layers.Flatten(input_shape=(32,32,3)),\n",
    "        layers.Dense(3000, activation='relu'),\n",
    "        layers.Dense(1000, activation='relu'),\n",
    "        layers.Dense(10, activation='softmax')    \n",
    "    ])\n",
    "\n",
    "ann.compile(optimizer='SGD',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "ann.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a47d134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we can see, accuracy of the ANN gives bad results. That's why\n",
    "# it's not good idea to use ANN(Artificial neural network) for images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5b6b29d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 15s 1ms/sample - loss: 1.4963 - acc: 0.4623\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4962767467498779, 0.4623]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3296431d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ac7440dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 32, 32, 3)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f9895c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifiaction Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.38      0.48      1000\n",
      "           1       0.58      0.55      0.57      1000\n",
      "           2       0.32      0.51      0.39      1000\n",
      "           3       0.39      0.21      0.27      1000\n",
      "           4       0.58      0.24      0.34      1000\n",
      "           5       0.43      0.34      0.38      1000\n",
      "           6       0.51      0.59      0.55      1000\n",
      "           7       0.63      0.44      0.52      1000\n",
      "           8       0.62      0.57      0.59      1000\n",
      "           9       0.33      0.80      0.47      1000\n",
      "\n",
      "    accuracy                           0.46     10000\n",
      "   macro avg       0.51      0.46      0.46     10000\n",
      "weighted avg       0.51      0.46      0.46     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "y_pred = ann.predict(X_test)\n",
    "y_pred_classes = [np.argmax(element) for element in y_pred]\n",
    "\n",
    "print(\"Classifiaction Report: \\n\", classification_report(y_test, y_pred_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ff87cbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4d33d78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = models.Sequential([\n",
    "        # CNN figures out filters for me. I don't have to tell what the filters are\n",
    "        # \n",
    "        layers.Conv2D(filters = 32, kernel_size = (3,3), activation = 'relu', input_shape = (32,32,3)),\n",
    "        layers.MaxPooling2D((2,2)),\n",
    "    \n",
    "        layers.Conv2D(filters = 64, kernel_size = (3,3), activation = 'relu'),\n",
    "        layers.MaxPooling2D((2,2)),\n",
    "        # cnn\n",
    "        # dense\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(10, activation='softmax')    \n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7b942f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer = 'adam',\n",
    "             loss= 'sparse_categorical_crossentropy',\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dcbedd90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples\n",
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 120s 2ms/sample - loss: 1.4397 - acc: 0.4822\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 89s 2ms/sample - loss: 1.0830 - acc: 0.6221\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 75s 1ms/sample - loss: 0.9613 - acc: 0.6647\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 66s 1ms/sample - loss: 0.8727 - acc: 0.6966\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 58s 1ms/sample - loss: 0.8055 - acc: 0.7190\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 57s 1ms/sample - loss: 0.7529 - acc: 0.7382\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 91s 2ms/sample - loss: 0.7048 - acc: 0.7555\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 57s 1ms/sample - loss: 0.6631 - acc: 0.7691\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 56s 1ms/sample - loss: 0.6231 - acc: 0.78210s - loss: 0.6230 - acc: 0.7\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 53s 1ms/sample - loss: 0.5935 - acc: 0.7911\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x27d67b41048>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6a29cfc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 7s 681us/sample - loss: 0.9236 - acc: 0.7047\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9235618158340454, 0.7047]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "de1f4d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy is pretty good for CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3b309f23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3],\n",
       "       [8],\n",
       "       [8],\n",
       "       [0],\n",
       "       [6]], dtype=uint8)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "153f411e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 8, 8, ..., 5, 1, 7], dtype=uint8)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = y_test.reshape(-1,)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c0c6c252",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_sample(X_test, y_test,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "eaf8eaa9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.0505787e-05, 5.9719951e-06, 6.3058711e-03, 9.6535927e-01,\n",
       "        1.5859898e-04, 1.4435811e-02, 1.3188121e-02, 1.2363952e-05,\n",
       "        4.8341480e-04, 5.9449686e-08],\n",
       "       [5.8245822e-03, 3.5027775e-03, 1.0642126e-06, 3.3753231e-06,\n",
       "        9.9930190e-08, 6.3181169e-08, 2.3795019e-08, 4.8925517e-09,\n",
       "        9.9010205e-01, 5.6595478e-04],\n",
       "       [1.5622160e-01, 4.0673593e-01, 1.2389894e-03, 1.3168112e-02,\n",
       "        3.5429880e-04, 1.0014771e-03, 2.6696187e-04, 8.8750880e-04,\n",
       "        3.9136121e-01, 2.8763974e-02],\n",
       "       [9.7660756e-01, 4.8101461e-05, 1.7542535e-02, 1.8342527e-05,\n",
       "        2.0569640e-04, 1.6939417e-06, 2.5356939e-04, 6.4095747e-07,\n",
       "        5.3214431e-03, 1.7857847e-07],\n",
       "       [6.0622507e-09, 2.7468408e-07, 3.9138864e-03, 2.1217118e-03,\n",
       "        9.6598439e-02, 1.6173075e-05, 8.9734864e-01, 1.7514289e-08,\n",
       "        8.8948343e-07, 1.5264200e-09]], dtype=float32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = cnn.predict(X_test)\n",
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "28eac832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax([5,12,167,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7254e884",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8f2ca36c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 8, 1, 0, 6]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_classes = [np.argmax(element) for element in y_pred]\n",
    "y_classes[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d320366f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 8, 8, 0, 6], dtype=uint8)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "41e20ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_sample(X_test, y_test, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "401b747c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['airplane',\n",
       " 'automobile',\n",
       " 'bird',\n",
       " 'cat',\n",
       " 'deer',\n",
       " 'dog',\n",
       " 'frog',\n",
       " 'horse',\n",
       " 'ship',\n",
       " 'truck']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c64962c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ship'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes[y_classes[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb9e42f",
   "metadata": {},
   "source": [
    "# Handwritten digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b7256808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_module_wrapper',\n",
       " '_sys',\n",
       " 'load_data']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(datasets.mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "4c2cd4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train),(X_test, y_test) = datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3b5cd326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x27dc5662a48>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "f56ba793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c8f5a65c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "231c1134",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "499b2e1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "cd8625eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train /255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cd19abfa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Model',\n",
       " 'Sequential',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_module_wrapper',\n",
       " '_sys',\n",
       " 'clone_model',\n",
       " 'load_model',\n",
       " 'model_from_config',\n",
       " 'model_from_json',\n",
       " 'model_from_yaml',\n",
       " 'save_model']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "865dd47a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Sequential in module tensorflow.python.keras.engine.sequential:\n",
      "\n",
      "class Sequential(tensorflow.python.keras.engine.training.Model)\n",
      " |  Sequential(layers=None, name=None)\n",
      " |  \n",
      " |  Linear stack of layers.\n",
      " |  \n",
      " |  Arguments:\n",
      " |      layers: list of layers to add to the model.\n",
      " |  \n",
      " |  Example:\n",
      " |  \n",
      " |  ```python\n",
      " |  # Optionally, the first layer can receive an `input_shape` argument:\n",
      " |  model = Sequential()\n",
      " |  model.add(Dense(32, input_shape=(500,)))\n",
      " |  # Afterwards, we do automatic shape inference:\n",
      " |  model.add(Dense(32))\n",
      " |  \n",
      " |  # This is identical to the following:\n",
      " |  model = Sequential()\n",
      " |  model.add(Dense(32, input_dim=500))\n",
      " |  \n",
      " |  # And to the following:\n",
      " |  model = Sequential()\n",
      " |  model.add(Dense(32, batch_input_shape=(None, 500)))\n",
      " |  \n",
      " |  # Note that you can also omit the `input_shape` argument:\n",
      " |  # In that case the model gets built the first time you call `fit` (or other\n",
      " |  # training and evaluation methods).\n",
      " |  model = Sequential()\n",
      " |  model.add(Dense(32))\n",
      " |  model.add(Dense(32))\n",
      " |  model.compile(optimizer=optimizer, loss=loss)\n",
      " |  # This builds the model for the first time:\n",
      " |  model.fit(x, y, batch_size=32, epochs=10)\n",
      " |  \n",
      " |  # Note that when using this delayed-build pattern (no input shape specified),\n",
      " |  # the model doesn't have any weights until the first call\n",
      " |  # to a training/evaluation method (since it isn't yet built):\n",
      " |  model = Sequential()\n",
      " |  model.add(Dense(32))\n",
      " |  model.add(Dense(32))\n",
      " |  model.weights  # returns []\n",
      " |  \n",
      " |  # Whereas if you specify the input shape, the model gets built continuously\n",
      " |  # as you are adding layers:\n",
      " |  model = Sequential()\n",
      " |  model.add(Dense(32, input_shape=(500,)))\n",
      " |  model.add(Dense(32))\n",
      " |  model.weights  # returns list of length 4\n",
      " |  \n",
      " |  # When using the delayed-build pattern (no input shape specified), you can\n",
      " |  # choose to manually build your model by calling `build(batch_input_shape)`:\n",
      " |  model = Sequential()\n",
      " |  model.add(Dense(32))\n",
      " |  model.add(Dense(32))\n",
      " |  model.build((None, 500))\n",
      " |  model.weights  # returns list of length 4\n",
      " |  ```\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Sequential\n",
      " |      tensorflow.python.keras.engine.training.Model\n",
      " |      tensorflow.python.keras.engine.network.Network\n",
      " |      tensorflow.python.keras.engine.base_layer.Layer\n",
      " |      tensorflow.python.module.module.Module\n",
      " |      tensorflow.python.training.tracking.tracking.AutoTrackable\n",
      " |      tensorflow.python.training.tracking.base.Trackable\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, layers=None, name=None)\n",
      " |  \n",
      " |  add(self, layer)\n",
      " |      Adds a layer instance on top of the layer stack.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          layer: layer instance.\n",
      " |      \n",
      " |      Raises:\n",
      " |          TypeError: If `layer` is not a layer instance.\n",
      " |          ValueError: In case the `layer` argument does not\n",
      " |              know its input shape.\n",
      " |          ValueError: In case the `layer` argument has\n",
      " |              multiple output tensors, or is already connected\n",
      " |              somewhere else (forbidden in `Sequential` models).\n",
      " |  \n",
      " |  build(self, input_shape=None)\n",
      " |      Builds the model based on input shapes received.\n",
      " |      \n",
      " |      This is to be used for subclassed models, which do not know at instantiation\n",
      " |      time what their inputs look like.\n",
      " |      \n",
      " |      This method only exists for users who want to call `model.build()` in a\n",
      " |      standalone way (as a substitute for calling the model on real data to\n",
      " |      build it). It will never be called by the framework (and thus it will\n",
      " |      never throw unexpected errors in an unrelated workflow).\n",
      " |      \n",
      " |      Args:\n",
      " |       input_shape: Single tuple, TensorShape, or list of shapes, where shapes\n",
      " |           are tuples, integers, or TensorShapes.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError:\n",
      " |          1. In case of invalid user-provided data (not of type tuple,\n",
      " |             list, or TensorShape).\n",
      " |          2. If the model requires call arguments that are agnostic\n",
      " |             to the input shapes (positional or kwarg in call signature).\n",
      " |          3. If not all layers were properly built.\n",
      " |          4. If float type inputs are not supported within the layers.\n",
      " |      \n",
      " |        In each of these cases, the user should build their model by calling it\n",
      " |        on real tensor data.\n",
      " |  \n",
      " |  call(self, inputs, training=None, mask=None)\n",
      " |      Calls the model on new inputs.\n",
      " |      \n",
      " |      In this case `call` just reapplies\n",
      " |      all ops in the graph to the new inputs\n",
      " |      (e.g. build a new computational graph from the provided inputs).\n",
      " |      \n",
      " |      Arguments:\n",
      " |          inputs: A tensor or list of tensors.\n",
      " |          training: Boolean or boolean scalar tensor, indicating whether to run\n",
      " |            the `Network` in training mode or inference mode.\n",
      " |          mask: A mask or list of masks. A mask can be\n",
      " |              either a tensor or None (no mask).\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor if there is a single output, or\n",
      " |          a list of tensors if there are more than one outputs.\n",
      " |  \n",
      " |  compute_mask(self, inputs, mask)\n",
      " |      Computes an output mask tensor.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          inputs: Tensor or list of tensors.\n",
      " |          mask: Tensor or list of tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |          None or a tensor (or list of tensors,\n",
      " |              one per output tensor of the layer).\n",
      " |  \n",
      " |  compute_output_shape(self, input_shape)\n",
      " |      Computes the output shape of the layer.\n",
      " |      \n",
      " |      If the layer has not been built, this method will call `build` on the\n",
      " |      layer. This assumes that the layer will later be used with inputs that\n",
      " |      match the input shape provided here.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          input_shape: Shape tuple (tuple of integers)\n",
      " |              or list of shape tuples (one per output tensor of the layer).\n",
      " |              Shape tuples can include None for free dimensions,\n",
      " |              instead of an integer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An input shape tuple.\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the config of the layer.\n",
      " |      \n",
      " |      A layer config is a Python dictionary (serializable)\n",
      " |      containing the configuration of a layer.\n",
      " |      The same layer can be reinstantiated later\n",
      " |      (without its trained weights) from this configuration.\n",
      " |      \n",
      " |      The config of a layer does not include connectivity\n",
      " |      information, nor the layer class name. These are handled\n",
      " |      by `Network` (one layer of abstraction above).\n",
      " |      \n",
      " |      Returns:\n",
      " |          Python dictionary.\n",
      " |  \n",
      " |  pop(self)\n",
      " |      Removes the last layer in the model.\n",
      " |      \n",
      " |      Raises:\n",
      " |          TypeError: if there are no layers in the model.\n",
      " |  \n",
      " |  predict_classes(self, x, batch_size=32, verbose=0)\n",
      " |      Generate class predictions for the input samples.\n",
      " |      \n",
      " |      The input samples are processed batch by batch.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: input data, as a Numpy array or list of Numpy arrays\n",
      " |              (if the model has multiple inputs).\n",
      " |          batch_size: integer.\n",
      " |          verbose: verbosity mode, 0 or 1.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A numpy array of class predictions.\n",
      " |  \n",
      " |  predict_proba(self, x, batch_size=32, verbose=0)\n",
      " |      Generates class probability predictions for the input samples.\n",
      " |      \n",
      " |      The input samples are processed batch by batch.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: input data, as a Numpy array or list of Numpy arrays\n",
      " |              (if the model has multiple inputs).\n",
      " |          batch_size: integer.\n",
      " |          verbose: verbosity mode, 0 or 1.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A Numpy array of probability predictions.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  from_config(config, custom_objects=None) from builtins.type\n",
      " |      Instantiates a Model from its config (output of `get_config()`).\n",
      " |      \n",
      " |      Arguments:\n",
      " |          config: Model config dictionary.\n",
      " |          custom_objects: Optional dictionary mapping names\n",
      " |              (strings) to custom classes or functions to be\n",
      " |              considered during deserialization.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A model instance.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: In case of improperly formatted config dict.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  dynamic\n",
      " |  \n",
      " |  input_spec\n",
      " |      Gets the network's input specs.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A list of `InputSpec` instances (one per input to the model)\n",
      " |              or a single instance if the model has only one input.\n",
      " |  \n",
      " |  layers\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tensorflow.python.keras.engine.training.Model:\n",
      " |  \n",
      " |  compile(self, optimizer='rmsprop', loss=None, metrics=None, loss_weights=None, sample_weight_mode=None, weighted_metrics=None, target_tensors=None, distribute=None, **kwargs)\n",
      " |      Configures the model for training.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          optimizer: String (name of optimizer) or optimizer instance.\n",
      " |              See `tf.keras.optimizers`.\n",
      " |          loss: String (name of objective function), objective function or\n",
      " |              `tf.losses.Loss` instance. See `tf.losses`. If the model has\n",
      " |              multiple outputs, you can use a different loss on each output by\n",
      " |              passing a dictionary or a list of losses. The loss value that will\n",
      " |              be minimized by the model will then be the sum of all individual\n",
      " |              losses.\n",
      " |          metrics: List of metrics to be evaluated by the model during training\n",
      " |              and testing. Typically you will use `metrics=['accuracy']`.\n",
      " |              To specify different metrics for different outputs of a\n",
      " |              multi-output model, you could also pass a dictionary, such as\n",
      " |              `metrics={'output_a': 'accuracy', 'output_b': ['accuracy', 'mse']}`.\n",
      " |              You can also pass a list (len = len(outputs)) of lists of metrics\n",
      " |              such as `metrics=[['accuracy'], ['accuracy', 'mse']]` or\n",
      " |              `metrics=['accuracy', ['accuracy', 'mse']]`.\n",
      " |          loss_weights: Optional list or dictionary specifying scalar\n",
      " |              coefficients (Python floats) to weight the loss contributions\n",
      " |              of different model outputs.\n",
      " |              The loss value that will be minimized by the model\n",
      " |              will then be the *weighted sum* of all individual losses,\n",
      " |              weighted by the `loss_weights` coefficients.\n",
      " |              If a list, it is expected to have a 1:1 mapping\n",
      " |              to the model's outputs. If a tensor, it is expected to map\n",
      " |              output names (strings) to scalar coefficients.\n",
      " |          sample_weight_mode: If you need to do timestep-wise\n",
      " |              sample weighting (2D weights), set this to `\"temporal\"`.\n",
      " |              `None` defaults to sample-wise weights (1D).\n",
      " |              If the model has multiple outputs, you can use a different\n",
      " |              `sample_weight_mode` on each output by passing a\n",
      " |              dictionary or a list of modes.\n",
      " |          weighted_metrics: List of metrics to be evaluated and weighted\n",
      " |              by sample_weight or class_weight during training and testing.\n",
      " |          target_tensors: By default, Keras will create placeholders for the\n",
      " |              model's target, which will be fed with the target data during\n",
      " |              training. If instead you would like to use your own\n",
      " |              target tensors (in turn, Keras will not expect external\n",
      " |              Numpy data for these targets at training time), you\n",
      " |              can specify them via the `target_tensors` argument. It can be\n",
      " |              a single tensor (for a single-output model), a list of tensors,\n",
      " |              or a dict mapping output names to target tensors.\n",
      " |          distribute: NOT SUPPORTED IN TF 2.0, please create and compile the\n",
      " |              model under distribution strategy scope instead of passing it to\n",
      " |              compile.\n",
      " |          **kwargs: Any additional arguments.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: In case of invalid arguments for\n",
      " |              `optimizer`, `loss`, `metrics` or `sample_weight_mode`.\n",
      " |  \n",
      " |  evaluate(self, x=None, y=None, batch_size=None, verbose=1, sample_weight=None, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
      " |      Returns the loss value & metrics values for the model in test mode.\n",
      " |      \n",
      " |      Computation is done in batches.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: Input data. It could be:\n",
      " |            - A Numpy array (or array-like), or a list of arrays\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A TensorFlow tensor, or a list of tensors\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A dict mapping input names to the corresponding array/tensors,\n",
      " |              if the model has named inputs.\n",
      " |            - A `tf.data` dataset.\n",
      " |            - A generator or `keras.utils.Sequence` instance.\n",
      " |          y: Target data. Like the input data `x`,\n",
      " |            it could be either Numpy array(s) or TensorFlow tensor(s).\n",
      " |            It should be consistent with `x` (you cannot have Numpy inputs and\n",
      " |            tensor targets, or inversely).\n",
      " |            If `x` is a dataset, generator or\n",
      " |            `keras.utils.Sequence` instance, `y` should not be specified (since\n",
      " |            targets will be obtained from the iterator/dataset).\n",
      " |          batch_size: Integer or `None`.\n",
      " |              Number of samples per gradient update.\n",
      " |              If unspecified, `batch_size` will default to 32.\n",
      " |              Do not specify the `batch_size` is your data is in the\n",
      " |              form of symbolic tensors, dataset,\n",
      " |              generators, or `keras.utils.Sequence` instances (since they generate\n",
      " |              batches).\n",
      " |          verbose: 0 or 1. Verbosity mode.\n",
      " |              0 = silent, 1 = progress bar.\n",
      " |          sample_weight: Optional Numpy array of weights for\n",
      " |              the test samples, used for weighting the loss function.\n",
      " |              You can either pass a flat (1D)\n",
      " |              Numpy array with the same length as the input samples\n",
      " |              (1:1 mapping between weights and samples),\n",
      " |              or in the case of temporal data,\n",
      " |              you can pass a 2D array with shape\n",
      " |              `(samples, sequence_length)`,\n",
      " |              to apply a different weight to every timestep of every sample.\n",
      " |              In this case you should make sure to specify\n",
      " |              `sample_weight_mode=\"temporal\"` in `compile()`. This argument is not\n",
      " |              supported when `x` is a dataset, instead pass\n",
      " |              sample weights as the third element of `x`.\n",
      " |          steps: Integer or `None`.\n",
      " |              Total number of steps (batches of samples)\n",
      " |              before declaring the evaluation round finished.\n",
      " |              Ignored with the default value of `None`.\n",
      " |              If x is a `tf.data` dataset and `steps` is\n",
      " |              None, 'evaluate' will run until the dataset is exhausted.\n",
      " |              This argument is not supported with array inputs.\n",
      " |          callbacks: List of `keras.callbacks.Callback` instances.\n",
      " |              List of callbacks to apply during evaluation.\n",
      " |              See [callbacks](/api_docs/python/tf/keras/callbacks).\n",
      " |          max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
      " |              input only. Maximum size for the generator queue.\n",
      " |              If unspecified, `max_queue_size` will default to 10.\n",
      " |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
      " |              only. Maximum number of processes to spin up when using\n",
      " |              process-based threading. If unspecified, `workers` will default\n",
      " |              to 1. If 0, will execute the generator on the main thread.\n",
      " |          use_multiprocessing: Boolean. Used for generator or\n",
      " |              `keras.utils.Sequence` input only. If `True`, use process-based\n",
      " |              threading. If unspecified, `use_multiprocessing` will default to\n",
      " |              `False`. Note that because this implementation relies on\n",
      " |              multiprocessing, you should not pass non-picklable arguments to\n",
      " |              the generator as they can't be passed easily to children processes.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Scalar test loss (if the model has a single output and no metrics)\n",
      " |          or list of scalars (if the model has multiple outputs\n",
      " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      " |          the display labels for the scalar outputs.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: in case of invalid arguments.\n",
      " |  \n",
      " |  evaluate_generator(self, generator, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)\n",
      " |      Evaluates the model on a data generator.\n",
      " |      \n",
      " |      The generator should return the same kind of data\n",
      " |      as accepted by `test_on_batch`.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          generator: Generator yielding tuples (inputs, targets)\n",
      " |              or (inputs, targets, sample_weights)\n",
      " |              or an instance of `keras.utils.Sequence`\n",
      " |              object in order to avoid duplicate data\n",
      " |              when using multiprocessing.\n",
      " |          steps: Total number of steps (batches of samples)\n",
      " |              to yield from `generator` before stopping.\n",
      " |              Optional for `Sequence`: if unspecified, will use\n",
      " |              the `len(generator)` as a number of steps.\n",
      " |          callbacks: List of `keras.callbacks.Callback` instances.\n",
      " |              List of callbacks to apply during evaluation.\n",
      " |              See [callbacks](/api_docs/python/tf/keras/callbacks).\n",
      " |          max_queue_size: maximum size for the generator queue\n",
      " |          workers: Integer. Maximum number of processes to spin up\n",
      " |              when using process-based threading.\n",
      " |              If unspecified, `workers` will default to 1. If 0, will\n",
      " |              execute the generator on the main thread.\n",
      " |          use_multiprocessing: Boolean.\n",
      " |              If `True`, use process-based threading.\n",
      " |              If unspecified, `use_multiprocessing` will default to `False`.\n",
      " |              Note that because this implementation relies on multiprocessing,\n",
      " |              you should not pass non-picklable arguments to the generator\n",
      " |              as they can't be passed easily to children processes.\n",
      " |          verbose: Verbosity mode, 0 or 1.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Scalar test loss (if the model has a single output and no metrics)\n",
      " |          or list of scalars (if the model has multiple outputs\n",
      " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      " |          the display labels for the scalar outputs.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: in case of invalid arguments.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: In case the generator yields data in an invalid format.\n",
      " |  \n",
      " |  fit(self, x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, validation_freq=1, max_queue_size=10, workers=1, use_multiprocessing=False, **kwargs)\n",
      " |      Trains the model for a fixed number of epochs (iterations on a dataset).\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: Input data. It could be:\n",
      " |            - A Numpy array (or array-like), or a list of arrays\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A TensorFlow tensor, or a list of tensors\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A dict mapping input names to the corresponding array/tensors,\n",
      " |              if the model has named inputs.\n",
      " |            - A `tf.data` dataset. Should return a tuple\n",
      " |              of either `(inputs, targets)` or\n",
      " |              `(inputs, targets, sample_weights)`.\n",
      " |            - A generator or `keras.utils.Sequence` returning `(inputs, targets)`\n",
      " |              or `(inputs, targets, sample weights)`.\n",
      " |          y: Target data. Like the input data `x`,\n",
      " |            it could be either Numpy array(s) or TensorFlow tensor(s).\n",
      " |            It should be consistent with `x` (you cannot have Numpy inputs and\n",
      " |            tensor targets, or inversely). If `x` is a dataset, generator,\n",
      " |            or `keras.utils.Sequence` instance, `y` should\n",
      " |            not be specified (since targets will be obtained from `x`).\n",
      " |          batch_size: Integer or `None`.\n",
      " |              Number of samples per gradient update.\n",
      " |              If unspecified, `batch_size` will default to 32.\n",
      " |              Do not specify the `batch_size` if your data is in the\n",
      " |              form of symbolic tensors, datasets,\n",
      " |              generators, or `keras.utils.Sequence` instances (since they generate\n",
      " |              batches).\n",
      " |          epochs: Integer. Number of epochs to train the model.\n",
      " |              An epoch is an iteration over the entire `x` and `y`\n",
      " |              data provided.\n",
      " |              Note that in conjunction with `initial_epoch`,\n",
      " |              `epochs` is to be understood as \"final epoch\".\n",
      " |              The model is not trained for a number of iterations\n",
      " |              given by `epochs`, but merely until the epoch\n",
      " |              of index `epochs` is reached.\n",
      " |          verbose: 0, 1, or 2. Verbosity mode.\n",
      " |              0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
      " |              Note that the progress bar is not particularly useful when\n",
      " |              logged to a file, so verbose=2 is recommended when not running\n",
      " |              interactively (eg, in a production environment).\n",
      " |          callbacks: List of `keras.callbacks.Callback` instances.\n",
      " |              List of callbacks to apply during training.\n",
      " |              See `tf.keras.callbacks`.\n",
      " |          validation_split: Float between 0 and 1.\n",
      " |              Fraction of the training data to be used as validation data.\n",
      " |              The model will set apart this fraction of the training data,\n",
      " |              will not train on it, and will evaluate\n",
      " |              the loss and any model metrics\n",
      " |              on this data at the end of each epoch.\n",
      " |              The validation data is selected from the last samples\n",
      " |              in the `x` and `y` data provided, before shuffling. This argument is\n",
      " |              not supported when `x` is a dataset, generator or\n",
      " |             `keras.utils.Sequence` instance.\n",
      " |          validation_data: Data on which to evaluate\n",
      " |              the loss and any model metrics at the end of each epoch.\n",
      " |              The model will not be trained on this data.\n",
      " |              `validation_data` will override `validation_split`.\n",
      " |              `validation_data` could be:\n",
      " |                - tuple `(x_val, y_val)` of Numpy arrays or tensors\n",
      " |                - tuple `(x_val, y_val, val_sample_weights)` of Numpy arrays\n",
      " |                - dataset\n",
      " |              For the first two cases, `batch_size` must be provided.\n",
      " |              For the last case, `validation_steps` must be provided.\n",
      " |          shuffle: Boolean (whether to shuffle the training data\n",
      " |              before each epoch) or str (for 'batch').\n",
      " |              'batch' is a special option for dealing with the\n",
      " |              limitations of HDF5 data; it shuffles in batch-sized chunks.\n",
      " |              Has no effect when `steps_per_epoch` is not `None`.\n",
      " |          class_weight: Optional dictionary mapping class indices (integers)\n",
      " |              to a weight (float) value, used for weighting the loss function\n",
      " |              (during training only).\n",
      " |              This can be useful to tell the model to\n",
      " |              \"pay more attention\" to samples from\n",
      " |              an under-represented class.\n",
      " |          sample_weight: Optional Numpy array of weights for\n",
      " |              the training samples, used for weighting the loss function\n",
      " |              (during training only). You can either pass a flat (1D)\n",
      " |              Numpy array with the same length as the input samples\n",
      " |              (1:1 mapping between weights and samples),\n",
      " |              or in the case of temporal data,\n",
      " |              you can pass a 2D array with shape\n",
      " |              `(samples, sequence_length)`,\n",
      " |              to apply a different weight to every timestep of every sample.\n",
      " |              In this case you should make sure to specify\n",
      " |              `sample_weight_mode=\"temporal\"` in `compile()`. This argument is not\n",
      " |              supported when `x` is a dataset, generator, or\n",
      " |             `keras.utils.Sequence` instance, instead provide the sample_weights\n",
      " |              as the third element of `x`.\n",
      " |          initial_epoch: Integer.\n",
      " |              Epoch at which to start training\n",
      " |              (useful for resuming a previous training run).\n",
      " |          steps_per_epoch: Integer or `None`.\n",
      " |              Total number of steps (batches of samples)\n",
      " |              before declaring one epoch finished and starting the\n",
      " |              next epoch. When training with input tensors such as\n",
      " |              TensorFlow data tensors, the default `None` is equal to\n",
      " |              the number of samples in your dataset divided by\n",
      " |              the batch size, or 1 if that cannot be determined. If x is a\n",
      " |              `tf.data` dataset, and 'steps_per_epoch'\n",
      " |              is None, the epoch will run until the input dataset is exhausted.\n",
      " |              This argument is not supported with array inputs.\n",
      " |          validation_steps: Only relevant if `validation_data` is provided and\n",
      " |              is a `tf.data` dataset. Total number of steps (batches of\n",
      " |              samples) to draw before stopping when performing validation\n",
      " |              at the end of every epoch. If validation_data is a `tf.data` dataset\n",
      " |              and 'validation_steps' is None, validation\n",
      " |              will run until the `validation_data` dataset is exhausted.\n",
      " |          validation_freq: Only relevant if validation data is provided. Integer\n",
      " |              or `collections_abc.Container` instance (e.g. list, tuple, etc.).\n",
      " |              If an integer, specifies how many training epochs to run before a\n",
      " |              new validation run is performed, e.g. `validation_freq=2` runs\n",
      " |              validation every 2 epochs. If a Container, specifies the epochs on\n",
      " |              which to run validation, e.g. `validation_freq=[1, 2, 10]` runs\n",
      " |              validation at the end of the 1st, 2nd, and 10th epochs.\n",
      " |          max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
      " |              input only. Maximum size for the generator queue.\n",
      " |              If unspecified, `max_queue_size` will default to 10.\n",
      " |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
      " |              only. Maximum number of processes to spin up\n",
      " |              when using process-based threading. If unspecified, `workers`\n",
      " |              will default to 1. If 0, will execute the generator on the main\n",
      " |              thread.\n",
      " |          use_multiprocessing: Boolean. Used for generator or\n",
      " |              `keras.utils.Sequence` input only. If `True`, use process-based\n",
      " |              threading. If unspecified, `use_multiprocessing` will default to\n",
      " |              `False`. Note that because this implementation relies on\n",
      " |              multiprocessing, you should not pass non-picklable arguments to\n",
      " |              the generator as they can't be passed easily to children processes.\n",
      " |          **kwargs: Used for backwards compatibility.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A `History` object. Its `History.history` attribute is\n",
      " |          a record of training loss values and metrics values\n",
      " |          at successive epochs, as well as validation loss values\n",
      " |          and validation metrics values (if applicable).\n",
      " |      \n",
      " |      Raises:\n",
      " |          RuntimeError: If the model was never compiled.\n",
      " |          ValueError: In case of mismatch between the provided input data\n",
      " |              and what the model expects.\n",
      " |  \n",
      " |  fit_generator(self, generator, steps_per_epoch=None, epochs=1, verbose=1, callbacks=None, validation_data=None, validation_steps=None, validation_freq=1, class_weight=None, max_queue_size=10, workers=1, use_multiprocessing=False, shuffle=True, initial_epoch=0)\n",
      " |      Fits the model on data yielded batch-by-batch by a Python generator.\n",
      " |      \n",
      " |      The generator is run in parallel to the model, for efficiency.\n",
      " |      For instance, this allows you to do real-time data augmentation\n",
      " |      on images on CPU in parallel to training your model on GPU.\n",
      " |      \n",
      " |      The use of `keras.utils.Sequence` guarantees the ordering\n",
      " |      and guarantees the single use of every input per epoch when\n",
      " |      using `use_multiprocessing=True`.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          generator: A generator or an instance of `Sequence`\n",
      " |            (`keras.utils.Sequence`)\n",
      " |              object in order to avoid duplicate data\n",
      " |              when using multiprocessing.\n",
      " |              The output of the generator must be either\n",
      " |              - a tuple `(inputs, targets)`\n",
      " |              - a tuple `(inputs, targets, sample_weights)`.\n",
      " |              This tuple (a single output of the generator) makes a single batch.\n",
      " |              Therefore, all arrays in this tuple must have the same length (equal\n",
      " |              to the size of this batch). Different batches may have different\n",
      " |                sizes.\n",
      " |              For example, the last batch of the epoch is commonly smaller than\n",
      " |                the\n",
      " |              others, if the size of the dataset is not divisible by the batch\n",
      " |                size.\n",
      " |              The generator is expected to loop over its data\n",
      " |              indefinitely. An epoch finishes when `steps_per_epoch`\n",
      " |              batches have been seen by the model.\n",
      " |          steps_per_epoch: Total number of steps (batches of samples)\n",
      " |              to yield from `generator` before declaring one epoch\n",
      " |              finished and starting the next epoch. It should typically\n",
      " |              be equal to the number of samples of your dataset\n",
      " |              divided by the batch size.\n",
      " |              Optional for `Sequence`: if unspecified, will use\n",
      " |              the `len(generator)` as a number of steps.\n",
      " |          epochs: Integer, total number of iterations on the data.\n",
      " |          verbose: Verbosity mode, 0, 1, or 2.\n",
      " |          callbacks: List of callbacks to be called during training.\n",
      " |          validation_data: This can be either\n",
      " |              - a generator for the validation data\n",
      " |              - a tuple (inputs, targets)\n",
      " |              - a tuple (inputs, targets, sample_weights).\n",
      " |          validation_steps: Only relevant if `validation_data`\n",
      " |              is a generator. Total number of steps (batches of samples)\n",
      " |              to yield from `generator` before stopping.\n",
      " |              Optional for `Sequence`: if unspecified, will use\n",
      " |              the `len(validation_data)` as a number of steps.\n",
      " |          validation_freq: Only relevant if validation data is provided. Integer\n",
      " |              or `collections_abc.Container` instance (e.g. list, tuple, etc.).\n",
      " |              If an integer, specifies how many training epochs to run before a\n",
      " |              new validation run is performed, e.g. `validation_freq=2` runs\n",
      " |              validation every 2 epochs. If a Container, specifies the epochs on\n",
      " |              which to run validation, e.g. `validation_freq=[1, 2, 10]` runs\n",
      " |              validation at the end of the 1st, 2nd, and 10th epochs.\n",
      " |          class_weight: Dictionary mapping class indices to a weight\n",
      " |              for the class.\n",
      " |          max_queue_size: Integer. Maximum size for the generator queue.\n",
      " |              If unspecified, `max_queue_size` will default to 10.\n",
      " |          workers: Integer. Maximum number of processes to spin up\n",
      " |              when using process-based threading.\n",
      " |              If unspecified, `workers` will default to 1. If 0, will\n",
      " |              execute the generator on the main thread.\n",
      " |          use_multiprocessing: Boolean.\n",
      " |              If `True`, use process-based threading.\n",
      " |              If unspecified, `use_multiprocessing` will default to `False`.\n",
      " |              Note that because this implementation relies on multiprocessing,\n",
      " |              you should not pass non-picklable arguments to the generator\n",
      " |              as they can't be passed easily to children processes.\n",
      " |          shuffle: Boolean. Whether to shuffle the order of the batches at\n",
      " |              the beginning of each epoch. Only used with instances\n",
      " |              of `Sequence` (`keras.utils.Sequence`).\n",
      " |              Has no effect when `steps_per_epoch` is not `None`.\n",
      " |          initial_epoch: Epoch at which to start training\n",
      " |              (useful for resuming a previous training run)\n",
      " |      \n",
      " |      Returns:\n",
      " |          A `History` object.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |          def generate_arrays_from_file(path):\n",
      " |              while 1:\n",
      " |                  f = open(path)\n",
      " |                  for line in f:\n",
      " |                      # create numpy arrays of input data\n",
      " |                      # and labels, from each line in the file\n",
      " |                      x1, x2, y = process_line(line)\n",
      " |                      yield ({'input_1': x1, 'input_2': x2}, {'output': y})\n",
      " |                  f.close()\n",
      " |      \n",
      " |          model.fit_generator(generate_arrays_from_file('/my_file.txt'),\n",
      " |                              steps_per_epoch=10000, epochs=10)\n",
      " |      ```\n",
      " |      Raises:\n",
      " |          ValueError: In case the generator yields data in an invalid format.\n",
      " |  \n",
      " |  get_weights(self)\n",
      " |      Retrieves the weights of the model.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A flat list of Numpy arrays.\n",
      " |  \n",
      " |  load_weights(self, filepath, by_name=False)\n",
      " |      Loads all layer weights, either from a TensorFlow or an HDF5 file.\n",
      " |  \n",
      " |  predict(self, x, batch_size=None, verbose=0, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
      " |      Generates output predictions for the input samples.\n",
      " |      \n",
      " |      Computation is done in batches.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: Input samples. It could be:\n",
      " |            - A Numpy array (or array-like), or a list of arrays\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A TensorFlow tensor, or a list of tensors\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A `tf.data` dataset.\n",
      " |            - A generator or `keras.utils.Sequence` instance.\n",
      " |          batch_size: Integer or `None`.\n",
      " |              Number of samples per gradient update.\n",
      " |              If unspecified, `batch_size` will default to 32.\n",
      " |              Do not specify the `batch_size` is your data is in the\n",
      " |              form of symbolic tensors, dataset,\n",
      " |              generators, or `keras.utils.Sequence` instances (since they generate\n",
      " |              batches).\n",
      " |          verbose: Verbosity mode, 0 or 1.\n",
      " |          steps: Total number of steps (batches of samples)\n",
      " |              before declaring the prediction round finished.\n",
      " |              Ignored with the default value of `None`. If x is a `tf.data`\n",
      " |              dataset and `steps` is None, `predict` will\n",
      " |              run until the input dataset is exhausted.\n",
      " |          callbacks: List of `keras.callbacks.Callback` instances.\n",
      " |              List of callbacks to apply during prediction.\n",
      " |              See [callbacks](/api_docs/python/tf/keras/callbacks).\n",
      " |          max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
      " |              input only. Maximum size for the generator queue.\n",
      " |              If unspecified, `max_queue_size` will default to 10.\n",
      " |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
      " |              only. Maximum number of processes to spin up when using\n",
      " |              process-based threading. If unspecified, `workers` will default\n",
      " |              to 1. If 0, will execute the generator on the main thread.\n",
      " |          use_multiprocessing: Boolean. Used for generator or\n",
      " |              `keras.utils.Sequence` input only. If `True`, use process-based\n",
      " |              threading. If unspecified, `use_multiprocessing` will default to\n",
      " |              `False`. Note that because this implementation relies on\n",
      " |              multiprocessing, you should not pass non-picklable arguments to\n",
      " |              the generator as they can't be passed easily to children processes.\n",
      " |      \n",
      " |      \n",
      " |      Returns:\n",
      " |          Numpy array(s) of predictions.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: In case of mismatch between the provided\n",
      " |              input data and the model's expectations,\n",
      " |              or in case a stateful model receives a number of samples\n",
      " |              that is not a multiple of the batch size.\n",
      " |  \n",
      " |  predict_generator(self, generator, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)\n",
      " |      Generates predictions for the input samples from a data generator.\n",
      " |      \n",
      " |      The generator should return the same kind of data as accepted by\n",
      " |      `predict_on_batch`.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          generator: Generator yielding batches of input samples\n",
      " |              or an instance of `keras.utils.Sequence` object in order to\n",
      " |              avoid duplicate data when using multiprocessing.\n",
      " |          steps: Total number of steps (batches of samples)\n",
      " |              to yield from `generator` before stopping.\n",
      " |              Optional for `Sequence`: if unspecified, will use\n",
      " |              the `len(generator)` as a number of steps.\n",
      " |          callbacks: List of `keras.callbacks.Callback` instances.\n",
      " |              List of callbacks to apply during prediction.\n",
      " |              See [callbacks](/api_docs/python/tf/keras/callbacks).\n",
      " |          max_queue_size: Maximum size for the generator queue.\n",
      " |          workers: Integer. Maximum number of processes to spin up\n",
      " |              when using process-based threading.\n",
      " |              If unspecified, `workers` will default to 1. If 0, will\n",
      " |              execute the generator on the main thread.\n",
      " |          use_multiprocessing: Boolean.\n",
      " |              If `True`, use process-based threading.\n",
      " |              If unspecified, `use_multiprocessing` will default to `False`.\n",
      " |              Note that because this implementation relies on multiprocessing,\n",
      " |              you should not pass non-picklable arguments to the generator\n",
      " |              as they can't be passed easily to children processes.\n",
      " |          verbose: verbosity mode, 0 or 1.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Numpy array(s) of predictions.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: In case the generator yields data in an invalid format.\n",
      " |  \n",
      " |  predict_on_batch(self, x)\n",
      " |      Returns predictions for a single batch of samples.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: Input data. It could be:\n",
      " |            - A Numpy array (or array-like), or a list of arrays\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A TensorFlow tensor, or a list of tensors\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A `tf.data` dataset.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Numpy array(s) of predictions.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: In case of mismatch between given number of inputs and\n",
      " |            expectations of the model.\n",
      " |  \n",
      " |  reset_metrics(self)\n",
      " |      Resets the state of metrics.\n",
      " |  \n",
      " |  test_on_batch(self, x, y=None, sample_weight=None, reset_metrics=True)\n",
      " |      Test the model on a single batch of samples.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: Input data. It could be:\n",
      " |            - A Numpy array (or array-like), or a list of arrays\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A TensorFlow tensor, or a list of tensors\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A dict mapping input names to the corresponding array/tensors,\n",
      " |              if the model has named inputs.\n",
      " |            - A `tf.data` dataset.\n",
      " |          y: Target data. Like the input data `x`,\n",
      " |            it could be either Numpy array(s) or TensorFlow tensor(s).\n",
      " |            It should be consistent with `x` (you cannot have Numpy inputs and\n",
      " |            tensor targets, or inversely). If `x` is a dataset `y` should\n",
      " |            not be specified (since targets will be obtained from the iterator).\n",
      " |          sample_weight: Optional array of the same length as x, containing\n",
      " |              weights to apply to the model's loss for each sample.\n",
      " |              In the case of temporal data, you can pass a 2D array\n",
      " |              with shape (samples, sequence_length),\n",
      " |              to apply a different weight to every timestep of every sample.\n",
      " |              In this case you should make sure to specify\n",
      " |              sample_weight_mode=\"temporal\" in compile(). This argument is not\n",
      " |              supported when `x` is a dataset.\n",
      " |          reset_metrics: If `True`, the metrics returned will be only for this\n",
      " |            batch. If `False`, the metrics will be statefully accumulated across\n",
      " |            batches.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Scalar test loss (if the model has a single output and no metrics)\n",
      " |          or list of scalars (if the model has multiple outputs\n",
      " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      " |          the display labels for the scalar outputs.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: In case of invalid user-provided arguments.\n",
      " |  \n",
      " |  train_on_batch(self, x, y=None, sample_weight=None, class_weight=None, reset_metrics=True)\n",
      " |      Runs a single gradient update on a single batch of data.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: Input data. It could be:\n",
      " |            - A Numpy array (or array-like), or a list of arrays\n",
      " |                (in case the model has multiple inputs).\n",
      " |            - A TensorFlow tensor, or a list of tensors\n",
      " |                (in case the model has multiple inputs).\n",
      " |            - A dict mapping input names to the corresponding array/tensors,\n",
      " |                if the model has named inputs.\n",
      " |            - A `tf.data` dataset.\n",
      " |          y: Target data. Like the input data `x`, it could be either Numpy\n",
      " |            array(s) or TensorFlow tensor(s). It should be consistent with `x`\n",
      " |            (you cannot have Numpy inputs and tensor targets, or inversely). If\n",
      " |            `x` is a dataset, `y` should not be specified\n",
      " |            (since targets will be obtained from the iterator).\n",
      " |          sample_weight: Optional array of the same length as x, containing\n",
      " |            weights to apply to the model's loss for each sample. In the case of\n",
      " |            temporal data, you can pass a 2D array with shape (samples,\n",
      " |            sequence_length), to apply a different weight to every timestep of\n",
      " |            every sample. In this case you should make sure to specify\n",
      " |            sample_weight_mode=\"temporal\" in compile(). This argument is not\n",
      " |            supported when `x` is a dataset.\n",
      " |          class_weight: Optional dictionary mapping class indices (integers) to a\n",
      " |            weight (float) to apply to the model's loss for the samples from this\n",
      " |            class during training. This can be useful to tell the model to \"pay\n",
      " |            more attention\" to samples from an under-represented class.\n",
      " |          reset_metrics: If `True`, the metrics returned will be only for this\n",
      " |            batch. If `False`, the metrics will be statefully accumulated across\n",
      " |            batches.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Scalar training loss\n",
      " |          (if the model has a single output and no metrics)\n",
      " |          or list of scalars (if the model has multiple outputs\n",
      " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      " |          the display labels for the scalar outputs.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: In case of invalid user-provided arguments.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.keras.engine.training.Model:\n",
      " |  \n",
      " |  metrics\n",
      " |      Returns the model's metrics added using `compile`, `add_metric` APIs.\n",
      " |  \n",
      " |  metrics_names\n",
      " |      Returns the model's display labels for all outputs.\n",
      " |  \n",
      " |  run_eagerly\n",
      " |      Settable attribute indicating whether the model should run eagerly.\n",
      " |      \n",
      " |      Running eagerly means that your model will be run step by step,\n",
      " |      like Python code. Your model might run slower, but it should become easier\n",
      " |      for you to debug it by stepping into individual layer calls.\n",
      " |      \n",
      " |      By default, we will attempt to compile your model to a static graph to\n",
      " |      deliver the best execution performance.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Boolean, whether the model should run eagerly.\n",
      " |  \n",
      " |  sample_weights\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tensorflow.python.keras.engine.network.Network:\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Support self.foo = trackable syntax.\n",
      " |  \n",
      " |  get_layer(self, name=None, index=None)\n",
      " |      Retrieves a layer based on either its name (unique) or index.\n",
      " |      \n",
      " |      If `name` and `index` are both provided, `index` will take precedence.\n",
      " |      Indices are based on order of horizontal graph traversal (bottom-up).\n",
      " |      \n",
      " |      Arguments:\n",
      " |          name: String, name of layer.\n",
      " |          index: Integer, index of layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A layer instance.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: In case of invalid layer name or index.\n",
      " |  \n",
      " |  reset_states(self)\n",
      " |  \n",
      " |  save(self, filepath, overwrite=True, include_optimizer=True, save_format=None, signatures=None)\n",
      " |      Saves the model to Tensorflow SavedModel or a single HDF5 file.\n",
      " |      \n",
      " |      The savefile includes:\n",
      " |          - The model architecture, allowing to re-instantiate the model.\n",
      " |          - The model weights.\n",
      " |          - The state of the optimizer, allowing to resume training\n",
      " |              exactly where you left off.\n",
      " |      \n",
      " |      This allows you to save the entirety of the state of a model\n",
      " |      in a single file.\n",
      " |      \n",
      " |      Saved models can be reinstantiated via `keras.models.load_model`.\n",
      " |      The model returned by `load_model`\n",
      " |      is a compiled model ready to be used (unless the saved model\n",
      " |      was never compiled in the first place).\n",
      " |      \n",
      " |      Arguments:\n",
      " |          filepath: String, path to SavedModel or H5 file to save the model.\n",
      " |          overwrite: Whether to silently overwrite any existing file at the\n",
      " |              target location, or provide the user with a manual prompt.\n",
      " |          include_optimizer: If True, save optimizer's state together.\n",
      " |          save_format: Either 'tf' or 'h5', indicating whether to save the model\n",
      " |            to Tensorflow SavedModel or HDF5. The default is currently 'h5', but\n",
      " |            will switch to 'tf' in TensorFlow 2.0. The 'tf' option is currently\n",
      " |            disabled (use `tf.keras.experimental.export_saved_model` instead).\n",
      " |        signatures: Signatures to save with the SavedModel. Applicable to the 'tf'\n",
      " |          format only. Please see the `signatures` argument in\n",
      " |          `tf.saved_model.save` for details.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      from keras.models import load_model\n",
      " |      \n",
      " |      model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
      " |      del model  # deletes the existing model\n",
      " |      \n",
      " |      # returns a compiled model\n",
      " |      # identical to the previous one\n",
      " |      model = load_model('my_model.h5')\n",
      " |      ```\n",
      " |  \n",
      " |  save_weights(self, filepath, overwrite=True, save_format=None)\n",
      " |      Saves all layer weights.\n",
      " |      \n",
      " |      Either saves in HDF5 or in TensorFlow format based on the `save_format`\n",
      " |      argument.\n",
      " |      \n",
      " |      When saving in HDF5 format, the weight file has:\n",
      " |        - `layer_names` (attribute), a list of strings\n",
      " |            (ordered names of model layers).\n",
      " |        - For every layer, a `group` named `layer.name`\n",
      " |            - For every such layer group, a group attribute `weight_names`,\n",
      " |                a list of strings\n",
      " |                (ordered names of weights tensor of the layer).\n",
      " |            - For every weight in the layer, a dataset\n",
      " |                storing the weight value, named after the weight tensor.\n",
      " |      \n",
      " |      When saving in TensorFlow format, all objects referenced by the network are\n",
      " |      saved in the same format as `tf.train.Checkpoint`, including any `Layer`\n",
      " |      instances or `Optimizer` instances assigned to object attributes. For\n",
      " |      networks constructed from inputs and outputs using `tf.keras.Model(inputs,\n",
      " |      outputs)`, `Layer` instances used by the network are tracked/saved\n",
      " |      automatically. For user-defined classes which inherit from `tf.keras.Model`,\n",
      " |      `Layer` instances must be assigned to object attributes, typically in the\n",
      " |      constructor. See the documentation of `tf.train.Checkpoint` and\n",
      " |      `tf.keras.Model` for details.\n",
      " |      \n",
      " |      While the formats are the same, do not mix `save_weights` and\n",
      " |      `tf.train.Checkpoint`. Checkpoints saved by `Model.save_weights` should be\n",
      " |      loaded using `Model.load_weights`. Checkpoints saved using\n",
      " |      `tf.train.Checkpoint.save` should be restored using the corresponding\n",
      " |      `tf.train.Checkpoint.restore`. Prefer `tf.train.Checkpoint` over\n",
      " |      `save_weights` for training checkpoints.\n",
      " |      \n",
      " |      The TensorFlow format matches objects and variables by starting at a root\n",
      " |      object, `self` for `save_weights`, and greedily matching attribute\n",
      " |      names. For `Model.save` this is the `Model`, and for `Checkpoint.save` this\n",
      " |      is the `Checkpoint` even if the `Checkpoint` has a model attached. This\n",
      " |      means saving a `tf.keras.Model` using `save_weights` and loading into a\n",
      " |      `tf.train.Checkpoint` with a `Model` attached (or vice versa) will not match\n",
      " |      the `Model`'s variables. See the [guide to training\n",
      " |      checkpoints](https://www.tensorflow.org/alpha/guide/checkpoints) for details\n",
      " |      on the TensorFlow format.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          filepath: String, path to the file to save the weights to. When saving\n",
      " |              in TensorFlow format, this is the prefix used for checkpoint files\n",
      " |              (multiple files are generated). Note that the '.h5' suffix causes\n",
      " |              weights to be saved in HDF5 format.\n",
      " |          overwrite: Whether to silently overwrite any existing file at the\n",
      " |              target location, or provide the user with a manual prompt.\n",
      " |          save_format: Either 'tf' or 'h5'. A `filepath` ending in '.h5' or\n",
      " |              '.keras' will default to HDF5 if `save_format` is `None`. Otherwise\n",
      " |              `None` defaults to 'tf'.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ImportError: If h5py is not available when attempting to save in HDF5\n",
      " |              format.\n",
      " |          ValueError: For invalid/unknown format arguments.\n",
      " |  \n",
      " |  summary(self, line_length=None, positions=None, print_fn=None)\n",
      " |      Prints a string summary of the network.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          line_length: Total length of printed lines\n",
      " |              (e.g. set this to adapt the display to different\n",
      " |              terminal window sizes).\n",
      " |          positions: Relative or absolute positions of log elements\n",
      " |              in each line. If not provided,\n",
      " |              defaults to `[.33, .55, .67, 1.]`.\n",
      " |          print_fn: Print function to use. Defaults to `print`.\n",
      " |              It will be called on each line of the summary.\n",
      " |              You can set it to a custom function\n",
      " |              in order to capture the string summary.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: if `summary()` is called before the model is built.\n",
      " |  \n",
      " |  to_json(self, **kwargs)\n",
      " |      Returns a JSON string containing the network configuration.\n",
      " |      \n",
      " |      To load a network from a JSON save file, use\n",
      " |      `keras.models.model_from_json(json_string, custom_objects={})`.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          **kwargs: Additional keyword arguments\n",
      " |              to be passed to `json.dumps()`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A JSON string.\n",
      " |  \n",
      " |  to_yaml(self, **kwargs)\n",
      " |      Returns a yaml string containing the network configuration.\n",
      " |      \n",
      " |      To load a network from a yaml save file, use\n",
      " |      `keras.models.model_from_yaml(yaml_string, custom_objects={})`.\n",
      " |      \n",
      " |      `custom_objects` should be a dictionary mapping\n",
      " |      the names of custom losses / layers / etc to the corresponding\n",
      " |      functions / classes.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          **kwargs: Additional keyword arguments\n",
      " |              to be passed to `yaml.dump()`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A YAML string.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ImportError: if yaml module is not found.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.keras.engine.network.Network:\n",
      " |  \n",
      " |  non_trainable_weights\n",
      " |  \n",
      " |  state_updates\n",
      " |      Returns the `updates` from all layers that are stateful.\n",
      " |      \n",
      " |      This is useful for separating training updates and\n",
      " |      state updates, e.g. when we need to update a layer's internal state\n",
      " |      during prediction.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A list of update ops.\n",
      " |  \n",
      " |  stateful\n",
      " |  \n",
      " |  trainable_weights\n",
      " |  \n",
      " |  weights\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  __call__(self, inputs, *args, **kwargs)\n",
      " |      Wraps `call`, applying pre- and post-processing steps.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: input tensor(s).\n",
      " |        *args: additional positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: additional keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |      \n",
      " |      Note:\n",
      " |        - The following optional keyword arguments are reserved for specific uses:\n",
      " |          * `training`: Boolean scalar tensor of Python boolean indicating\n",
      " |            whether the `call` is meant for training or inference.\n",
      " |          * `mask`: Boolean input mask.\n",
      " |        - If the layer's `call` method takes a `mask` argument (as some Keras\n",
      " |          layers do), its default value will be set to the mask generated\n",
      " |          for `inputs` by the previous layer (if `input` did come from\n",
      " |          a layer that generated a corresponding mask, i.e. if it came from\n",
      " |          a Keras layer with masking support.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: if the layer's `call` method returns None (an invalid value).\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  add_loss(self, losses, inputs=None)\n",
      " |      Add loss tensor(s), potentially dependent on layer inputs.\n",
      " |      \n",
      " |      Some losses (for instance, activity regularization losses) may be dependent\n",
      " |      on the inputs passed when calling a layer. Hence, when reusing the same\n",
      " |      layer on different inputs `a` and `b`, some entries in `layer.losses` may\n",
      " |      be dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      This method can be used inside a subclassed layer or model's `call`\n",
      " |      function, in which case `losses` should be a Tensor or list of Tensors.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      class MyLayer(tf.keras.layers.Layer):\n",
      " |        def call(inputs, self):\n",
      " |          self.add_loss(tf.abs(tf.reduce_mean(inputs)), inputs=True)\n",
      " |          return inputs\n",
      " |      ```\n",
      " |      \n",
      " |      This method can also be called directly on a Functional Model during\n",
      " |      construction. In this case, any loss Tensors passed to this Model must\n",
      " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
      " |      losses become part of the model's topology and are tracked in `get_config`.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Actvity regularization.\n",
      " |      model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
      " |      ```\n",
      " |      \n",
      " |      If this is not the case for your loss (if, for example, your loss references\n",
      " |      a `Variable` of one of the model's layers), you can wrap your loss in a\n",
      " |      zero-argument lambda. These losses are not tracked as part of the model's\n",
      " |      topology since they can't be serialized.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Weight regularization.\n",
      " |      model.add_loss(lambda: tf.reduce_mean(x.kernel))\n",
      " |      ```\n",
      " |      \n",
      " |      The `get_losses_for` method allows to retrieve the losses relevant to a\n",
      " |      specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        losses: Loss tensor, or list/tuple of tensors. Rather than tensors, losses\n",
      " |          may also be zero-argument callables which create a loss tensor.\n",
      " |        inputs: Ignored when executing eagerly. If anything other than None is\n",
      " |          passed, it signals the losses are conditional on some of the layer's\n",
      " |          inputs, and thus they should only be run where these inputs are\n",
      " |          available. This is the case for activity regularization losses, for\n",
      " |          instance. If `None` is passed, the losses are assumed\n",
      " |          to be unconditional, and will apply across all dataflows of the layer\n",
      " |          (e.g. weight regularization losses).\n",
      " |  \n",
      " |  add_metric(self, value, aggregation=None, name=None)\n",
      " |      Adds metric tensor to the layer.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: Metric tensor.\n",
      " |        aggregation: Sample-wise metric reduction function. If `aggregation=None`,\n",
      " |          it indicates that the metric tensor provided has been aggregated\n",
      " |          already. eg, `bin_acc = BinaryAccuracy(name='acc')` followed by\n",
      " |          `model.add_metric(bin_acc(y_true, y_pred))`. If aggregation='mean', the\n",
      " |          given metric tensor will be sample-wise reduced using `mean` function.\n",
      " |          eg, `model.add_metric(tf.reduce_sum(outputs), name='output_mean',\n",
      " |          aggregation='mean')`.\n",
      " |        name: String metric name.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If `aggregation` is anything other than None or `mean`.\n",
      " |  \n",
      " |  add_update(self, updates, inputs=None)\n",
      " |      Add update op(s), potentially dependent on layer inputs. (deprecated arguments)\n",
      " |      \n",
      " |      Warning: SOME ARGUMENTS ARE DEPRECATED: `(inputs)`. They will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      `inputs` is now automatically inferred\n",
      " |      \n",
      " |      Weight updates (for instance, the updates of the moving mean and variance\n",
      " |      in a BatchNormalization layer) may be dependent on the inputs passed\n",
      " |      when calling a layer. Hence, when reusing the same layer on\n",
      " |      different inputs `a` and `b`, some entries in `layer.updates` may be\n",
      " |      dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      The `get_updates_for` method allows to retrieve the updates relevant to a\n",
      " |      specific set of inputs.\n",
      " |      \n",
      " |      This call is ignored when eager execution is enabled (in that case, variable\n",
      " |      updates are run on the fly and thus do not need to be tracked for later\n",
      " |      execution).\n",
      " |      \n",
      " |      Arguments:\n",
      " |        updates: Update op, or list/tuple of update ops, or zero-arg callable\n",
      " |          that returns an update op. A zero-arg callable should be passed in\n",
      " |          order to disable running the updates by setting `trainable=False`\n",
      " |          on this Layer, when executing in Eager mode.\n",
      " |        inputs: Deprecated, will be automatically inferred.\n",
      " |  \n",
      " |  add_variable(self, *args, **kwargs)\n",
      " |      Deprecated, do NOT use! Alias for `add_weight`. (deprecated)\n",
      " |      \n",
      " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      Please use `layer.add_weight` method instead.\n",
      " |  \n",
      " |  add_weight(self, name=None, shape=None, dtype=None, initializer=None, regularizer=None, trainable=None, constraint=None, partitioner=None, use_resource=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregation.NONE: 0>, **kwargs)\n",
      " |      Adds a new variable to the layer.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        name: Variable name.\n",
      " |        shape: Variable shape. Defaults to scalar if unspecified.\n",
      " |        dtype: The type of the variable. Defaults to `self.dtype` or `float32`.\n",
      " |        initializer: Initializer instance (callable).\n",
      " |        regularizer: Regularizer instance (callable).\n",
      " |        trainable: Boolean, whether the variable should be part of the layer's\n",
      " |          \"trainable_variables\" (e.g. variables, biases)\n",
      " |          or \"non_trainable_variables\" (e.g. BatchNorm mean and variance).\n",
      " |          Note that `trainable` cannot be `True` if `synchronization`\n",
      " |          is set to `ON_READ`.\n",
      " |        constraint: Constraint instance (callable).\n",
      " |        partitioner: Partitioner to be passed to the `Trackable` API.\n",
      " |        use_resource: Whether to use `ResourceVariable`.\n",
      " |        synchronization: Indicates when a distributed a variable will be\n",
      " |          aggregated. Accepted values are constants defined in the class\n",
      " |          `tf.VariableSynchronization`. By default the synchronization is set to\n",
      " |          `AUTO` and the current `DistributionStrategy` chooses\n",
      " |          when to synchronize. If `synchronization` is set to `ON_READ`,\n",
      " |          `trainable` must not be set to `True`.\n",
      " |        aggregation: Indicates how a distributed variable will be aggregated.\n",
      " |          Accepted values are constants defined in the class\n",
      " |          `tf.VariableAggregation`.\n",
      " |        **kwargs: Additional keyword arguments. Accepted values are `getter` and\n",
      " |          `collections`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The created variable. Usually either a `Variable` or `ResourceVariable`\n",
      " |        instance. If `partitioner` is not `None`, a `PartitionedVariable`\n",
      " |        instance is returned.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called with partitioned variable regularization and\n",
      " |          eager execution is enabled.\n",
      " |        ValueError: When giving unsupported dtype and no initializer or when\n",
      " |          trainable has been set to True with synchronization set as `ON_READ`.\n",
      " |  \n",
      " |  apply(self, inputs, *args, **kwargs)\n",
      " |      Deprecated, do NOT use! (deprecated)\n",
      " |      \n",
      " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      Please use `layer.__call__` method instead.\n",
      " |      \n",
      " |      This is an alias of `self.__call__`.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor(s).\n",
      " |        *args: additional positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: additional keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |  \n",
      " |  compute_output_signature(self, input_signature)\n",
      " |      Compute the output tensor signature of the layer based on the inputs.\n",
      " |      \n",
      " |      Unlike a TensorShape object, a TensorSpec object contains both shape\n",
      " |      and dtype information for a tensor. This method allows layers to provide\n",
      " |      output dtype information if it is different from the input dtype.\n",
      " |      For any layer that doesn't implement this function,\n",
      " |      the framework will fall back to use `compute_output_shape`, and will\n",
      " |      assume that the output dtype matches the input dtype.\n",
      " |      \n",
      " |      Args:\n",
      " |        input_signature: Single TensorSpec or nested structure of TensorSpec\n",
      " |          objects, describing a candidate input for the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Single TensorSpec or nested structure of TensorSpec objects, describing\n",
      " |          how the layer would transform the provided input.\n",
      " |      \n",
      " |      Raises:\n",
      " |        TypeError: If input_signature contains a non-TensorSpec object.\n",
      " |  \n",
      " |  count_params(self)\n",
      " |      Count the total number of scalars composing the weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An integer count.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: if the layer isn't yet built\n",
      " |            (in which case its weights aren't yet defined).\n",
      " |  \n",
      " |  get_input_at(self, node_index)\n",
      " |      Retrieves the input tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_input_mask_at(self, node_index)\n",
      " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_shape_at(self, node_index)\n",
      " |      Retrieves the input shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_losses_for(self, inputs)\n",
      " |      Retrieves losses relevant to a specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor or list/tuple of input tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |        List of loss tensors of the layer that depend on `inputs`.\n",
      " |  \n",
      " |  get_output_at(self, node_index)\n",
      " |      Retrieves the output tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_output_mask_at(self, node_index)\n",
      " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_shape_at(self, node_index)\n",
      " |      Retrieves the output shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_updates_for(self, inputs)\n",
      " |      Retrieves updates relevant to a specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor or list/tuple of input tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |        List of update ops of the layer that depend on `inputs`.\n",
      " |  \n",
      " |  set_weights(self, weights)\n",
      " |      Sets the weights of the layer, from Numpy arrays.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          weights: a list of Numpy arrays. The number\n",
      " |              of arrays and their shape must match\n",
      " |              number of the dimensions of the weights\n",
      " |              of the layer (i.e. it should match the\n",
      " |              output of `get_weights`).\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: If the provided weights list does not match the\n",
      " |              layer's specifications.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  activity_regularizer\n",
      " |      Optional regularizer function for the output of this layer.\n",
      " |  \n",
      " |  dtype\n",
      " |  \n",
      " |  inbound_nodes\n",
      " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      " |  \n",
      " |  input\n",
      " |      Retrieves the input tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input tensor or list of input tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |        AttributeError: If no inbound nodes are found.\n",
      " |  \n",
      " |  input_mask\n",
      " |      Retrieves the input mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input mask tensor (potentially None) or list of input\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_shape\n",
      " |      Retrieves the input shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer, or if all inputs\n",
      " |      have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per input tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined input_shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  losses\n",
      " |      Losses which are associated with this `Layer`.\n",
      " |      \n",
      " |      Variable regularization tensors are created when this property is accessed,\n",
      " |      so it is eager safe: accessing `losses` under a `tf.GradientTape` will\n",
      " |      propagate gradients back to the corresponding variables.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of tensors.\n",
      " |  \n",
      " |  name\n",
      " |      Returns the name of this module as passed or determined in the ctor.\n",
      " |      \n",
      " |      NOTE: This is not the same as the `self.name_scope.name` which includes\n",
      " |      parent module names.\n",
      " |  \n",
      " |  non_trainable_variables\n",
      " |  \n",
      " |  outbound_nodes\n",
      " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      " |  \n",
      " |  output\n",
      " |      Retrieves the output tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one output,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor or list of output tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        AttributeError: if the layer is connected to more than one incoming\n",
      " |          layers.\n",
      " |        RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  output_mask\n",
      " |      Retrieves the output mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output mask tensor (potentially None) or list of output\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_shape\n",
      " |      Retrieves the output shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has one output,\n",
      " |      or if all outputs have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per output tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined output shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  trainable\n",
      " |  \n",
      " |  trainable_variables\n",
      " |      Sequence of variables owned by this module and it's submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  updates\n",
      " |  \n",
      " |  variables\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Alias of `self.weights`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  with_name_scope(method) from builtins.type\n",
      " |      Decorator to automatically enter the module name scope.\n",
      " |      \n",
      " |      ```\n",
      " |      class MyModule(tf.Module):\n",
      " |        @tf.Module.with_name_scope\n",
      " |        def __call__(self, x):\n",
      " |          if not hasattr(self, 'w'):\n",
      " |            self.w = tf.Variable(tf.random.normal([x.shape[1], 64]))\n",
      " |          return tf.matmul(x, self.w)\n",
      " |      ```\n",
      " |      \n",
      " |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
      " |      names included the module name:\n",
      " |      \n",
      " |      ```\n",
      " |      mod = MyModule()\n",
      " |      mod(tf.ones([8, 32]))\n",
      " |      # ==> <tf.Tensor: ...>\n",
      " |      mod.w\n",
      " |      # ==> <tf.Variable ...'my_module/w:0'>\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        method: The method to wrap.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The original method wrapped such that it enters the module's name scope.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  name_scope\n",
      " |      Returns a `tf.name_scope` instance for this class.\n",
      " |  \n",
      " |  submodules\n",
      " |      Sequence of all sub-modules.\n",
      " |      \n",
      " |      Submodules are modules which are properties of this module, or found as\n",
      " |      properties of modules which are properties of this module (and so on).\n",
      " |      \n",
      " |      ```\n",
      " |      a = tf.Module()\n",
      " |      b = tf.Module()\n",
      " |      c = tf.Module()\n",
      " |      a.b = b\n",
      " |      b.c = c\n",
      " |      assert list(a.submodules) == [b, c]\n",
      " |      assert list(b.submodules) == [c]\n",
      " |      assert list(c.submodules) == []\n",
      " |      ```\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of all submodules.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.training.tracking.base.Trackable:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(models.Sequential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b24ce103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AbstractRNNCell',\n",
       " 'Activation',\n",
       " 'ActivityRegularization',\n",
       " 'Add',\n",
       " 'AdditiveAttention',\n",
       " 'AlphaDropout',\n",
       " 'Attention',\n",
       " 'Average',\n",
       " 'AveragePooling1D',\n",
       " 'AveragePooling2D',\n",
       " 'AveragePooling3D',\n",
       " 'AvgPool1D',\n",
       " 'AvgPool2D',\n",
       " 'AvgPool3D',\n",
       " 'BatchNormalization',\n",
       " 'Bidirectional',\n",
       " 'Concatenate',\n",
       " 'Conv1D',\n",
       " 'Conv2D',\n",
       " 'Conv2DTranspose',\n",
       " 'Conv3D',\n",
       " 'Conv3DTranspose',\n",
       " 'ConvLSTM2D',\n",
       " 'Convolution1D',\n",
       " 'Convolution2D',\n",
       " 'Convolution2DTranspose',\n",
       " 'Convolution3D',\n",
       " 'Convolution3DTranspose',\n",
       " 'Cropping1D',\n",
       " 'Cropping2D',\n",
       " 'Cropping3D',\n",
       " 'CuDNNGRU',\n",
       " 'CuDNNLSTM',\n",
       " 'Dense',\n",
       " 'DenseFeatures',\n",
       " 'DepthwiseConv2D',\n",
       " 'Dot',\n",
       " 'Dropout',\n",
       " 'ELU',\n",
       " 'Embedding',\n",
       " 'Flatten',\n",
       " 'GRU',\n",
       " 'GRUCell',\n",
       " 'GaussianDropout',\n",
       " 'GaussianNoise',\n",
       " 'GlobalAveragePooling1D',\n",
       " 'GlobalAveragePooling2D',\n",
       " 'GlobalAveragePooling3D',\n",
       " 'GlobalAvgPool1D',\n",
       " 'GlobalAvgPool2D',\n",
       " 'GlobalAvgPool3D',\n",
       " 'GlobalMaxPool1D',\n",
       " 'GlobalMaxPool2D',\n",
       " 'GlobalMaxPool3D',\n",
       " 'GlobalMaxPooling1D',\n",
       " 'GlobalMaxPooling2D',\n",
       " 'GlobalMaxPooling3D',\n",
       " 'Input',\n",
       " 'InputLayer',\n",
       " 'InputSpec',\n",
       " 'LSTM',\n",
       " 'LSTMCell',\n",
       " 'Lambda',\n",
       " 'Layer',\n",
       " 'LayerNormalization',\n",
       " 'LeakyReLU',\n",
       " 'LocallyConnected1D',\n",
       " 'LocallyConnected2D',\n",
       " 'Masking',\n",
       " 'MaxPool1D',\n",
       " 'MaxPool2D',\n",
       " 'MaxPool3D',\n",
       " 'MaxPooling1D',\n",
       " 'MaxPooling2D',\n",
       " 'MaxPooling3D',\n",
       " 'Maximum',\n",
       " 'Minimum',\n",
       " 'Multiply',\n",
       " 'PReLU',\n",
       " 'Permute',\n",
       " 'RNN',\n",
       " 'ReLU',\n",
       " 'RepeatVector',\n",
       " 'Reshape',\n",
       " 'SeparableConv1D',\n",
       " 'SeparableConv2D',\n",
       " 'SeparableConvolution1D',\n",
       " 'SeparableConvolution2D',\n",
       " 'SimpleRNN',\n",
       " 'SimpleRNNCell',\n",
       " 'Softmax',\n",
       " 'SpatialDropout1D',\n",
       " 'SpatialDropout2D',\n",
       " 'SpatialDropout3D',\n",
       " 'StackedRNNCells',\n",
       " 'Subtract',\n",
       " 'ThresholdedReLU',\n",
       " 'TimeDistributed',\n",
       " 'UpSampling1D',\n",
       " 'UpSampling2D',\n",
       " 'UpSampling3D',\n",
       " 'Wrapper',\n",
       " 'ZeroPadding1D',\n",
       " 'ZeroPadding2D',\n",
       " 'ZeroPadding3D',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_module_wrapper',\n",
       " '_sys',\n",
       " 'add',\n",
       " 'average',\n",
       " 'concatenate',\n",
       " 'deserialize',\n",
       " 'dot',\n",
       " 'maximum',\n",
       " 'minimum',\n",
       " 'multiply',\n",
       " 'serialize',\n",
       " 'subtract']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "86734bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Conv2D in module tensorflow.python.keras.layers.convolutional:\n",
      "\n",
      "class Conv2D(Conv)\n",
      " |  Conv2D(filters, kernel_size, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1), activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)\n",
      " |  \n",
      " |  2D convolution layer (e.g. spatial convolution over images).\n",
      " |  \n",
      " |  This layer creates a convolution kernel that is convolved\n",
      " |  with the layer input to produce a tensor of\n",
      " |  outputs. If `use_bias` is True,\n",
      " |  a bias vector is created and added to the outputs. Finally, if\n",
      " |  `activation` is not `None`, it is applied to the outputs as well.\n",
      " |  \n",
      " |  When using this layer as the first layer in a model,\n",
      " |  provide the keyword argument `input_shape`\n",
      " |  (tuple of integers, does not include the sample axis),\n",
      " |  e.g. `input_shape=(128, 128, 3)` for 128x128 RGB pictures\n",
      " |  in `data_format=\"channels_last\"`.\n",
      " |  \n",
      " |  Arguments:\n",
      " |    filters: Integer, the dimensionality of the output space\n",
      " |      (i.e. the number of output filters in the convolution).\n",
      " |    kernel_size: An integer or tuple/list of 2 integers, specifying the\n",
      " |      height and width of the 2D convolution window.\n",
      " |      Can be a single integer to specify the same value for\n",
      " |      all spatial dimensions.\n",
      " |    strides: An integer or tuple/list of 2 integers,\n",
      " |      specifying the strides of the convolution along the height and width.\n",
      " |      Can be a single integer to specify the same value for\n",
      " |      all spatial dimensions.\n",
      " |      Specifying any stride value != 1 is incompatible with specifying\n",
      " |      any `dilation_rate` value != 1.\n",
      " |    padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n",
      " |    data_format: A string,\n",
      " |      one of `channels_last` (default) or `channels_first`.\n",
      " |      The ordering of the dimensions in the inputs.\n",
      " |      `channels_last` corresponds to inputs with shape\n",
      " |      `(batch, height, width, channels)` while `channels_first`\n",
      " |      corresponds to inputs with shape\n",
      " |      `(batch, channels, height, width)`.\n",
      " |      It defaults to the `image_data_format` value found in your\n",
      " |      Keras config file at `~/.keras/keras.json`.\n",
      " |      If you never set it, then it will be \"channels_last\".\n",
      " |    dilation_rate: an integer or tuple/list of 2 integers, specifying\n",
      " |      the dilation rate to use for dilated convolution.\n",
      " |      Can be a single integer to specify the same value for\n",
      " |      all spatial dimensions.\n",
      " |      Currently, specifying any `dilation_rate` value != 1 is\n",
      " |      incompatible with specifying any stride value != 1.\n",
      " |    activation: Activation function to use.\n",
      " |      If you don't specify anything, no activation is applied\n",
      " |      (ie. \"linear\" activation: `a(x) = x`).\n",
      " |    use_bias: Boolean, whether the layer uses a bias vector.\n",
      " |    kernel_initializer: Initializer for the `kernel` weights matrix.\n",
      " |    bias_initializer: Initializer for the bias vector.\n",
      " |    kernel_regularizer: Regularizer function applied to\n",
      " |      the `kernel` weights matrix.\n",
      " |    bias_regularizer: Regularizer function applied to the bias vector.\n",
      " |    activity_regularizer: Regularizer function applied to\n",
      " |      the output of the layer (its \"activation\")..\n",
      " |    kernel_constraint: Constraint function applied to the kernel matrix.\n",
      " |    bias_constraint: Constraint function applied to the bias vector.\n",
      " |  \n",
      " |  Input shape:\n",
      " |    4D tensor with shape:\n",
      " |    `(samples, channels, rows, cols)` if data_format='channels_first'\n",
      " |    or 4D tensor with shape:\n",
      " |    `(samples, rows, cols, channels)` if data_format='channels_last'.\n",
      " |  \n",
      " |  Output shape:\n",
      " |    4D tensor with shape:\n",
      " |    `(samples, filters, new_rows, new_cols)` if data_format='channels_first'\n",
      " |    or 4D tensor with shape:\n",
      " |    `(samples, new_rows, new_cols, filters)` if data_format='channels_last'.\n",
      " |    `rows` and `cols` values might have changed due to padding.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Conv2D\n",
      " |      Conv\n",
      " |      tensorflow.python.keras.engine.base_layer.Layer\n",
      " |      tensorflow.python.module.module.Module\n",
      " |      tensorflow.python.training.tracking.tracking.AutoTrackable\n",
      " |      tensorflow.python.training.tracking.base.Trackable\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, filters, kernel_size, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1), activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from Conv:\n",
      " |  \n",
      " |  build(self, input_shape)\n",
      " |      Creates the variables of the layer (optional, for subclass implementers).\n",
      " |      \n",
      " |      This is a method that implementers of subclasses of `Layer` or `Model`\n",
      " |      can override if they need a state-creation step in-between\n",
      " |      layer instantiation and layer call.\n",
      " |      \n",
      " |      This is typically used to create the weights of `Layer` subclasses.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        input_shape: Instance of `TensorShape`, or list of instances of\n",
      " |          `TensorShape` if the layer expects a list of inputs\n",
      " |          (one instance per input).\n",
      " |  \n",
      " |  call(self, inputs)\n",
      " |      This is where the layer's logic lives.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          inputs: Input tensor, or list/tuple of input tensors.\n",
      " |          **kwargs: Additional keyword arguments.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor or list/tuple of tensors.\n",
      " |  \n",
      " |  compute_output_shape(self, input_shape)\n",
      " |      Computes the output shape of the layer.\n",
      " |      \n",
      " |      If the layer has not been built, this method will call `build` on the\n",
      " |      layer. This assumes that the layer will later be used with inputs that\n",
      " |      match the input shape provided here.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          input_shape: Shape tuple (tuple of integers)\n",
      " |              or list of shape tuples (one per output tensor of the layer).\n",
      " |              Shape tuples can include None for free dimensions,\n",
      " |              instead of an integer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An input shape tuple.\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the config of the layer.\n",
      " |      \n",
      " |      A layer config is a Python dictionary (serializable)\n",
      " |      containing the configuration of a layer.\n",
      " |      The same layer can be reinstantiated later\n",
      " |      (without its trained weights) from this configuration.\n",
      " |      \n",
      " |      The config of a layer does not include connectivity\n",
      " |      information, nor the layer class name. These are handled\n",
      " |      by `Network` (one layer of abstraction above).\n",
      " |      \n",
      " |      Returns:\n",
      " |          Python dictionary.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  __call__(self, inputs, *args, **kwargs)\n",
      " |      Wraps `call`, applying pre- and post-processing steps.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: input tensor(s).\n",
      " |        *args: additional positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: additional keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |      \n",
      " |      Note:\n",
      " |        - The following optional keyword arguments are reserved for specific uses:\n",
      " |          * `training`: Boolean scalar tensor of Python boolean indicating\n",
      " |            whether the `call` is meant for training or inference.\n",
      " |          * `mask`: Boolean input mask.\n",
      " |        - If the layer's `call` method takes a `mask` argument (as some Keras\n",
      " |          layers do), its default value will be set to the mask generated\n",
      " |          for `inputs` by the previous layer (if `input` did come from\n",
      " |          a layer that generated a corresponding mask, i.e. if it came from\n",
      " |          a Keras layer with masking support.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: if the layer's `call` method returns None (an invalid value).\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Support self.foo = trackable syntax.\n",
      " |  \n",
      " |  add_loss(self, losses, inputs=None)\n",
      " |      Add loss tensor(s), potentially dependent on layer inputs.\n",
      " |      \n",
      " |      Some losses (for instance, activity regularization losses) may be dependent\n",
      " |      on the inputs passed when calling a layer. Hence, when reusing the same\n",
      " |      layer on different inputs `a` and `b`, some entries in `layer.losses` may\n",
      " |      be dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      This method can be used inside a subclassed layer or model's `call`\n",
      " |      function, in which case `losses` should be a Tensor or list of Tensors.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      class MyLayer(tf.keras.layers.Layer):\n",
      " |        def call(inputs, self):\n",
      " |          self.add_loss(tf.abs(tf.reduce_mean(inputs)), inputs=True)\n",
      " |          return inputs\n",
      " |      ```\n",
      " |      \n",
      " |      This method can also be called directly on a Functional Model during\n",
      " |      construction. In this case, any loss Tensors passed to this Model must\n",
      " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
      " |      losses become part of the model's topology and are tracked in `get_config`.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Actvity regularization.\n",
      " |      model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
      " |      ```\n",
      " |      \n",
      " |      If this is not the case for your loss (if, for example, your loss references\n",
      " |      a `Variable` of one of the model's layers), you can wrap your loss in a\n",
      " |      zero-argument lambda. These losses are not tracked as part of the model's\n",
      " |      topology since they can't be serialized.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Weight regularization.\n",
      " |      model.add_loss(lambda: tf.reduce_mean(x.kernel))\n",
      " |      ```\n",
      " |      \n",
      " |      The `get_losses_for` method allows to retrieve the losses relevant to a\n",
      " |      specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        losses: Loss tensor, or list/tuple of tensors. Rather than tensors, losses\n",
      " |          may also be zero-argument callables which create a loss tensor.\n",
      " |        inputs: Ignored when executing eagerly. If anything other than None is\n",
      " |          passed, it signals the losses are conditional on some of the layer's\n",
      " |          inputs, and thus they should only be run where these inputs are\n",
      " |          available. This is the case for activity regularization losses, for\n",
      " |          instance. If `None` is passed, the losses are assumed\n",
      " |          to be unconditional, and will apply across all dataflows of the layer\n",
      " |          (e.g. weight regularization losses).\n",
      " |  \n",
      " |  add_metric(self, value, aggregation=None, name=None)\n",
      " |      Adds metric tensor to the layer.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: Metric tensor.\n",
      " |        aggregation: Sample-wise metric reduction function. If `aggregation=None`,\n",
      " |          it indicates that the metric tensor provided has been aggregated\n",
      " |          already. eg, `bin_acc = BinaryAccuracy(name='acc')` followed by\n",
      " |          `model.add_metric(bin_acc(y_true, y_pred))`. If aggregation='mean', the\n",
      " |          given metric tensor will be sample-wise reduced using `mean` function.\n",
      " |          eg, `model.add_metric(tf.reduce_sum(outputs), name='output_mean',\n",
      " |          aggregation='mean')`.\n",
      " |        name: String metric name.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If `aggregation` is anything other than None or `mean`.\n",
      " |  \n",
      " |  add_update(self, updates, inputs=None)\n",
      " |      Add update op(s), potentially dependent on layer inputs. (deprecated arguments)\n",
      " |      \n",
      " |      Warning: SOME ARGUMENTS ARE DEPRECATED: `(inputs)`. They will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      `inputs` is now automatically inferred\n",
      " |      \n",
      " |      Weight updates (for instance, the updates of the moving mean and variance\n",
      " |      in a BatchNormalization layer) may be dependent on the inputs passed\n",
      " |      when calling a layer. Hence, when reusing the same layer on\n",
      " |      different inputs `a` and `b`, some entries in `layer.updates` may be\n",
      " |      dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      The `get_updates_for` method allows to retrieve the updates relevant to a\n",
      " |      specific set of inputs.\n",
      " |      \n",
      " |      This call is ignored when eager execution is enabled (in that case, variable\n",
      " |      updates are run on the fly and thus do not need to be tracked for later\n",
      " |      execution).\n",
      " |      \n",
      " |      Arguments:\n",
      " |        updates: Update op, or list/tuple of update ops, or zero-arg callable\n",
      " |          that returns an update op. A zero-arg callable should be passed in\n",
      " |          order to disable running the updates by setting `trainable=False`\n",
      " |          on this Layer, when executing in Eager mode.\n",
      " |        inputs: Deprecated, will be automatically inferred.\n",
      " |  \n",
      " |  add_variable(self, *args, **kwargs)\n",
      " |      Deprecated, do NOT use! Alias for `add_weight`. (deprecated)\n",
      " |      \n",
      " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      Please use `layer.add_weight` method instead.\n",
      " |  \n",
      " |  add_weight(self, name=None, shape=None, dtype=None, initializer=None, regularizer=None, trainable=None, constraint=None, partitioner=None, use_resource=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregation.NONE: 0>, **kwargs)\n",
      " |      Adds a new variable to the layer.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        name: Variable name.\n",
      " |        shape: Variable shape. Defaults to scalar if unspecified.\n",
      " |        dtype: The type of the variable. Defaults to `self.dtype` or `float32`.\n",
      " |        initializer: Initializer instance (callable).\n",
      " |        regularizer: Regularizer instance (callable).\n",
      " |        trainable: Boolean, whether the variable should be part of the layer's\n",
      " |          \"trainable_variables\" (e.g. variables, biases)\n",
      " |          or \"non_trainable_variables\" (e.g. BatchNorm mean and variance).\n",
      " |          Note that `trainable` cannot be `True` if `synchronization`\n",
      " |          is set to `ON_READ`.\n",
      " |        constraint: Constraint instance (callable).\n",
      " |        partitioner: Partitioner to be passed to the `Trackable` API.\n",
      " |        use_resource: Whether to use `ResourceVariable`.\n",
      " |        synchronization: Indicates when a distributed a variable will be\n",
      " |          aggregated. Accepted values are constants defined in the class\n",
      " |          `tf.VariableSynchronization`. By default the synchronization is set to\n",
      " |          `AUTO` and the current `DistributionStrategy` chooses\n",
      " |          when to synchronize. If `synchronization` is set to `ON_READ`,\n",
      " |          `trainable` must not be set to `True`.\n",
      " |        aggregation: Indicates how a distributed variable will be aggregated.\n",
      " |          Accepted values are constants defined in the class\n",
      " |          `tf.VariableAggregation`.\n",
      " |        **kwargs: Additional keyword arguments. Accepted values are `getter` and\n",
      " |          `collections`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The created variable. Usually either a `Variable` or `ResourceVariable`\n",
      " |        instance. If `partitioner` is not `None`, a `PartitionedVariable`\n",
      " |        instance is returned.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called with partitioned variable regularization and\n",
      " |          eager execution is enabled.\n",
      " |        ValueError: When giving unsupported dtype and no initializer or when\n",
      " |          trainable has been set to True with synchronization set as `ON_READ`.\n",
      " |  \n",
      " |  apply(self, inputs, *args, **kwargs)\n",
      " |      Deprecated, do NOT use! (deprecated)\n",
      " |      \n",
      " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      Please use `layer.__call__` method instead.\n",
      " |      \n",
      " |      This is an alias of `self.__call__`.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor(s).\n",
      " |        *args: additional positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: additional keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |  \n",
      " |  compute_mask(self, inputs, mask=None)\n",
      " |      Computes an output mask tensor.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          inputs: Tensor or list of tensors.\n",
      " |          mask: Tensor or list of tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |          None or a tensor (or list of tensors,\n",
      " |              one per output tensor of the layer).\n",
      " |  \n",
      " |  compute_output_signature(self, input_signature)\n",
      " |      Compute the output tensor signature of the layer based on the inputs.\n",
      " |      \n",
      " |      Unlike a TensorShape object, a TensorSpec object contains both shape\n",
      " |      and dtype information for a tensor. This method allows layers to provide\n",
      " |      output dtype information if it is different from the input dtype.\n",
      " |      For any layer that doesn't implement this function,\n",
      " |      the framework will fall back to use `compute_output_shape`, and will\n",
      " |      assume that the output dtype matches the input dtype.\n",
      " |      \n",
      " |      Args:\n",
      " |        input_signature: Single TensorSpec or nested structure of TensorSpec\n",
      " |          objects, describing a candidate input for the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Single TensorSpec or nested structure of TensorSpec objects, describing\n",
      " |          how the layer would transform the provided input.\n",
      " |      \n",
      " |      Raises:\n",
      " |        TypeError: If input_signature contains a non-TensorSpec object.\n",
      " |  \n",
      " |  count_params(self)\n",
      " |      Count the total number of scalars composing the weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An integer count.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: if the layer isn't yet built\n",
      " |            (in which case its weights aren't yet defined).\n",
      " |  \n",
      " |  get_input_at(self, node_index)\n",
      " |      Retrieves the input tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_input_mask_at(self, node_index)\n",
      " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_shape_at(self, node_index)\n",
      " |      Retrieves the input shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_losses_for(self, inputs)\n",
      " |      Retrieves losses relevant to a specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor or list/tuple of input tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |        List of loss tensors of the layer that depend on `inputs`.\n",
      " |  \n",
      " |  get_output_at(self, node_index)\n",
      " |      Retrieves the output tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_output_mask_at(self, node_index)\n",
      " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_shape_at(self, node_index)\n",
      " |      Retrieves the output shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_updates_for(self, inputs)\n",
      " |      Retrieves updates relevant to a specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor or list/tuple of input tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |        List of update ops of the layer that depend on `inputs`.\n",
      " |  \n",
      " |  get_weights(self)\n",
      " |      Returns the current weights of the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Weights values as a list of numpy arrays.\n",
      " |  \n",
      " |  set_weights(self, weights)\n",
      " |      Sets the weights of the layer, from Numpy arrays.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          weights: a list of Numpy arrays. The number\n",
      " |              of arrays and their shape must match\n",
      " |              number of the dimensions of the weights\n",
      " |              of the layer (i.e. it should match the\n",
      " |              output of `get_weights`).\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: If the provided weights list does not match the\n",
      " |              layer's specifications.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  from_config(config) from builtins.type\n",
      " |      Creates a layer from its config.\n",
      " |      \n",
      " |      This method is the reverse of `get_config`,\n",
      " |      capable of instantiating the same layer from the config\n",
      " |      dictionary. It does not handle layer connectivity\n",
      " |      (handled by Network), nor weights (handled by `set_weights`).\n",
      " |      \n",
      " |      Arguments:\n",
      " |          config: A Python dictionary, typically the\n",
      " |              output of get_config.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A layer instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  activity_regularizer\n",
      " |      Optional regularizer function for the output of this layer.\n",
      " |  \n",
      " |  dtype\n",
      " |  \n",
      " |  dynamic\n",
      " |  \n",
      " |  inbound_nodes\n",
      " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      " |  \n",
      " |  input\n",
      " |      Retrieves the input tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input tensor or list of input tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |        AttributeError: If no inbound nodes are found.\n",
      " |  \n",
      " |  input_mask\n",
      " |      Retrieves the input mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input mask tensor (potentially None) or list of input\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_shape\n",
      " |      Retrieves the input shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer, or if all inputs\n",
      " |      have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per input tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined input_shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  input_spec\n",
      " |  \n",
      " |  losses\n",
      " |      Losses which are associated with this `Layer`.\n",
      " |      \n",
      " |      Variable regularization tensors are created when this property is accessed,\n",
      " |      so it is eager safe: accessing `losses` under a `tf.GradientTape` will\n",
      " |      propagate gradients back to the corresponding variables.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of tensors.\n",
      " |  \n",
      " |  metrics\n",
      " |  \n",
      " |  name\n",
      " |      Returns the name of this module as passed or determined in the ctor.\n",
      " |      \n",
      " |      NOTE: This is not the same as the `self.name_scope.name` which includes\n",
      " |      parent module names.\n",
      " |  \n",
      " |  non_trainable_variables\n",
      " |  \n",
      " |  non_trainable_weights\n",
      " |  \n",
      " |  outbound_nodes\n",
      " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      " |  \n",
      " |  output\n",
      " |      Retrieves the output tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one output,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor or list of output tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        AttributeError: if the layer is connected to more than one incoming\n",
      " |          layers.\n",
      " |        RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  output_mask\n",
      " |      Retrieves the output mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output mask tensor (potentially None) or list of output\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_shape\n",
      " |      Retrieves the output shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has one output,\n",
      " |      or if all outputs have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per output tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined output shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  trainable\n",
      " |  \n",
      " |  trainable_variables\n",
      " |      Sequence of variables owned by this module and it's submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  trainable_weights\n",
      " |  \n",
      " |  updates\n",
      " |  \n",
      " |  variables\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Alias of `self.weights`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  weights\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  with_name_scope(method) from builtins.type\n",
      " |      Decorator to automatically enter the module name scope.\n",
      " |      \n",
      " |      ```\n",
      " |      class MyModule(tf.Module):\n",
      " |        @tf.Module.with_name_scope\n",
      " |        def __call__(self, x):\n",
      " |          if not hasattr(self, 'w'):\n",
      " |            self.w = tf.Variable(tf.random.normal([x.shape[1], 64]))\n",
      " |          return tf.matmul(x, self.w)\n",
      " |      ```\n",
      " |      \n",
      " |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
      " |      names included the module name:\n",
      " |      \n",
      " |      ```\n",
      " |      mod = MyModule()\n",
      " |      mod(tf.ones([8, 32]))\n",
      " |      # ==> <tf.Tensor: ...>\n",
      " |      mod.w\n",
      " |      # ==> <tf.Variable ...'my_module/w:0'>\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        method: The method to wrap.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The original method wrapped such that it enters the module's name scope.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  name_scope\n",
      " |      Returns a `tf.name_scope` instance for this class.\n",
      " |  \n",
      " |  submodules\n",
      " |      Sequence of all sub-modules.\n",
      " |      \n",
      " |      Submodules are modules which are properties of this module, or found as\n",
      " |      properties of modules which are properties of this module (and so on).\n",
      " |      \n",
      " |      ```\n",
      " |      a = tf.Module()\n",
      " |      b = tf.Module()\n",
      " |      c = tf.Module()\n",
      " |      a.b = b\n",
      " |      b.c = c\n",
      " |      assert list(a.submodules) == [b, c]\n",
      " |      assert list(b.submodules) == [c]\n",
      " |      assert list(c.submodules) == []\n",
      " |      ```\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of all submodules.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.training.tracking.base.Trackable:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(layers.Convolution2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "415bba5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Flatten in module tensorflow.python.keras.layers.core:\n",
      "\n",
      "class Flatten(tensorflow.python.keras.engine.base_layer.Layer)\n",
      " |  Flatten(data_format=None, **kwargs)\n",
      " |  \n",
      " |  Flattens the input. Does not affect the batch size.\n",
      " |  \n",
      " |  If inputs are shaped `(batch,)` without a channel dimension, then flattening\n",
      " |  adds an extra channel dimension and output shapes are `(batch, 1)`.\n",
      " |  \n",
      " |  Arguments:\n",
      " |    data_format: A string,\n",
      " |      one of `channels_last` (default) or `channels_first`.\n",
      " |      The ordering of the dimensions in the inputs.\n",
      " |      `channels_last` corresponds to inputs with shape\n",
      " |      `(batch, ..., channels)` while `channels_first` corresponds to\n",
      " |      inputs with shape `(batch, channels, ...)`.\n",
      " |      It defaults to the `image_data_format` value found in your\n",
      " |      Keras config file at `~/.keras/keras.json`.\n",
      " |      If you never set it, then it will be \"channels_last\".\n",
      " |  \n",
      " |  Example:\n",
      " |  \n",
      " |  ```python\n",
      " |  model = Sequential()\n",
      " |  model.add(Convolution2D(64, 3, 3,\n",
      " |                          border_mode='same',\n",
      " |                          input_shape=(3, 32, 32)))\n",
      " |  # now: model.output_shape == (None, 64, 32, 32)\n",
      " |  \n",
      " |  model.add(Flatten())\n",
      " |  # now: model.output_shape == (None, 65536)\n",
      " |  ```\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Flatten\n",
      " |      tensorflow.python.keras.engine.base_layer.Layer\n",
      " |      tensorflow.python.module.module.Module\n",
      " |      tensorflow.python.training.tracking.tracking.AutoTrackable\n",
      " |      tensorflow.python.training.tracking.base.Trackable\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, data_format=None, **kwargs)\n",
      " |  \n",
      " |  call(self, inputs)\n",
      " |      This is where the layer's logic lives.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          inputs: Input tensor, or list/tuple of input tensors.\n",
      " |          **kwargs: Additional keyword arguments.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor or list/tuple of tensors.\n",
      " |  \n",
      " |  compute_output_shape(self, input_shape)\n",
      " |      Computes the output shape of the layer.\n",
      " |      \n",
      " |      If the layer has not been built, this method will call `build` on the\n",
      " |      layer. This assumes that the layer will later be used with inputs that\n",
      " |      match the input shape provided here.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          input_shape: Shape tuple (tuple of integers)\n",
      " |              or list of shape tuples (one per output tensor of the layer).\n",
      " |              Shape tuples can include None for free dimensions,\n",
      " |              instead of an integer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An input shape tuple.\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the config of the layer.\n",
      " |      \n",
      " |      A layer config is a Python dictionary (serializable)\n",
      " |      containing the configuration of a layer.\n",
      " |      The same layer can be reinstantiated later\n",
      " |      (without its trained weights) from this configuration.\n",
      " |      \n",
      " |      The config of a layer does not include connectivity\n",
      " |      information, nor the layer class name. These are handled\n",
      " |      by `Network` (one layer of abstraction above).\n",
      " |      \n",
      " |      Returns:\n",
      " |          Python dictionary.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  __call__(self, inputs, *args, **kwargs)\n",
      " |      Wraps `call`, applying pre- and post-processing steps.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: input tensor(s).\n",
      " |        *args: additional positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: additional keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |      \n",
      " |      Note:\n",
      " |        - The following optional keyword arguments are reserved for specific uses:\n",
      " |          * `training`: Boolean scalar tensor of Python boolean indicating\n",
      " |            whether the `call` is meant for training or inference.\n",
      " |          * `mask`: Boolean input mask.\n",
      " |        - If the layer's `call` method takes a `mask` argument (as some Keras\n",
      " |          layers do), its default value will be set to the mask generated\n",
      " |          for `inputs` by the previous layer (if `input` did come from\n",
      " |          a layer that generated a corresponding mask, i.e. if it came from\n",
      " |          a Keras layer with masking support.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: if the layer's `call` method returns None (an invalid value).\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Support self.foo = trackable syntax.\n",
      " |  \n",
      " |  add_loss(self, losses, inputs=None)\n",
      " |      Add loss tensor(s), potentially dependent on layer inputs.\n",
      " |      \n",
      " |      Some losses (for instance, activity regularization losses) may be dependent\n",
      " |      on the inputs passed when calling a layer. Hence, when reusing the same\n",
      " |      layer on different inputs `a` and `b`, some entries in `layer.losses` may\n",
      " |      be dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      This method can be used inside a subclassed layer or model's `call`\n",
      " |      function, in which case `losses` should be a Tensor or list of Tensors.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      class MyLayer(tf.keras.layers.Layer):\n",
      " |        def call(inputs, self):\n",
      " |          self.add_loss(tf.abs(tf.reduce_mean(inputs)), inputs=True)\n",
      " |          return inputs\n",
      " |      ```\n",
      " |      \n",
      " |      This method can also be called directly on a Functional Model during\n",
      " |      construction. In this case, any loss Tensors passed to this Model must\n",
      " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
      " |      losses become part of the model's topology and are tracked in `get_config`.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Actvity regularization.\n",
      " |      model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
      " |      ```\n",
      " |      \n",
      " |      If this is not the case for your loss (if, for example, your loss references\n",
      " |      a `Variable` of one of the model's layers), you can wrap your loss in a\n",
      " |      zero-argument lambda. These losses are not tracked as part of the model's\n",
      " |      topology since they can't be serialized.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Weight regularization.\n",
      " |      model.add_loss(lambda: tf.reduce_mean(x.kernel))\n",
      " |      ```\n",
      " |      \n",
      " |      The `get_losses_for` method allows to retrieve the losses relevant to a\n",
      " |      specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        losses: Loss tensor, or list/tuple of tensors. Rather than tensors, losses\n",
      " |          may also be zero-argument callables which create a loss tensor.\n",
      " |        inputs: Ignored when executing eagerly. If anything other than None is\n",
      " |          passed, it signals the losses are conditional on some of the layer's\n",
      " |          inputs, and thus they should only be run where these inputs are\n",
      " |          available. This is the case for activity regularization losses, for\n",
      " |          instance. If `None` is passed, the losses are assumed\n",
      " |          to be unconditional, and will apply across all dataflows of the layer\n",
      " |          (e.g. weight regularization losses).\n",
      " |  \n",
      " |  add_metric(self, value, aggregation=None, name=None)\n",
      " |      Adds metric tensor to the layer.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: Metric tensor.\n",
      " |        aggregation: Sample-wise metric reduction function. If `aggregation=None`,\n",
      " |          it indicates that the metric tensor provided has been aggregated\n",
      " |          already. eg, `bin_acc = BinaryAccuracy(name='acc')` followed by\n",
      " |          `model.add_metric(bin_acc(y_true, y_pred))`. If aggregation='mean', the\n",
      " |          given metric tensor will be sample-wise reduced using `mean` function.\n",
      " |          eg, `model.add_metric(tf.reduce_sum(outputs), name='output_mean',\n",
      " |          aggregation='mean')`.\n",
      " |        name: String metric name.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If `aggregation` is anything other than None or `mean`.\n",
      " |  \n",
      " |  add_update(self, updates, inputs=None)\n",
      " |      Add update op(s), potentially dependent on layer inputs. (deprecated arguments)\n",
      " |      \n",
      " |      Warning: SOME ARGUMENTS ARE DEPRECATED: `(inputs)`. They will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      `inputs` is now automatically inferred\n",
      " |      \n",
      " |      Weight updates (for instance, the updates of the moving mean and variance\n",
      " |      in a BatchNormalization layer) may be dependent on the inputs passed\n",
      " |      when calling a layer. Hence, when reusing the same layer on\n",
      " |      different inputs `a` and `b`, some entries in `layer.updates` may be\n",
      " |      dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      The `get_updates_for` method allows to retrieve the updates relevant to a\n",
      " |      specific set of inputs.\n",
      " |      \n",
      " |      This call is ignored when eager execution is enabled (in that case, variable\n",
      " |      updates are run on the fly and thus do not need to be tracked for later\n",
      " |      execution).\n",
      " |      \n",
      " |      Arguments:\n",
      " |        updates: Update op, or list/tuple of update ops, or zero-arg callable\n",
      " |          that returns an update op. A zero-arg callable should be passed in\n",
      " |          order to disable running the updates by setting `trainable=False`\n",
      " |          on this Layer, when executing in Eager mode.\n",
      " |        inputs: Deprecated, will be automatically inferred.\n",
      " |  \n",
      " |  add_variable(self, *args, **kwargs)\n",
      " |      Deprecated, do NOT use! Alias for `add_weight`. (deprecated)\n",
      " |      \n",
      " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      Please use `layer.add_weight` method instead.\n",
      " |  \n",
      " |  add_weight(self, name=None, shape=None, dtype=None, initializer=None, regularizer=None, trainable=None, constraint=None, partitioner=None, use_resource=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregation.NONE: 0>, **kwargs)\n",
      " |      Adds a new variable to the layer.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        name: Variable name.\n",
      " |        shape: Variable shape. Defaults to scalar if unspecified.\n",
      " |        dtype: The type of the variable. Defaults to `self.dtype` or `float32`.\n",
      " |        initializer: Initializer instance (callable).\n",
      " |        regularizer: Regularizer instance (callable).\n",
      " |        trainable: Boolean, whether the variable should be part of the layer's\n",
      " |          \"trainable_variables\" (e.g. variables, biases)\n",
      " |          or \"non_trainable_variables\" (e.g. BatchNorm mean and variance).\n",
      " |          Note that `trainable` cannot be `True` if `synchronization`\n",
      " |          is set to `ON_READ`.\n",
      " |        constraint: Constraint instance (callable).\n",
      " |        partitioner: Partitioner to be passed to the `Trackable` API.\n",
      " |        use_resource: Whether to use `ResourceVariable`.\n",
      " |        synchronization: Indicates when a distributed a variable will be\n",
      " |          aggregated. Accepted values are constants defined in the class\n",
      " |          `tf.VariableSynchronization`. By default the synchronization is set to\n",
      " |          `AUTO` and the current `DistributionStrategy` chooses\n",
      " |          when to synchronize. If `synchronization` is set to `ON_READ`,\n",
      " |          `trainable` must not be set to `True`.\n",
      " |        aggregation: Indicates how a distributed variable will be aggregated.\n",
      " |          Accepted values are constants defined in the class\n",
      " |          `tf.VariableAggregation`.\n",
      " |        **kwargs: Additional keyword arguments. Accepted values are `getter` and\n",
      " |          `collections`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The created variable. Usually either a `Variable` or `ResourceVariable`\n",
      " |        instance. If `partitioner` is not `None`, a `PartitionedVariable`\n",
      " |        instance is returned.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called with partitioned variable regularization and\n",
      " |          eager execution is enabled.\n",
      " |        ValueError: When giving unsupported dtype and no initializer or when\n",
      " |          trainable has been set to True with synchronization set as `ON_READ`.\n",
      " |  \n",
      " |  apply(self, inputs, *args, **kwargs)\n",
      " |      Deprecated, do NOT use! (deprecated)\n",
      " |      \n",
      " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      Please use `layer.__call__` method instead.\n",
      " |      \n",
      " |      This is an alias of `self.__call__`.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor(s).\n",
      " |        *args: additional positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: additional keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |  \n",
      " |  build(self, input_shape)\n",
      " |      Creates the variables of the layer (optional, for subclass implementers).\n",
      " |      \n",
      " |      This is a method that implementers of subclasses of `Layer` or `Model`\n",
      " |      can override if they need a state-creation step in-between\n",
      " |      layer instantiation and layer call.\n",
      " |      \n",
      " |      This is typically used to create the weights of `Layer` subclasses.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        input_shape: Instance of `TensorShape`, or list of instances of\n",
      " |          `TensorShape` if the layer expects a list of inputs\n",
      " |          (one instance per input).\n",
      " |  \n",
      " |  compute_mask(self, inputs, mask=None)\n",
      " |      Computes an output mask tensor.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          inputs: Tensor or list of tensors.\n",
      " |          mask: Tensor or list of tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |          None or a tensor (or list of tensors,\n",
      " |              one per output tensor of the layer).\n",
      " |  \n",
      " |  compute_output_signature(self, input_signature)\n",
      " |      Compute the output tensor signature of the layer based on the inputs.\n",
      " |      \n",
      " |      Unlike a TensorShape object, a TensorSpec object contains both shape\n",
      " |      and dtype information for a tensor. This method allows layers to provide\n",
      " |      output dtype information if it is different from the input dtype.\n",
      " |      For any layer that doesn't implement this function,\n",
      " |      the framework will fall back to use `compute_output_shape`, and will\n",
      " |      assume that the output dtype matches the input dtype.\n",
      " |      \n",
      " |      Args:\n",
      " |        input_signature: Single TensorSpec or nested structure of TensorSpec\n",
      " |          objects, describing a candidate input for the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Single TensorSpec or nested structure of TensorSpec objects, describing\n",
      " |          how the layer would transform the provided input.\n",
      " |      \n",
      " |      Raises:\n",
      " |        TypeError: If input_signature contains a non-TensorSpec object.\n",
      " |  \n",
      " |  count_params(self)\n",
      " |      Count the total number of scalars composing the weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An integer count.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: if the layer isn't yet built\n",
      " |            (in which case its weights aren't yet defined).\n",
      " |  \n",
      " |  get_input_at(self, node_index)\n",
      " |      Retrieves the input tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_input_mask_at(self, node_index)\n",
      " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_shape_at(self, node_index)\n",
      " |      Retrieves the input shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_losses_for(self, inputs)\n",
      " |      Retrieves losses relevant to a specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor or list/tuple of input tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |        List of loss tensors of the layer that depend on `inputs`.\n",
      " |  \n",
      " |  get_output_at(self, node_index)\n",
      " |      Retrieves the output tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_output_mask_at(self, node_index)\n",
      " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_shape_at(self, node_index)\n",
      " |      Retrieves the output shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_updates_for(self, inputs)\n",
      " |      Retrieves updates relevant to a specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor or list/tuple of input tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |        List of update ops of the layer that depend on `inputs`.\n",
      " |  \n",
      " |  get_weights(self)\n",
      " |      Returns the current weights of the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Weights values as a list of numpy arrays.\n",
      " |  \n",
      " |  set_weights(self, weights)\n",
      " |      Sets the weights of the layer, from Numpy arrays.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          weights: a list of Numpy arrays. The number\n",
      " |              of arrays and their shape must match\n",
      " |              number of the dimensions of the weights\n",
      " |              of the layer (i.e. it should match the\n",
      " |              output of `get_weights`).\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: If the provided weights list does not match the\n",
      " |              layer's specifications.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  from_config(config) from builtins.type\n",
      " |      Creates a layer from its config.\n",
      " |      \n",
      " |      This method is the reverse of `get_config`,\n",
      " |      capable of instantiating the same layer from the config\n",
      " |      dictionary. It does not handle layer connectivity\n",
      " |      (handled by Network), nor weights (handled by `set_weights`).\n",
      " |      \n",
      " |      Arguments:\n",
      " |          config: A Python dictionary, typically the\n",
      " |              output of get_config.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A layer instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  activity_regularizer\n",
      " |      Optional regularizer function for the output of this layer.\n",
      " |  \n",
      " |  dtype\n",
      " |  \n",
      " |  dynamic\n",
      " |  \n",
      " |  inbound_nodes\n",
      " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      " |  \n",
      " |  input\n",
      " |      Retrieves the input tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input tensor or list of input tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |        AttributeError: If no inbound nodes are found.\n",
      " |  \n",
      " |  input_mask\n",
      " |      Retrieves the input mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input mask tensor (potentially None) or list of input\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_shape\n",
      " |      Retrieves the input shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer, or if all inputs\n",
      " |      have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per input tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined input_shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  input_spec\n",
      " |  \n",
      " |  losses\n",
      " |      Losses which are associated with this `Layer`.\n",
      " |      \n",
      " |      Variable regularization tensors are created when this property is accessed,\n",
      " |      so it is eager safe: accessing `losses` under a `tf.GradientTape` will\n",
      " |      propagate gradients back to the corresponding variables.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of tensors.\n",
      " |  \n",
      " |  metrics\n",
      " |  \n",
      " |  name\n",
      " |      Returns the name of this module as passed or determined in the ctor.\n",
      " |      \n",
      " |      NOTE: This is not the same as the `self.name_scope.name` which includes\n",
      " |      parent module names.\n",
      " |  \n",
      " |  non_trainable_variables\n",
      " |  \n",
      " |  non_trainable_weights\n",
      " |  \n",
      " |  outbound_nodes\n",
      " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      " |  \n",
      " |  output\n",
      " |      Retrieves the output tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one output,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor or list of output tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        AttributeError: if the layer is connected to more than one incoming\n",
      " |          layers.\n",
      " |        RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  output_mask\n",
      " |      Retrieves the output mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output mask tensor (potentially None) or list of output\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_shape\n",
      " |      Retrieves the output shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has one output,\n",
      " |      or if all outputs have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per output tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined output shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  trainable\n",
      " |  \n",
      " |  trainable_variables\n",
      " |      Sequence of variables owned by this module and it's submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  trainable_weights\n",
      " |  \n",
      " |  updates\n",
      " |  \n",
      " |  variables\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Alias of `self.weights`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  weights\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  with_name_scope(method) from builtins.type\n",
      " |      Decorator to automatically enter the module name scope.\n",
      " |      \n",
      " |      ```\n",
      " |      class MyModule(tf.Module):\n",
      " |        @tf.Module.with_name_scope\n",
      " |        def __call__(self, x):\n",
      " |          if not hasattr(self, 'w'):\n",
      " |            self.w = tf.Variable(tf.random.normal([x.shape[1], 64]))\n",
      " |          return tf.matmul(x, self.w)\n",
      " |      ```\n",
      " |      \n",
      " |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
      " |      names included the module name:\n",
      " |      \n",
      " |      ```\n",
      " |      mod = MyModule()\n",
      " |      mod(tf.ones([8, 32]))\n",
      " |      # ==> <tf.Tensor: ...>\n",
      " |      mod.w\n",
      " |      # ==> <tf.Variable ...'my_module/w:0'>\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        method: The method to wrap.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The original method wrapped such that it enters the module's name scope.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  name_scope\n",
      " |      Returns a `tf.name_scope` instance for this class.\n",
      " |  \n",
      " |  submodules\n",
      " |      Sequence of all sub-modules.\n",
      " |      \n",
      " |      Submodules are modules which are properties of this module, or found as\n",
      " |      properties of modules which are properties of this module (and so on).\n",
      " |      \n",
      " |      ```\n",
      " |      a = tf.Module()\n",
      " |      b = tf.Module()\n",
      " |      c = tf.Module()\n",
      " |      a.b = b\n",
      " |      b.c = c\n",
      " |      assert list(a.submodules) == [b, c]\n",
      " |      assert list(b.submodules) == [c]\n",
      " |      assert list(c.submodules) == []\n",
      " |      ```\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of all submodules.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.training.tracking.base.Trackable:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(layers.Flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b14c02b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Dense in module tensorflow.python.keras.layers.core:\n",
      "\n",
      "class Dense(tensorflow.python.keras.engine.base_layer.Layer)\n",
      " |  Dense(units, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)\n",
      " |  \n",
      " |  Just your regular densely-connected NN layer.\n",
      " |  \n",
      " |  `Dense` implements the operation:\n",
      " |  `output = activation(dot(input, kernel) + bias)`\n",
      " |  where `activation` is the element-wise activation function\n",
      " |  passed as the `activation` argument, `kernel` is a weights matrix\n",
      " |  created by the layer, and `bias` is a bias vector created by the layer\n",
      " |  (only applicable if `use_bias` is `True`).\n",
      " |  \n",
      " |  Note: If the input to the layer has a rank greater than 2, then\n",
      " |  it is flattened prior to the initial dot product with `kernel`.\n",
      " |  \n",
      " |  Example:\n",
      " |  \n",
      " |  ```python\n",
      " |  # as first layer in a sequential model:\n",
      " |  model = Sequential()\n",
      " |  model.add(Dense(32, input_shape=(16,)))\n",
      " |  # now the model will take as input arrays of shape (*, 16)\n",
      " |  # and output arrays of shape (*, 32)\n",
      " |  \n",
      " |  # after the first layer, you don't need to specify\n",
      " |  # the size of the input anymore:\n",
      " |  model.add(Dense(32))\n",
      " |  ```\n",
      " |  \n",
      " |  Arguments:\n",
      " |    units: Positive integer, dimensionality of the output space.\n",
      " |    activation: Activation function to use.\n",
      " |      If you don't specify anything, no activation is applied\n",
      " |      (ie. \"linear\" activation: `a(x) = x`).\n",
      " |    use_bias: Boolean, whether the layer uses a bias vector.\n",
      " |    kernel_initializer: Initializer for the `kernel` weights matrix.\n",
      " |    bias_initializer: Initializer for the bias vector.\n",
      " |    kernel_regularizer: Regularizer function applied to\n",
      " |      the `kernel` weights matrix.\n",
      " |    bias_regularizer: Regularizer function applied to the bias vector.\n",
      " |    activity_regularizer: Regularizer function applied to\n",
      " |      the output of the layer (its \"activation\")..\n",
      " |    kernel_constraint: Constraint function applied to\n",
      " |      the `kernel` weights matrix.\n",
      " |    bias_constraint: Constraint function applied to the bias vector.\n",
      " |  \n",
      " |  Input shape:\n",
      " |    N-D tensor with shape: `(batch_size, ..., input_dim)`.\n",
      " |    The most common situation would be\n",
      " |    a 2D input with shape `(batch_size, input_dim)`.\n",
      " |  \n",
      " |  Output shape:\n",
      " |    N-D tensor with shape: `(batch_size, ..., units)`.\n",
      " |    For instance, for a 2D input with shape `(batch_size, input_dim)`,\n",
      " |    the output would have shape `(batch_size, units)`.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Dense\n",
      " |      tensorflow.python.keras.engine.base_layer.Layer\n",
      " |      tensorflow.python.module.module.Module\n",
      " |      tensorflow.python.training.tracking.tracking.AutoTrackable\n",
      " |      tensorflow.python.training.tracking.base.Trackable\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, units, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)\n",
      " |  \n",
      " |  build(self, input_shape)\n",
      " |      Creates the variables of the layer (optional, for subclass implementers).\n",
      " |      \n",
      " |      This is a method that implementers of subclasses of `Layer` or `Model`\n",
      " |      can override if they need a state-creation step in-between\n",
      " |      layer instantiation and layer call.\n",
      " |      \n",
      " |      This is typically used to create the weights of `Layer` subclasses.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        input_shape: Instance of `TensorShape`, or list of instances of\n",
      " |          `TensorShape` if the layer expects a list of inputs\n",
      " |          (one instance per input).\n",
      " |  \n",
      " |  call(self, inputs)\n",
      " |      This is where the layer's logic lives.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          inputs: Input tensor, or list/tuple of input tensors.\n",
      " |          **kwargs: Additional keyword arguments.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor or list/tuple of tensors.\n",
      " |  \n",
      " |  compute_output_shape(self, input_shape)\n",
      " |      Computes the output shape of the layer.\n",
      " |      \n",
      " |      If the layer has not been built, this method will call `build` on the\n",
      " |      layer. This assumes that the layer will later be used with inputs that\n",
      " |      match the input shape provided here.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          input_shape: Shape tuple (tuple of integers)\n",
      " |              or list of shape tuples (one per output tensor of the layer).\n",
      " |              Shape tuples can include None for free dimensions,\n",
      " |              instead of an integer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An input shape tuple.\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the config of the layer.\n",
      " |      \n",
      " |      A layer config is a Python dictionary (serializable)\n",
      " |      containing the configuration of a layer.\n",
      " |      The same layer can be reinstantiated later\n",
      " |      (without its trained weights) from this configuration.\n",
      " |      \n",
      " |      The config of a layer does not include connectivity\n",
      " |      information, nor the layer class name. These are handled\n",
      " |      by `Network` (one layer of abstraction above).\n",
      " |      \n",
      " |      Returns:\n",
      " |          Python dictionary.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  __call__(self, inputs, *args, **kwargs)\n",
      " |      Wraps `call`, applying pre- and post-processing steps.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: input tensor(s).\n",
      " |        *args: additional positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: additional keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |      \n",
      " |      Note:\n",
      " |        - The following optional keyword arguments are reserved for specific uses:\n",
      " |          * `training`: Boolean scalar tensor of Python boolean indicating\n",
      " |            whether the `call` is meant for training or inference.\n",
      " |          * `mask`: Boolean input mask.\n",
      " |        - If the layer's `call` method takes a `mask` argument (as some Keras\n",
      " |          layers do), its default value will be set to the mask generated\n",
      " |          for `inputs` by the previous layer (if `input` did come from\n",
      " |          a layer that generated a corresponding mask, i.e. if it came from\n",
      " |          a Keras layer with masking support.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: if the layer's `call` method returns None (an invalid value).\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Support self.foo = trackable syntax.\n",
      " |  \n",
      " |  add_loss(self, losses, inputs=None)\n",
      " |      Add loss tensor(s), potentially dependent on layer inputs.\n",
      " |      \n",
      " |      Some losses (for instance, activity regularization losses) may be dependent\n",
      " |      on the inputs passed when calling a layer. Hence, when reusing the same\n",
      " |      layer on different inputs `a` and `b`, some entries in `layer.losses` may\n",
      " |      be dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      This method can be used inside a subclassed layer or model's `call`\n",
      " |      function, in which case `losses` should be a Tensor or list of Tensors.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      class MyLayer(tf.keras.layers.Layer):\n",
      " |        def call(inputs, self):\n",
      " |          self.add_loss(tf.abs(tf.reduce_mean(inputs)), inputs=True)\n",
      " |          return inputs\n",
      " |      ```\n",
      " |      \n",
      " |      This method can also be called directly on a Functional Model during\n",
      " |      construction. In this case, any loss Tensors passed to this Model must\n",
      " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
      " |      losses become part of the model's topology and are tracked in `get_config`.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Actvity regularization.\n",
      " |      model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
      " |      ```\n",
      " |      \n",
      " |      If this is not the case for your loss (if, for example, your loss references\n",
      " |      a `Variable` of one of the model's layers), you can wrap your loss in a\n",
      " |      zero-argument lambda. These losses are not tracked as part of the model's\n",
      " |      topology since they can't be serialized.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Weight regularization.\n",
      " |      model.add_loss(lambda: tf.reduce_mean(x.kernel))\n",
      " |      ```\n",
      " |      \n",
      " |      The `get_losses_for` method allows to retrieve the losses relevant to a\n",
      " |      specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        losses: Loss tensor, or list/tuple of tensors. Rather than tensors, losses\n",
      " |          may also be zero-argument callables which create a loss tensor.\n",
      " |        inputs: Ignored when executing eagerly. If anything other than None is\n",
      " |          passed, it signals the losses are conditional on some of the layer's\n",
      " |          inputs, and thus they should only be run where these inputs are\n",
      " |          available. This is the case for activity regularization losses, for\n",
      " |          instance. If `None` is passed, the losses are assumed\n",
      " |          to be unconditional, and will apply across all dataflows of the layer\n",
      " |          (e.g. weight regularization losses).\n",
      " |  \n",
      " |  add_metric(self, value, aggregation=None, name=None)\n",
      " |      Adds metric tensor to the layer.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: Metric tensor.\n",
      " |        aggregation: Sample-wise metric reduction function. If `aggregation=None`,\n",
      " |          it indicates that the metric tensor provided has been aggregated\n",
      " |          already. eg, `bin_acc = BinaryAccuracy(name='acc')` followed by\n",
      " |          `model.add_metric(bin_acc(y_true, y_pred))`. If aggregation='mean', the\n",
      " |          given metric tensor will be sample-wise reduced using `mean` function.\n",
      " |          eg, `model.add_metric(tf.reduce_sum(outputs), name='output_mean',\n",
      " |          aggregation='mean')`.\n",
      " |        name: String metric name.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If `aggregation` is anything other than None or `mean`.\n",
      " |  \n",
      " |  add_update(self, updates, inputs=None)\n",
      " |      Add update op(s), potentially dependent on layer inputs. (deprecated arguments)\n",
      " |      \n",
      " |      Warning: SOME ARGUMENTS ARE DEPRECATED: `(inputs)`. They will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      `inputs` is now automatically inferred\n",
      " |      \n",
      " |      Weight updates (for instance, the updates of the moving mean and variance\n",
      " |      in a BatchNormalization layer) may be dependent on the inputs passed\n",
      " |      when calling a layer. Hence, when reusing the same layer on\n",
      " |      different inputs `a` and `b`, some entries in `layer.updates` may be\n",
      " |      dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      The `get_updates_for` method allows to retrieve the updates relevant to a\n",
      " |      specific set of inputs.\n",
      " |      \n",
      " |      This call is ignored when eager execution is enabled (in that case, variable\n",
      " |      updates are run on the fly and thus do not need to be tracked for later\n",
      " |      execution).\n",
      " |      \n",
      " |      Arguments:\n",
      " |        updates: Update op, or list/tuple of update ops, or zero-arg callable\n",
      " |          that returns an update op. A zero-arg callable should be passed in\n",
      " |          order to disable running the updates by setting `trainable=False`\n",
      " |          on this Layer, when executing in Eager mode.\n",
      " |        inputs: Deprecated, will be automatically inferred.\n",
      " |  \n",
      " |  add_variable(self, *args, **kwargs)\n",
      " |      Deprecated, do NOT use! Alias for `add_weight`. (deprecated)\n",
      " |      \n",
      " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      Please use `layer.add_weight` method instead.\n",
      " |  \n",
      " |  add_weight(self, name=None, shape=None, dtype=None, initializer=None, regularizer=None, trainable=None, constraint=None, partitioner=None, use_resource=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregation.NONE: 0>, **kwargs)\n",
      " |      Adds a new variable to the layer.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        name: Variable name.\n",
      " |        shape: Variable shape. Defaults to scalar if unspecified.\n",
      " |        dtype: The type of the variable. Defaults to `self.dtype` or `float32`.\n",
      " |        initializer: Initializer instance (callable).\n",
      " |        regularizer: Regularizer instance (callable).\n",
      " |        trainable: Boolean, whether the variable should be part of the layer's\n",
      " |          \"trainable_variables\" (e.g. variables, biases)\n",
      " |          or \"non_trainable_variables\" (e.g. BatchNorm mean and variance).\n",
      " |          Note that `trainable` cannot be `True` if `synchronization`\n",
      " |          is set to `ON_READ`.\n",
      " |        constraint: Constraint instance (callable).\n",
      " |        partitioner: Partitioner to be passed to the `Trackable` API.\n",
      " |        use_resource: Whether to use `ResourceVariable`.\n",
      " |        synchronization: Indicates when a distributed a variable will be\n",
      " |          aggregated. Accepted values are constants defined in the class\n",
      " |          `tf.VariableSynchronization`. By default the synchronization is set to\n",
      " |          `AUTO` and the current `DistributionStrategy` chooses\n",
      " |          when to synchronize. If `synchronization` is set to `ON_READ`,\n",
      " |          `trainable` must not be set to `True`.\n",
      " |        aggregation: Indicates how a distributed variable will be aggregated.\n",
      " |          Accepted values are constants defined in the class\n",
      " |          `tf.VariableAggregation`.\n",
      " |        **kwargs: Additional keyword arguments. Accepted values are `getter` and\n",
      " |          `collections`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The created variable. Usually either a `Variable` or `ResourceVariable`\n",
      " |        instance. If `partitioner` is not `None`, a `PartitionedVariable`\n",
      " |        instance is returned.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called with partitioned variable regularization and\n",
      " |          eager execution is enabled.\n",
      " |        ValueError: When giving unsupported dtype and no initializer or when\n",
      " |          trainable has been set to True with synchronization set as `ON_READ`.\n",
      " |  \n",
      " |  apply(self, inputs, *args, **kwargs)\n",
      " |      Deprecated, do NOT use! (deprecated)\n",
      " |      \n",
      " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      Please use `layer.__call__` method instead.\n",
      " |      \n",
      " |      This is an alias of `self.__call__`.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor(s).\n",
      " |        *args: additional positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: additional keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |  \n",
      " |  compute_mask(self, inputs, mask=None)\n",
      " |      Computes an output mask tensor.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          inputs: Tensor or list of tensors.\n",
      " |          mask: Tensor or list of tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |          None or a tensor (or list of tensors,\n",
      " |              one per output tensor of the layer).\n",
      " |  \n",
      " |  compute_output_signature(self, input_signature)\n",
      " |      Compute the output tensor signature of the layer based on the inputs.\n",
      " |      \n",
      " |      Unlike a TensorShape object, a TensorSpec object contains both shape\n",
      " |      and dtype information for a tensor. This method allows layers to provide\n",
      " |      output dtype information if it is different from the input dtype.\n",
      " |      For any layer that doesn't implement this function,\n",
      " |      the framework will fall back to use `compute_output_shape`, and will\n",
      " |      assume that the output dtype matches the input dtype.\n",
      " |      \n",
      " |      Args:\n",
      " |        input_signature: Single TensorSpec or nested structure of TensorSpec\n",
      " |          objects, describing a candidate input for the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Single TensorSpec or nested structure of TensorSpec objects, describing\n",
      " |          how the layer would transform the provided input.\n",
      " |      \n",
      " |      Raises:\n",
      " |        TypeError: If input_signature contains a non-TensorSpec object.\n",
      " |  \n",
      " |  count_params(self)\n",
      " |      Count the total number of scalars composing the weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An integer count.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: if the layer isn't yet built\n",
      " |            (in which case its weights aren't yet defined).\n",
      " |  \n",
      " |  get_input_at(self, node_index)\n",
      " |      Retrieves the input tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_input_mask_at(self, node_index)\n",
      " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_shape_at(self, node_index)\n",
      " |      Retrieves the input shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_losses_for(self, inputs)\n",
      " |      Retrieves losses relevant to a specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor or list/tuple of input tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |        List of loss tensors of the layer that depend on `inputs`.\n",
      " |  \n",
      " |  get_output_at(self, node_index)\n",
      " |      Retrieves the output tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_output_mask_at(self, node_index)\n",
      " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_shape_at(self, node_index)\n",
      " |      Retrieves the output shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_updates_for(self, inputs)\n",
      " |      Retrieves updates relevant to a specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor or list/tuple of input tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |        List of update ops of the layer that depend on `inputs`.\n",
      " |  \n",
      " |  get_weights(self)\n",
      " |      Returns the current weights of the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Weights values as a list of numpy arrays.\n",
      " |  \n",
      " |  set_weights(self, weights)\n",
      " |      Sets the weights of the layer, from Numpy arrays.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          weights: a list of Numpy arrays. The number\n",
      " |              of arrays and their shape must match\n",
      " |              number of the dimensions of the weights\n",
      " |              of the layer (i.e. it should match the\n",
      " |              output of `get_weights`).\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: If the provided weights list does not match the\n",
      " |              layer's specifications.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  from_config(config) from builtins.type\n",
      " |      Creates a layer from its config.\n",
      " |      \n",
      " |      This method is the reverse of `get_config`,\n",
      " |      capable of instantiating the same layer from the config\n",
      " |      dictionary. It does not handle layer connectivity\n",
      " |      (handled by Network), nor weights (handled by `set_weights`).\n",
      " |      \n",
      " |      Arguments:\n",
      " |          config: A Python dictionary, typically the\n",
      " |              output of get_config.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A layer instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  activity_regularizer\n",
      " |      Optional regularizer function for the output of this layer.\n",
      " |  \n",
      " |  dtype\n",
      " |  \n",
      " |  dynamic\n",
      " |  \n",
      " |  inbound_nodes\n",
      " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      " |  \n",
      " |  input\n",
      " |      Retrieves the input tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input tensor or list of input tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |        AttributeError: If no inbound nodes are found.\n",
      " |  \n",
      " |  input_mask\n",
      " |      Retrieves the input mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input mask tensor (potentially None) or list of input\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_shape\n",
      " |      Retrieves the input shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer, or if all inputs\n",
      " |      have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per input tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined input_shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  input_spec\n",
      " |  \n",
      " |  losses\n",
      " |      Losses which are associated with this `Layer`.\n",
      " |      \n",
      " |      Variable regularization tensors are created when this property is accessed,\n",
      " |      so it is eager safe: accessing `losses` under a `tf.GradientTape` will\n",
      " |      propagate gradients back to the corresponding variables.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of tensors.\n",
      " |  \n",
      " |  metrics\n",
      " |  \n",
      " |  name\n",
      " |      Returns the name of this module as passed or determined in the ctor.\n",
      " |      \n",
      " |      NOTE: This is not the same as the `self.name_scope.name` which includes\n",
      " |      parent module names.\n",
      " |  \n",
      " |  non_trainable_variables\n",
      " |  \n",
      " |  non_trainable_weights\n",
      " |  \n",
      " |  outbound_nodes\n",
      " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      " |  \n",
      " |  output\n",
      " |      Retrieves the output tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one output,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor or list of output tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        AttributeError: if the layer is connected to more than one incoming\n",
      " |          layers.\n",
      " |        RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  output_mask\n",
      " |      Retrieves the output mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output mask tensor (potentially None) or list of output\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_shape\n",
      " |      Retrieves the output shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has one output,\n",
      " |      or if all outputs have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per output tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined output shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  trainable\n",
      " |  \n",
      " |  trainable_variables\n",
      " |      Sequence of variables owned by this module and it's submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  trainable_weights\n",
      " |  \n",
      " |  updates\n",
      " |  \n",
      " |  variables\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Alias of `self.weights`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  weights\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  with_name_scope(method) from builtins.type\n",
      " |      Decorator to automatically enter the module name scope.\n",
      " |      \n",
      " |      ```\n",
      " |      class MyModule(tf.Module):\n",
      " |        @tf.Module.with_name_scope\n",
      " |        def __call__(self, x):\n",
      " |          if not hasattr(self, 'w'):\n",
      " |            self.w = tf.Variable(tf.random.normal([x.shape[1], 64]))\n",
      " |          return tf.matmul(x, self.w)\n",
      " |      ```\n",
      " |      \n",
      " |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
      " |      names included the module name:\n",
      " |      \n",
      " |      ```\n",
      " |      mod = MyModule()\n",
      " |      mod(tf.ones([8, 32]))\n",
      " |      # ==> <tf.Tensor: ...>\n",
      " |      mod.w\n",
      " |      # ==> <tf.Variable ...'my_module/w:0'>\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        method: The method to wrap.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The original method wrapped such that it enters the module's name scope.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  name_scope\n",
      " |      Returns a `tf.name_scope` instance for this class.\n",
      " |  \n",
      " |  submodules\n",
      " |      Sequence of all sub-modules.\n",
      " |      \n",
      " |      Submodules are modules which are properties of this module, or found as\n",
      " |      properties of modules which are properties of this module (and so on).\n",
      " |      \n",
      " |      ```\n",
      " |      a = tf.Module()\n",
      " |      b = tf.Module()\n",
      " |      c = tf.Module()\n",
      " |      a.b = b\n",
      " |      b.c = c\n",
      " |      assert list(a.submodules) == [b, c]\n",
      " |      assert list(b.submodules) == [c]\n",
      " |      assert list(c.submodules) == []\n",
      " |      ```\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of all submodules.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.training.tracking.base.Trackable:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(layers.Dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a03a24c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "800c1013",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_2 = models.Sequential([\n",
    "    layers.Convolution2D(filters = 5, kernel_size = (3,3),activation='relu', input_shape=(28, 28,1)),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    \n",
    "    layers.Convolution2D(filters = 5, kernel_size = (3,3),activation='relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='sigmoid'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "db5d52ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_2.compile(optimizer = 'adam',\n",
    "             loss= 'sparse_categorical_crossentropy',\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "aea2cc81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "ade4806c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "3b5005e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test = y_test.reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b8087168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "c075344c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_train_reshaped = np.expand_dims(X_train, axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "736b42a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "2a511ab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.00392157, 0.33333333, 1.        ,\n",
       "       0.9372549 , 0.2       , 0.00784314, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[34444][23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "b0b2cfb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 27s 445us/sample - loss: 0.3053 - acc: 0.9050\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 27s 446us/sample - loss: 0.1227 - acc: 0.9620\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 30s 502us/sample - loss: 0.0966 - acc: 0.9704\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 28s 461us/sample - loss: 0.0812 - acc: 0.9749\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 23s 375us/sample - loss: 0.0708 - acc: 0.9783\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 23s 379us/sample - loss: 0.0623 - acc: 0.9809\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 23s 377us/sample - loss: 0.0536 - acc: 0.9830\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 22s 373us/sample - loss: 0.0485 - acc: 0.9847\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 23s 376us/sample - loss: 0.0439 - acc: 0.9857\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 23s 375us/sample - loss: 0.0410 - acc: 0.9871\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x27d6aa768c8>"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_2.fit(X_train_reshaped, y_train ,epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "eb7093fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_reshaped = np.expand_dims(X_test, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "ba84b64d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "a2298307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "4c06d109",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_reshaped = np.expand_dims(y_test, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "9f514ae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "f05a7c60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "beb65327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From git of the guy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "609f5196",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train),(X_test, y_test) = datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "b5e4f487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "X_train = X_train.reshape(-1,28,28,1)\n",
    "X_train.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "0ce48976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = X_test.reshape(-1,28,28,1)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "47b46aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_3 = models.Sequential([\n",
    "    layers.Convolution2D(filters = 5, kernel_size = (3,3),activation='relu', input_shape=(28, 28,1)),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    \n",
    "    layers.Convolution2D(filters = 5, kernel_size = (3,3),activation='relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "cnn_3.compile(optimizer = 'adam',\n",
    "             loss= 'sparse_categorical_crossentropy',\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "5468ca46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 44s 729us/sample - loss: 0.7410 - acc: 0.7670\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 46s 768us/sample - loss: 0.1477 - acc: 0.9556\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 44s 739us/sample - loss: 0.1035 - acc: 0.9684\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 41s 685us/sample - loss: 0.0857 - acc: 0.9739\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 36s 598us/sample - loss: 0.0725 - acc: 0.9778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x27d6aa61108>"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_3.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "8f72715d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 4s 413us/sample - loss: 0.0753 - acc: 0.9773\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0753352636468131, 0.9773]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_3.evaluate(X_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
