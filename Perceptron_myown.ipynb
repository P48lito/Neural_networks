{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "utgvFolE71q7"
      },
      "outputs": [],
      "source": [
        "# Perceptron algorithm implementation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# I will implement perceptron algorithm"
      ],
      "metadata": {
        "id": "tEjAyLN8ojb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import math as mt\n",
        "\n",
        "features = np.array(([0.1,0.5,0.2],[0.2,0.3,0.1],[0.7,0.4,0.2],[0.1,0.4,0.3]))\n",
        "targets = np.array([0,1,0,1])\n",
        "weights = np.array([0.4, 0.2, 0.6])\n",
        "learnrate = 0.1\n",
        "bias = 0.5\n",
        "\n",
        "# def gradient_descent(x_features, target, weights, bias, learnrate, pred):\n",
        "#   # def gradient_descent(x_features, weights,pred,target,bias,learnrate):\n",
        "#   new_weights = []\n",
        "\n",
        "#   bias = bias + learnrate*(target-pred)\n",
        "\n",
        "\n",
        "#   for x, w in zip(x_features, weights):\n",
        "#     new_w = w + learnrate*(target-pred)*x\n",
        "#     new_weights.append(new_w)\n",
        "\n",
        "#     return new_weights, bias\n",
        "\n",
        "def gradient_descent(x, y, weights, bias, learnrate, pred):\n",
        "    new_weights = []\n",
        "    bias += learnrate*(y-pred)\n",
        "\n",
        "    for w,xi in zip(weights,x):\n",
        "        new_weight = w + learnrate*(y-pred)*xi\n",
        "        new_weights.append(new_weight) \n",
        "    return new_weights, bias\n",
        "\n",
        "# Activation Function\n",
        "def sigmoid(w_sum):\n",
        "    return 1/(1+np.exp(-w_sum))\n",
        "\n",
        "# Get Prediction\n",
        "def predict(features, weights, bias):\n",
        "    return sigmoid(np.dot(features, weights) + bias)\n",
        "\n",
        "# Loss Function\n",
        "def cross_entropy(target, pred):\n",
        "    return -(target*np.log10(pred)+(1-target)*(np.log10(1-pred)))\n",
        "\n",
        "# def sigmoid(w_sum):\n",
        "#   return 1/(1+mt.e**(-w_sum))\n",
        "\n",
        "# def predict(features, weights, bias):\n",
        "#   return sigmoid(np.dot(features,weights)+bias)\n",
        "\n",
        "# #Check if is good\n",
        "# print(predict(features, weights, bias))\n",
        "\n",
        "# def cross_entropy(target, pred):\n",
        "#   return -(target*np.log10(pred)+(1-target)*np.log10(1-pred))\n",
        "\n",
        "np.mean(cross_entropy(targets, predict(features, weights, bias)))\n",
        "\n",
        "\n",
        "epochs = 5\n",
        "\n",
        "# for s in range(epochs):\n",
        "\n",
        "#   pred = predict(features, weights, bias)\n",
        "#   weights, bias = gradient_descent(features, weights,pred,targets,bias)\n",
        "\n",
        "for e in range(epochs):\n",
        "    for x, y in zip(features, targets):\n",
        "        pred = predict(x, weights, bias)\n",
        "        error = cross_entropy(y, pred)\n",
        "        weights, bias = gradient_descent(x, y, weights, bias, learnrate, pred)\n",
        "    \n",
        "    # Printing out the log-loss error on the training set\n",
        "    out = predict(features, weights, bias)\n",
        "    loss = np.mean(cross_entropy(targets, out))\n",
        "    # errors.append(loss)\n",
        "    print(\"\\n========== Epoch\", e,\"==========\")\n",
        "    print(\"Average loss: \", loss)\n",
        "# out = predict(features, weights, bias)\n",
        "# loss = np.mean(cross_entropy(targets, out))\n",
        "# def try_function(weights, x):\n",
        "#   for w,xi in zip(weights,x):\n",
        "#     print(xi)\n",
        "#   # print(x)\n",
        "\n",
        "# for xi in features:\n",
        "#   try_function(weights,xi)\n",
        "#   # print(w)\n",
        "#   # print(xi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwhHQYR71Rhy",
        "outputId": "cc2983fd-e4bc-43b0-ec2e-fe6c3e136320"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========== Epoch 0 ==========\n",
            "Average loss:  0.33944294852408824\n",
            "\n",
            "========== Epoch 1 ==========\n",
            "Average loss:  0.33147083470744965\n",
            "\n",
            "========== Epoch 2 ==========\n",
            "Average loss:  0.32499752814643046\n",
            "\n",
            "========== Epoch 3 ==========\n",
            "Average loss:  0.31973828925825093\n",
            "\n",
            "========== Epoch 4 ==========\n",
            "Average loss:  0.3154527992144233\n"
          ]
        }
      ]
    }
  ]
}